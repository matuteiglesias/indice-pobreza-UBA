{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_298514/3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de informacion accesoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Q             Region          CBA          CBT\n",
      "0  2003-02-15               cuyo  1238.589102  3176.495627\n",
      "1  2003-02-15  gran_buenos_aires  1390.409493  3349.454151\n",
      "2  2003-02-15            noreste  1244.428745  2806.272579\n",
      "3  2003-02-15           noroeste  1207.986502  2700.523155\n",
      "4  2003-02-15           pampeana  1377.923211  3318.374699\n"
     ]
    }
   ],
   "source": [
    "# Adulto equivalente. Cuanto cuesta la manutencion de las personas segun sexo y edad.\n",
    "ad_eq = pd.read_csv('./../data/info/adulto_eq.csv')\n",
    "\n",
    "#Importar canasta basica regional deflac\n",
    "url_canasta_q_deflac = 'https://raw.githubusercontent.com/matuteiglesias/canastasINDEC/main/data/CB_Reg_defl_Q.csv'\n",
    "CB_ipc = pd.read_csv(url_canasta_q_deflac)\n",
    "\n",
    "# Check the first few rows to confirm it's loaded correctly\n",
    "print(CB_ipc.head())\n",
    "# ppp_defl = pd.read_csv('./../data/info/ppp_defl.csv')\n",
    "\n",
    "# Load radio ref. Merge regiones.\n",
    "# Anything that is AGLOMERADO 33 should be region Gran Buenos Aires\n",
    "# radio_ref = pd.read_csv('./../data/info/radio_ref.csv').merge(pd.read_csv('./../data/info/prov_regs.csv'), how = 'left')\n",
    "radio_ref = pd.read_csv('./../data/info/radio_ref.csv')#.merge(aglo_labels)\n",
    "dpto_region = pd.read_csv('./../data/info/DPTO_PROV_Region.csv')\n",
    "radio_ref = radio_ref.merge(dpto_region)\n",
    "\n",
    "# DPTO_Region = radio_ref[['DPTO', 'Region']].drop_duplicates()\n",
    "\n",
    "# dpto_region = pd.read_csv('./../data/info/DPTO_PROV_Region.csv')\n",
    "DPTO_Region = radio_ref[['DPTO', 'Region']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./../data/Pobreza/'):\n",
    "    os.makedirs('./../data/Pobreza/')\n",
    "\n",
    "frac = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion Generar dataset Pobreza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ## Grupos Etarios\n",
    "    # df_ingresos['Grupo_Etario_3'] = pd.cut(df_ingresos.P03, np.arange(-1, 80, 3)).astype(str)#.round(-1)\n",
    "    # df_ingresos['Grupo_Etario_INDEC'] = pd.cut(df_ingresos.P03, np.array([-1, 13, 29, 64, 110])).astype(str)#.round(-1)\n",
    "    # df_ingresos['Grupo_Etario_q10'] = pd.cut(df_ingresos.P03, np.array([-0.001, 5.0,  11.0, 17.0, 23.0, 29.0, 36.0, 44.0, 53.0, 65.0, 110.0])).astype(str)#.round(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ingresos_a_pobreza(df_ingresos, filename, columnas_pesos = ['P47T']):\n",
    "\n",
    "    df_ingresos[columnas_pesos] = np.power(10, df_ingresos[columnas_pesos]) - 1\n",
    "    \n",
    "    # Editar columnas:\n",
    "    ## Nivel Educativo\n",
    "    df_ingresos['P10'] = 2 - df_ingresos['P10']  ## Re codificacion de pregunta 'termino el nivel'\n",
    "    df_ingresos['P09'] = df_ingresos.P09.replace(5, 4) # Polimodal tomado como secundario \n",
    "    df_ingresos['P0910'] = df_ingresos.P09.astype(str) + df_ingresos.P10.astype(str)\n",
    "    \n",
    "    ## Grupos Etarios\n",
    "    df_ingresos['Grupo_Etario_3'] = pd.cut(df_ingresos.P03, np.arange(-1, 80, 3)).astype(str)#.round(-1)\n",
    "    df_ingresos['Grupo_Etario_INDEC'] = pd.cut(df_ingresos.P03, np.array([-1, 13, 29, 64, 110])).astype(str)#.round(-1)\n",
    "    df_ingresos['Grupo_Etario_q10'] = pd.cut(df_ingresos.P03, np.array([-0.001, 5.0,  11.0, 17.0, 23.0, 29.0, 36.0, 44.0, 53.0, 65.0, 110.0])).astype(str)#.round(-1)\n",
    "    # df = pd.read_csv('file.csv', dtype={'Col' : 'category'}) # Despues podemos necesitar...\n",
    "\n",
    "    df = df_ingresos.reset_index()\n",
    "\n",
    "    ## CANASTA: Datos mergeado con adulto equivalente, region y serie de tiempo canasta\n",
    "    df_cb = df_ingresos.merge(ad_eq).merge(DPTO_Region).merge(CB_ipc)#.merge(ppp_defl[['Q', 'ppp_5usd_ARS_deflac']])\n",
    "    df_cb['CBA'] = df_cb['CBA']*df_cb['CB_EQUIV']  ## Con este paso el valor de canasta de una persona YA INCORPORA EL AD EQ\n",
    "    df_cb['CBT'] = df_cb['CBT']*df_cb['CB_EQUIV']  ## Con este paso el valor de canasta de una persona YA INCORPORA EL AD EQ\n",
    "\n",
    "    ## VARIABLES A NIVEL HOGARES\n",
    "#     df_cb_hogares = df_cb.groupby(['HOGAR_REF_ID', 'Q'])[['P47T','CBA', 'CBT', 'CB_EQUIV', 'ppp_5usd_ARS_deflac']].sum()\n",
    "    df_cb_hogares = df_cb.groupby(['HOGAR_REF_ID', 'Q'])[['P47T','CBA', 'CBT', 'CB_EQUIV']].sum()\n",
    "    df_cb_hogares['Pobreza'] = df_cb_hogares['P47T'] < df_cb_hogares['CBT']\n",
    "    df_cb_hogares['Indigencia'] = df_cb_hogares['P47T'] < df_cb_hogares['CBA']\n",
    "#     df_cb_hogares['Pobreza_5usd'] = df_cb_hogares['P47T'] < df_cb_hogares['ppp_5usd_ARS_deflac']\n",
    "#     pobreza_hogares = df_cb_hogares[['P47T','CBA','CBT', 'CB_EQUIV','Pobreza', 'Indigencia', 'Pobreza_5usd']].reset_index()\n",
    "    pobreza_hogares = df_cb_hogares[['P47T','CBA','CBT', 'CB_EQUIV','Pobreza', 'Indigencia']].reset_index()\n",
    "    pobreza_hogares['gap_pobreza'] = pobreza_hogares.P47T - pobreza_hogares.CBT\n",
    "    pobreza_hogares['gap_indigencia'] = pobreza_hogares.P47T - pobreza_hogares.CBA\n",
    "    pobreza_hogares = pobreza_hogares.rename(columns = {'P47T': 'P47T_hogar'})\n",
    "\n",
    "    ## UNION DE DATOS DE HOGARES A REGISTROS INDIVIDUALES\n",
    "    data = df_ingresos.merge(pobreza_hogares, on = ['HOGAR_REF_ID', 'Q'])#, how = 'left')\n",
    "    del df; del pobreza_hogares # Ahorrar memoria\n",
    "    data = data.rename(columns = {'P47T': 'P47T_persona'}) # Renombrar la variable P47T para aclarar que es a nivel persona.\n",
    "\n",
    "    ## UNIR INFO GEOGRAFICA\n",
    "    data = data.merge(radio_ref[['RADIO_REF_ID', 'IDFRAC', 'PROV', 'NOMPROV', 'AGLOMERADO', 'Region']].drop_duplicates())\n",
    "\n",
    "    n_q = data.Q.nunique()\n",
    "    print(\"Poblacion: \"+str(len(data)/frac/n_q))\n",
    "#     display(data[['Pobreza', 'Indigencia', 'Pobreza_5usd']].mean())\n",
    "    data.to_csv(filename, index = False) ## Aca si ya existen no deberian sobreescribirse (o si)\n",
    "    \n",
    "    print(filename+' saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/matias/Elements/suite/resultados/RFReg_0.01_2015-02-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2015-05-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2016-05-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2016-08-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2016-11-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2017-02-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2017-05-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2017-08-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2017-11-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2018-02-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2018-05-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2018-08-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2018-11-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2019-02-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2019-05-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2019-08-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2019-11-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2020-02-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2020-05-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2020-08-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2020-11-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2021-02-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2021-05-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2021-08-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2021-11-15_ARG.csv',\n",
       " '/media/matias/Elements/suite/resultados/RFReg_0.01_2022-02-15_ARG.csv']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# path ='./data/RFReg_' # use your path\n",
    "# path ='./../../encuestador-de-hogares/data/yr_samples/RFReg_' # use your path\n",
    "path ='/media/matias/Elements/suite/resultados/RFReg_'\n",
    "\n",
    "allFiles = []\n",
    "for year in [str(s) for s in range(2003, 2024)]:\n",
    "    allFiles += glob.glob(path +str(frac)+ '*'+str(year)+'*_ARG.csv')\n",
    "    # Estos son los archivos que se usan para tener una figura estatica, corte donde no importa evol. temporal.\n",
    "\n",
    "allFiles = sorted(allFiles) # ultimo anio\n",
    "allFiles\n",
    "\n",
    "# '/media/matias/Elements/suite/resultados/RFReg_0.01_2017-11-15_ARG.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            'X_data': pd.concat([X_q, result1, result2, result3], axis=1),\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Resultados estaticos (se toma 1 aÃ±o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-2022'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# years = np.unique([int(f[-14:-10]) for f in  allFiles])\n",
    "\n",
    "recentFiles = allFiles[-4:]\n",
    "qstrings = np.unique([Path(f).name.split('_')[-2] for f in  recentFiles[-4:]])\n",
    "ystrings = np.unique([Path(f).name.split('_')[-2].split('-')[0] for f in  recentFiles[-4:]])\n",
    "years = [int(y) for y in ystrings]\n",
    "years\n",
    "if len(years) == 1:\n",
    "    yr_label = str(years[0])\n",
    "else:\n",
    "    yr_label = '-'.join([str(years[0]), str(years[-1])])\n",
    "    \n",
    "yr_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: ['INGRESO', 'P02', 'PP07K', 'IX_TOT', 'HOGAR_REF_ID', 'URP', 'P10', 'RADIO_REF_ID', 'CAT_INAC', 'INGRESO_JUB', 'PERSONA_REF_ID', 'INGRESO_NLB', 'INGRESO_SBS', 'H15', 'H16', 'P09', 'CONDACT', 'DPTO', 'P03', 'CAT_OCUP']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m df_parts \u001b[39m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m quarter_Xy_file \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(recentFiles):\u001b[39m# ultimo anio\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     df_Q \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(quarter_Xy_file, \n\u001b[1;32m      5\u001b[0m                            usecols \u001b[39m=\u001b[39;49m [\u001b[39m'\u001b[39;49m\u001b[39mPERSONA_REF_ID\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mHOGAR_REF_ID\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mRADIO_REF_ID\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mCONDACT\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mCAT_INAC\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mCAT_OCUP\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m                                       \u001b[39m'\u001b[39;49m\u001b[39mINGRESO\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mINGRESO_NLB\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mINGRESO_JUB\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mINGRESO_SBS\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mPP07K\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m                                       \u001b[39m'\u001b[39;49m\u001b[39mIX_TOT\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mH16\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mH15\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mP47T\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mP03\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mP02\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mP09\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mP10\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mDPTO\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mURP\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      9\u001b[0m     df_Q[\u001b[39m'\u001b[39m\u001b[39mANO4\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(Path(quarter_Xy_file)\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m])\n\u001b[1;32m     10\u001b[0m     q \u001b[39m=\u001b[39m Path(quarter_Xy_file)\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]; \u001b[39mprint\u001b[39m(q)\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1676\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1678\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1679\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1680\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1681\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:140\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_names \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols_dtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mset\u001b[39m(usecols)\u001b[39m.\u001b[39missubset(\n\u001b[1;32m    138\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_names\n\u001b[1;32m    139\u001b[0m ):\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_usecols_names(usecols, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49morig_names)\n\u001b[1;32m    142\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames) \u001b[39m>\u001b[39m \u001b[39mlen\u001b[39m(usecols):  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py:958\u001b[0m, in \u001b[0;36mParserBase._validate_usecols_names\u001b[0;34m(self, usecols, names)\u001b[0m\n\u001b[1;32m    956\u001b[0m missing \u001b[39m=\u001b[39m [c \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m usecols \u001b[39mif\u001b[39;00m c \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m names]\n\u001b[1;32m    957\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 958\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    959\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsecols do not match columns, columns expected but not found: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmissing\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    961\u001b[0m     )\n\u001b[1;32m    963\u001b[0m \u001b[39mreturn\u001b[39;00m usecols\n",
      "\u001b[0;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['INGRESO', 'P02', 'PP07K', 'IX_TOT', 'HOGAR_REF_ID', 'URP', 'P10', 'RADIO_REF_ID', 'CAT_INAC', 'INGRESO_JUB', 'PERSONA_REF_ID', 'INGRESO_NLB', 'INGRESO_SBS', 'H15', 'H16', 'P09', 'CONDACT', 'DPTO', 'P03', 'CAT_OCUP']"
     ]
    }
   ],
   "source": [
    "### Dataset Ultimo anio\n",
    "df_parts = []\n",
    "for quarter_Xy_file in sorted(recentFiles):# ultimo anio\n",
    "    df_Q = pd.read_csv(quarter_Xy_file, \n",
    "                           usecols = ['PERSONA_REF_ID', 'HOGAR_REF_ID','RADIO_REF_ID', 'CONDACT', 'CAT_INAC', 'CAT_OCUP',\n",
    "                                      'INGRESO', 'INGRESO_NLB', 'INGRESO_JUB', 'INGRESO_SBS', 'PP07K',\n",
    "                                      'IX_TOT', 'H16', 'H15','P47T', 'P03','P02', 'P09','P10', 'DPTO', 'URP'])\n",
    "    \n",
    "    df_Q['ANO4'] = int(Path(quarter_Xy_file).name.split('_')[-2].split('-')[0])\n",
    "    q = Path(quarter_Xy_file).name.split('_')[-2]; print(q)\n",
    "    df_Q['Q'] = q\n",
    "    df_parts += [df_Q]\n",
    "\n",
    "df = pd.concat(df_parts)\n",
    "del df_Q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computar Pobreza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poblacion: 45383225.0\n",
      "/media/miglesia/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_0.01_2021-2022.csv saved\n"
     ]
    }
   ],
   "source": [
    "filename = '/media/matias/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_'+'_'.join([str(frac), yr_label])+'.csv'\n",
    "\n",
    "ingresos_a_pobreza(df_ingresos = df, filename = filename, columnas_pesos = ['P47T'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Resultados semestre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files =  ['/media/matias/Elements/suite/yr_samples/RFReg_0.01_2021-08-15_ARG.csv',\n",
    " '/media/matias/Elements/suite/yr_samples/RFReg_0.01_2021-11-15_ARG.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-15\n",
      "2021-11-15\n"
     ]
    }
   ],
   "source": [
    "df_parts = []\n",
    "for quarter_Xy_file in sorted(files):# ultimo anio\n",
    "    df_Q = pd.read_csv(quarter_Xy_file, \n",
    "                           usecols = ['PERSONA_REF_ID', 'HOGAR_REF_ID','RADIO_REF_ID', 'CONDACT', 'CAT_INAC', 'CAT_OCUP',\n",
    "                                      'INGRESO', 'INGRESO_NLB', 'INGRESO_JUB', 'INGRESO_SBS', 'PP07K',\n",
    "                                      'IX_TOT', 'H16', 'H15','P47T', 'P03','P02', 'P09','P10', 'DPTO', 'URP'])\n",
    "    \n",
    "    df_Q['ANO4'] = int(Path(quarter_Xy_file).name.split('_')[-2].split('-')[0])\n",
    "    q = Path(quarter_Xy_file).name.split('_')[-2]; print(q)\n",
    "    df_Q['Q'] = q\n",
    "    df_parts += [df_Q]\n",
    "\n",
    "df = pd.concat(df_parts)\n",
    "del df_Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poblacion: 45325100.0\n",
      "/media/miglesia/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_0.01_20212C.csv saved\n"
     ]
    }
   ],
   "source": [
    "label = '20212C'\n",
    "filename = '/media/matias/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_'+'_'.join([str(frac), label])+'.csv'\n",
    "\n",
    "ingresos_a_pobreza(df_ingresos = df, filename = filename, columnas_pesos = ['P47T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(906502, 27)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45325100.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)/frac/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2014-11-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2015-02-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2015-05-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2016-05-15_ARG.csv']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# allFiles[44:48]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resultados series de tiempo (se computa para todos y cada trimestre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-11-15\n",
      "Poblacion: 41934300.0\n",
      "/media/miglesia/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_0.01_q2014-11-15.csv saved\n",
      "2015-02-15\n",
      "Poblacion: 42555200.0\n",
      "/media/miglesia/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_0.01_q2015-02-15.csv saved\n",
      "2015-05-15\n",
      "Poblacion: 42555200.0\n",
      "/media/miglesia/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_0.01_q2015-05-15.csv saved\n",
      "2016-05-15\n",
      "Poblacion: 42890800.0\n",
      "/media/miglesia/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_0.01_q2016-05-15.csv saved\n"
     ]
    }
   ],
   "source": [
    "for quarter_Xy_file in sorted(allFiles):\n",
    "#     if not os.path.exists('./../data/Pobreza/pobreza_'+'_'.join([str(frac), 'q'+q])+'.csv'):\n",
    "\n",
    "    df_Q = pd.read_csv(quarter_Xy_file, \n",
    "                           usecols = ['PERSONA_REF_ID', 'HOGAR_REF_ID','RADIO_REF_ID', 'CONDACT', 'CAT_INAC', 'CAT_OCUP',\n",
    "                                      'INGRESO', 'INGRESO_NLB', 'INGRESO_JUB', 'INGRESO_SBS', 'PP07K',\n",
    "                                      'IX_TOT', 'H16', 'H15','P47T', 'P03','P02', 'P09','P10', 'DPTO', 'URP'])\n",
    "    df_Q['ANO4'] = int(Path(quarter_Xy_file).name.split('_')[-2].split('-')[0])\n",
    "    q = Path(quarter_Xy_file).name.split('_')[-2]; print(q)\n",
    "    df_Q['Q'] = q\n",
    "\n",
    "    ## Computar pobreza\n",
    "    ingresos_a_pobreza(df_ingresos = df_Q, filename = '/media/matias/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_'+'_'.join([str(frac), 'q'+q])+'.csv', columnas_pesos = ['P47T'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
