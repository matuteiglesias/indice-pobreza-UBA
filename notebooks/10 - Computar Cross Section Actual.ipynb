{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Sampleo \"Pesado\" de Censo, para poder tener buena calidad en areas pequenas.\n",
    "\n",
    "### Prediccion en base a modelos. Ultimos 4 trimestres disponibles.\n",
    "\n",
    "### Generar dataset de pobreza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-09-14'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "hoy = datetime.today().strftime('%Y-%m-%d')\n",
    "hoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sampleo Censo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/miglesia/Elements/suite/encuestador-de-hogares/fitted_RF/clf4_2021-05-15_ARG',\n",
       " '/media/miglesia/Elements/suite/encuestador-de-hogares/fitted_RF/clf4_2021-08-15_ARG',\n",
       " '/media/miglesia/Elements/suite/encuestador-de-hogares/fitted_RF/clf4_2021-11-15_ARG',\n",
       " '/media/miglesia/Elements/suite/encuestador-de-hogares/fitted_RF/clf4_2022-02-15_ARG']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "## Trimestres con ingresos disponibles (depende de disponibilidad de microdatos EPH)\n",
    "import glob\n",
    "\n",
    "fuente_modelos = 'encuestador-de-hogares' # \n",
    "modelos_trimestrales = '/media/miglesia/Elements/suite/'+fuente_modelos+'/fitted_RF/clf4_' # use your path\n",
    "\n",
    "allFiles = []\n",
    "allFiles += glob.glob(modelos_trimestrales +'*'+'ARG')\n",
    "allFiles = sorted(allFiles)\n",
    "FilesActual = allFiles[-4:]\n",
    "FilesActual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "qstrings = np.unique([Path(f).name.split('_')[-2] for f in  FilesActual])\n",
    "ystrings = np.unique([Path(f).name.split('_')[-2].split('-')[0] for f in  FilesActual])\n",
    "yrs = [int(y) for y in ystrings]\n",
    "\n",
    "startyr = min(yrs)\n",
    "endyr = max(yrs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./../../samplerCensoARG/'):\n",
    "    !git clone https://github.com/matuteiglesias/samplerCensoARG.git ./../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.02 ## Frac needs to be the fraction used in the sampling (eg. -f 0.01 needs frac = 0.01)\n",
    "\n",
    "sample_tag = 'CSactual'\n",
    "\n",
    "# Comentar si los datasets ya estan calculados\n",
    "# for j in range(2):\n",
    "#     sample_tag = str(10*j).zfill(3)\n",
    "#     print(sample_tag)\n",
    "    \n",
    "# !python ./../../samplerCensoARG/samplear.py -dbp '/media/miglesia/Elements/suite/ext_CPV2010_basico_radio_pub' -f $frac -y $startyr $endyr -n $sample_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-42b8a69ce876>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-42b8a69ce876>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    if not os.exists(out_filename)\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "AGLO_rk = pd.read_csv('./../../encuestador-de-hogares/data/info/AGLO_rk')\n",
    "rk_table = AGLO_rk.set_index(['ANO4', 'AGLOMERADO']).unstack()\n",
    "AGLO_rk_filled = rk_table.fillna(rk_table.mean()).stack().reset_index()\n",
    "AGLO_rk = AGLO_rk_filled\n",
    "\n",
    "Reg_rk = pd.read_csv('./../../encuestador-de-hogares/data/info/Reg_rk')\n",
    "\n",
    "dpto_region = pd.read_csv('./../data/info/DPTO_PROV_Region.csv')\n",
    "\n",
    "# for j in range(2):\n",
    "#     sample_tag = str(10*j).zfill(3)\n",
    "#     print(sample_tag)\n",
    "    \n",
    "for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "    print(yr)\n",
    "    out_filename = '/media/miglesia/Elements/suite/yr_samples/table_f'+str(frac)+'_'+yr+'_'+sample_tag+'.csv'\n",
    "\n",
    "    if not os.exists(out_filename):\n",
    "\n",
    "        table = pd.read_csv('./../../samplerCensoARG/data/censo_samples/table_f'+str(frac)+'_'+yr+'_'+sample_tag+'.csv')\n",
    "        table['ANO4'] = int(yr)\n",
    "\n",
    "        # Adaptamos las categorias de respuestas para que iguales las de la EPH\n",
    "        ## VIVIENDA\n",
    "        table['V01'] = table['V01'].map({1:1, 2:6, 3:6, 4:2, 5:3, 6:4, 7:5, 8:6})\n",
    "        ## HOGAR\n",
    "        table['H06'] = table['H06'].map({1:1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7, 8:9})\n",
    "        table['H09'] = table['H09'].map({1:1, 2:2, 3:3, 4:4, 5:4, 6:4})\n",
    "        table['H16'] = table['H16'].clip(0, 9)\n",
    "        table['H14'] = table['H14'].map({1:1, 2:4, 3:2, 4:2, 5:4, 6:3, 7:4, 8:9})\n",
    "        table['H13'] = table['H13'].map({1:1, 2:2, 4:0})\n",
    "        # PERSONA\n",
    "        table['P07'] = table['P07'].map({1:1, 2:2, 0:2})\n",
    "\n",
    "        ## Agregar Region\n",
    "        table = table.merge(dpto_region[['DPTO', 'Region']])\n",
    "\n",
    "        ## Agregar ranking de Region y Aglo\n",
    "        print(table.shape)\n",
    "        table = table.merge(AGLO_rk[['AGLOMERADO', 'ANO4', 'AGLO_rk']]).merge(Reg_rk[['Region', 'ANO4', 'Reg_rk']])\n",
    "        print(table.shape)\n",
    "\n",
    "        table.to_csv(out_filename, index = False)  # Copias en carpeta yr_samples, en nuestra carpeta de indice de pobreza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Predecir  (X --> y)\n",
    "\n",
    "## Info Empleo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0628729377307203"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empleo = pd.read_csv('https://raw.githubusercontent.com/matuteiglesias/empleoARG/main/datos/45.2_ECTDT.csv')\n",
    "empleo = empleo[['45.2_IT_0_T_13', '45.2_ECTDT_0_T_33']] # ('45.2_ECTDT_0_T_33' es tasa de desocupacion en total aglomerados)\n",
    "empleo['Q'] = pd.to_datetime(empleo['45.2_IT_0_T_13']) + pd.DateOffset(months=1, days = 14)\n",
    "empleo = empleo.set_index('Q').drop(['45.2_IT_0_T_13'], axis = 1)\n",
    "empleo = empleo.replace('s/d', np.nan).astype(float).round(4)\n",
    "empleo['censo2010_ratio'] = (empleo/empleo.loc['2010-11-15'])\n",
    "\n",
    "## notar que la tasa en Aglos, segun el censo, no es igual al valor de la serie de tiempo.\n",
    "# para oct 2010 el censo da (6.29 %) y la que tenemos en dato (7.5%)\n",
    "desoc_C2010 = pd.read_csv('./../data/info/desoc_AGLOsi_C2010.csv')\n",
    "tasa_C2010 = desoc_C2010.loc[desoc_C2010.AGLO_si == True]['Tasa desocupacion'].values[0]\n",
    "tasa_C2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "### Funcion ajustar nivel de empleo\n",
    "\n",
    "def ajustar_empleo(data, verbose = False):\n",
    "\n",
    "        ratio = empleo.loc[pd.to_datetime(q)].censo2010_ratio\n",
    "        n_desempleados_ = ratio*(CONDACT_cnts[1] + CONDACT_cnts[2])*tasa_C2010\n",
    "        desemp_adic = round(n_desempleados_ - CONDACT_cnts.loc[2]) # Desempleados adicionales\n",
    "        \n",
    "        print(str(q)[:10])\n",
    "\n",
    "        if desemp_adic > 0:\n",
    "            data.loc[\n",
    "                data.query('CONDACT == 1').sample(desemp_adic).index,\n",
    "                'CONDACT'\n",
    "            ] = 2\n",
    "        elif desemp_adic < 0:\n",
    "            data.loc[\n",
    "                data.query('CONDACT == 2').sample(- desemp_adic).index,\n",
    "                'CONDACT'\n",
    "            ] = 1\n",
    "\n",
    "        if verbose:\n",
    "            desempleo = data.CONDACT.value_counts().loc[2] / (data.CONDACT.value_counts().loc[1] + data.CONDACT.value_counts().loc[2])\n",
    "            print('desempleo:' + str(desempleo))\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    \n",
    "def predict_save(X_data, x_cols, y_cols, model_filename, out_filename, balance_proba, tag, overwrite = False):\n",
    "\n",
    "        # Si todavia no existe la training data de ese anio, o si la opcion overwrite esta activada:\n",
    "        if (not os.path.exists(out_filename)) or (overwrite): \n",
    "\n",
    "            CLF = joblib.load(model_filename)\n",
    "            \n",
    "            if balance_proba: ## Prediccion usando predict proba y factores de balance.\n",
    "                y_out = pd.DataFrame([])\n",
    "                proba_values = CLF.predict_proba(X_data[x_cols])\n",
    "\n",
    "                ## Leer factores de archivo json\n",
    "                with open('/home/miglesia/repositories/encuestador-de-hogares/data/training/factors/'+tag+'.json', 'r') as file:\n",
    "                    info = json.load(file)\n",
    "                factors_mean = pd.DataFrame(json.loads(info[tag])).stack()\n",
    "                factors_mean.index.names = ['variable', 'valor']\n",
    "                factors_mean.index = factors_mean.index.set_levels(factors_mean.index.levels[1].astype(float).astype(int), level='valor')\n",
    "\n",
    "                for j, y_col in enumerate(y_cols):\n",
    "\n",
    "                    y_probas = pd.DataFrame(proba_values[j], columns = factors_mean.loc[y_col].index.values)\n",
    "                    y_out[y_col] = (y_probas/factors_mean.loc[y_col]).idxmax(1)#.value_counts().sort_index()\n",
    "                \n",
    "            else: ## Prediccion sin balance\n",
    "                y_out = CLF.predict(X_data[x_cols].values)\n",
    "\n",
    "            ## Listo\n",
    "            y_censo_fit = pd.DataFrame(y_out, index = X_data.index, columns=y_cols)\n",
    "            \n",
    "            Xy_censo = pd.concat([X_data, y_censo_fit], axis = 1)\n",
    "\n",
    "#             save\n",
    "            Xy_censo.to_csv(out_filename, index = False)\n",
    "            print('File saved at '+ out_filename)\n",
    "            del X_data; del Xy_censo; del CLF\n",
    "#             gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARGCSactual\n"
     ]
    }
   ],
   "source": [
    "overwrite = False\n",
    "\n",
    "## Elegir el dataset usado como X:\n",
    "frac = '0.02'\n",
    "\n",
    "# models_path = '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza'\n",
    "models_path = '/media/miglesia/Elements/suite/encuestador-de-hogares'\n",
    "\n",
    "balance_proba = False\n",
    "\n",
    "import joblib\n",
    "\n",
    "models_tag = 'ARG'\n",
    "sample_tag = 'CSactual'\n",
    "\n",
    "# for i in range(n_models):\n",
    "#     models_tag = str(i).zfill(3)\n",
    "\n",
    "#     for j in range(2):\n",
    "#         sample_tag = str(10*j).zfill(3)\n",
    "experiment_tag = models_tag + sample_tag\n",
    "\n",
    "print(experiment_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARGCSactual\n",
      "2021\n",
      "['2021-05-15' '2021-08-15' '2021-11-15' '2022-02-15']\n",
      "Nuevo trimestre.\n",
      "2021-05-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-08-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-11-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2022-02-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "2022\n",
      "['2021-05-15' '2021-08-15' '2021-11-15' '2022-02-15']\n",
      "Nuevo trimestre.\n",
      "2021-05-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-08-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-11-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2022-02-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "    print(yr)\n",
    "    file_ = '/media/miglesia/Elements/suite/yr_samples/table_f'+str(frac)+'_'+yr+'_'+sample_tag+'.csv'\n",
    "\n",
    "    X_censo = pd.read_csv(file_, usecols = ['DPTO','RADIO_REF_ID','PERSONA_REF_ID', 'HOGAR_REF_ID','IX_TOT', 'P02', 'P03', 'CONDACT', 'AGLOMERADO', 'URP', 'V01', 'H05', 'H06',\n",
    "           'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14', 'AGLO_rk', 'Reg_rk',\n",
    "           'H13', 'P07', 'P08', 'P09', 'P10', 'P05']).fillna(0)\n",
    "\n",
    "    ## Tratamiento trimestral \n",
    "#             qs = np.array(allqs)[[i for i, si in enumerate(allqs) if si.startswith(yr)]]\n",
    "    qs = np.array(qstrings)[[i for i, si in enumerate(qstrings) if si.startswith(yr)]]\n",
    "    print(qs)\n",
    "\n",
    "    CONDACT_cnts = X_censo.CONDACT.value_counts()\n",
    "\n",
    "#             print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "    ### Cargar modelos de la parte no trimestral (anual).\n",
    "    for q in sorted(qs):\n",
    "\n",
    "        ### AJUSTAR NIVEL DE DESEMPLEO\n",
    "        X_q = X_censo.copy()\n",
    "        X_q['Q'] = q\n",
    "        print('Nuevo trimestre.')\n",
    "\n",
    "        X_q = ajustar_empleo(X_q)\n",
    "\n",
    "        #################################    #################################    #################################\n",
    "\n",
    "        print('C1')\n",
    "        ## CLASIF 1\n",
    "        X_data = X_q;\n",
    "        y_cols1 = ['CAT_OCUP', 'CAT_INAC', 'CH07']\n",
    "        x_cols1 = ['IX_TOT', 'P02', 'P03', 'AGLO_rk', 'Reg_rk', 'V01', 'H05', 'H06',\n",
    "       'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14',\n",
    "       'H13', 'P07', 'P08', 'P09', 'P10', 'P05', 'CONDACT']\n",
    "        out_filename1 = '/media/miglesia/Elements/suite/yr_samples/RFC1_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "        predict_save(X_data,\n",
    "                     x_cols = x_cols1,\n",
    "                     y_cols = y_cols1,\n",
    "                     out_filename = out_filename1,\n",
    "                     model_filename = models_path + '/fitted_RF/clf1_'+yr+'_'+models_tag,\n",
    "                     balance_proba = balance_proba,\n",
    "                     tag = 'clf1_'+yr+'_'+models_tag,\n",
    "                    overwrite = overwrite)\n",
    "\n",
    "        del X_q; del X_data\n",
    "#         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "        #################################    #################################    #################################\n",
    "\n",
    "        print('C2')\n",
    "        ## CLASIF 2\n",
    "        X_data = pd.read_csv(out_filename1)\n",
    "        y_cols2 = ['INGRESO', 'INGRESO_NLB', 'INGRESO_JUB', 'INGRESO_SBS']\n",
    "        x_cols2 = x_cols1 + y_cols1\n",
    "        out_filename2 = '/media/miglesia/Elements/suite/yr_samples/RFC2_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "        predict_save(X_data,\n",
    "                     x_cols = x_cols2,\n",
    "                     y_cols = y_cols2,\n",
    "                     out_filename = out_filename2,\n",
    "                     model_filename = models_path + '/fitted_RF/clf2_'+yr+'_'+models_tag,\n",
    "                     balance_proba = balance_proba,\n",
    "                     tag = 'clf2_'+yr+'_'+models_tag,\n",
    "                    overwrite = overwrite)\n",
    "\n",
    "        del X_data\n",
    "#         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "        #################################    #################################    #################################\n",
    "\n",
    "        print('C3')\n",
    "\n",
    "        ## CLASIF 3\n",
    "        X_data = pd.read_csv(out_filename2)\n",
    "        y_cols3 = ['PP07G1','PP07G_59', 'PP07I', 'PP07J', 'PP07K']\n",
    "        x_cols3 = x_cols2 + y_cols2\n",
    "        out_filename3 = '/media/miglesia/Elements/suite/yr_samples/RFC3_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "        predict_save(X_data,\n",
    "                     x_cols = x_cols3,\n",
    "                     y_cols = y_cols3,\n",
    "                     out_filename = out_filename3,\n",
    "                     model_filename = models_path + '/fitted_RF/clf3_'+yr+'_'+models_tag,\n",
    "                     balance_proba = balance_proba,\n",
    "                     tag = 'clf3_'+yr+'_'+models_tag,\n",
    "                    overwrite = overwrite)\n",
    "        del X_data\n",
    "#         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "        #################################    #################################    #################################\n",
    "\n",
    "\n",
    "        # Columnas de ingresos. Necesitan una regresion...\n",
    "        columnas_pesos = [u'P21', u'P47T', u'PP08D1', u'TOT_P12', u'T_VI', u'V12_M', u'V2_M', u'V3_M', u'V5_M']\n",
    "\n",
    "        x_cols4 = x_cols3 + y_cols3\n",
    "        # Columnas de ingresos. Necesitan una regresion...\n",
    "        predecir4 = columnas_pesos\n",
    "        y_cols4 = predecir4\n",
    "\n",
    "\n",
    "        print('reg')\n",
    "        # REGRESION            \n",
    "        out_filename4 = '/media/miglesia/Elements/suite/yr_samples/RFReg_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "        if (not os.path.exists(out_filename4)) or (overwrite): \n",
    "\n",
    "            ## Cargar Modelo\n",
    "            model_filename4 = models_path + '/fitted_RF/clf4_'+str(q)[:10]+'_'+models_tag\n",
    "    #         filename = '/media/miglesia/Elements/CENSO_dirs/Pobreza/fitted_RF/clf4_0.02_'+str(q)[:10]+'_'+experiment_tag+'.sav'\n",
    "#             clf4 = pickle.load(open(model_filename4+'sav', 'rb'))\n",
    "            clf4 = joblib.load(model_filename4)\n",
    "\n",
    "            Xy3_censo = pd.read_csv(out_filename3)\n",
    "            y_out4 = clf4.predict(Xy3_censo[x_cols4].values); del clf4\n",
    "            y_censo_fit4 = pd.DataFrame(y_out4, index = Xy3_censo.index, columns=predecir4)\n",
    "\n",
    "            Xy4_censo = pd.concat([Xy3_censo, y_censo_fit4], axis = 1)\n",
    "#             save\n",
    "            Xy4_censo.to_csv(out_filename4, index = False)\n",
    "\n",
    "            del Xy4_censo;\n",
    "\n",
    "    del X_censo; #del clf1; del clf2; del clf3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Computar Pobreza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adulto equivalente. Cuanto cuesta la manutencion de las personas segun sexo y edad.\n",
    "ad_eq = pd.read_csv('./../data/info/adulto_eq.csv')\n",
    "\n",
    "#Importar canasta basica regional deflac\n",
    "CB_ipc = pd.read_csv('./../data/info/CB_Reg_defl.csv')\n",
    "radio_ref = pd.read_csv('./../data/info/radio_ref.csv')#.merge(aglo_labels)\n",
    "dpto_region = pd.read_csv('./../data/info/DPTO_PROV_Region.csv')\n",
    "\n",
    "## Fix temporario, migracion a nombres de region oficiales\n",
    "dpto_region['Region'] = dpto_region['Region'].map({'Gran Buenos Aires':'gran_buenos_aires', \n",
    "                                                   'Pampeana':'pampeana', 'Noroeste':'noroeste', \n",
    "                                                   'Noreste':'noreste','PatagÃ³nica': 'patagonia', 'Cuyo': 'cuyo'})\n",
    "\n",
    "radio_ref = radio_ref.merge(dpto_region)\n",
    "# dpto_region = pd.read_csv('./../data/info/DPTO_PROV_Region.csv')\n",
    "DPTO_Region = radio_ref[['DPTO', 'Region']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./../data/Pobreza/'):\n",
    "    os.makedirs('./../data/Pobreza/')\n",
    "\n",
    "frac = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ingresos_a_pobreza(df_ingresos, filename, columnas_pesos = ['P47T']):\n",
    "\n",
    "    df_ingresos[columnas_pesos] = np.power(10, df_ingresos[columnas_pesos]) - 1\n",
    "\n",
    "    df = df_ingresos.reset_index()\n",
    "\n",
    "    ## CANASTA: Datos mergeado con adulto equivalente, region y serie de tiempo canasta\n",
    "    df_cb = df_ingresos.merge(ad_eq).merge(DPTO_Region).merge(CB_ipc)#.merge(ppp_defl[['Q', 'ppp_5usd_ARS_deflac']])\n",
    "    df_cb['CBA'] = df_cb['CBA']*df_cb['CB_EQUIV']  ## Con este paso el valor de canasta de una persona YA INCORPORA EL AD EQ\n",
    "    df_cb['CBT'] = df_cb['CBT']*df_cb['CB_EQUIV']  ## Con este paso el valor de canasta de una persona YA INCORPORA EL AD EQ\n",
    "\n",
    "    ## VARIABLES A NIVEL HOGARES\n",
    "#     df_cb_hogares = df_cb.groupby(['HOGAR_REF_ID', 'Q'])[['P47T','CBA', 'CBT', 'CB_EQUIV', 'ppp_5usd_ARS_deflac']].sum()\n",
    "    df_cb_hogares = df_cb.groupby(['HOGAR_REF_ID', 'Q'])[['P47T','CBA', 'CBT', 'CB_EQUIV']].sum()\n",
    "    df_cb_hogares['Pobreza'] = df_cb_hogares['P47T'] < df_cb_hogares['CBT']\n",
    "    df_cb_hogares['Indigencia'] = df_cb_hogares['P47T'] < df_cb_hogares['CBA']\n",
    "#     df_cb_hogares['Pobreza_5usd'] = df_cb_hogares['P47T'] < df_cb_hogares['ppp_5usd_ARS_deflac']\n",
    "#     pobreza_hogares = df_cb_hogares[['P47T','CBA','CBT', 'CB_EQUIV','Pobreza', 'Indigencia', 'Pobreza_5usd']].reset_index()\n",
    "    pobreza_hogares = df_cb_hogares[['P47T','CBA','CBT', 'CB_EQUIV','Pobreza', 'Indigencia']].reset_index()\n",
    "    pobreza_hogares['gap_pobreza'] = pobreza_hogares.P47T - pobreza_hogares.CBT\n",
    "    pobreza_hogares['gap_indigencia'] = pobreza_hogares.P47T - pobreza_hogares.CBA\n",
    "    pobreza_hogares = pobreza_hogares.rename(columns = {'P47T': 'P47T_hogar'})\n",
    "\n",
    "    ## UNION DE DATOS DE HOGARES A REGISTROS INDIVIDUALES\n",
    "    data = df_ingresos.merge(pobreza_hogares, on = ['HOGAR_REF_ID', 'Q'])#, how = 'left')\n",
    "    del df; del pobreza_hogares # Ahorrar memoria\n",
    "    data = data.rename(columns = {'P47T': 'P47T_persona'}) # Renombrar la variable P47T para aclarar que es a nivel persona.\n",
    "\n",
    "    ## UNIR INFO GEOGRAFICA\n",
    "    data = data.merge(radio_ref[['RADIO_REF_ID', 'IDFRAC', 'PROV', 'NOMPROV', 'AGLOMERADO', 'Region']].drop_duplicates())\n",
    "\n",
    "    n_q = data.Q.nunique()\n",
    "    print(\"Poblacion: \"+str(len(data)/frac/n_q))\n",
    "#     display(data[['Pobreza', 'Indigencia', 'Pobreza_5usd']].mean())\n",
    "    data.to_csv(filename, index = False) ## Aca si ya existen no deberian sobreescribirse (o si)\n",
    "    \n",
    "    print(filename+' saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/miglesia/Elements/suite/yr_samples/RFReg_0.02_2021-05-15_ARGCSactual.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.02_2021-08-15_ARGCSactual.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.02_2021-11-15_ARGCSactual.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.02_2022-02-15_ARGCSactual.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy_trimestrales = '/media/miglesia/Elements/suite/yr_samples/RFReg_'+str(frac)  # use your path\n",
    "\n",
    "allFiles = []\n",
    "allFiles += glob.glob(Xy_trimestrales +'*'+experiment_tag+'.csv')\n",
    "allFiles = sorted(allFiles)\n",
    "CSXyfiles = allFiles[-4:]\n",
    "CSXyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARGCSactual\n",
      "2021-05-15\n",
      "2021-08-15\n",
      "2021-11-15\n",
      "2022-02-15\n",
      "Poblacion: 44435950.0\n",
      "/media/miglesia/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_0.02_ARGCSactual.csv saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(experiment_tag)\n",
    "filename = '/media/miglesia/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_'+'_'.join([str(frac), experiment_tag])+'.csv'\n",
    "\n",
    "df_parts = []\n",
    "for quarter_Xy_file in sorted(CSXyfiles):# ultimo anio\n",
    "    df_Q = pd.read_csv(quarter_Xy_file, \n",
    "                           usecols = ['PERSONA_REF_ID', 'HOGAR_REF_ID','RADIO_REF_ID', 'CONDACT', 'CAT_INAC', 'CAT_OCUP',\n",
    "                                      'INGRESO', 'INGRESO_NLB', 'INGRESO_JUB', 'INGRESO_SBS', 'PP07K',\n",
    "                                      'IX_TOT', 'H16', 'H15','P47T', 'P03','P02', 'P09','P10', 'DPTO', 'URP'])\n",
    "\n",
    "    df_Q['ANO4'] = int(Path(quarter_Xy_file).name.split('_')[-2].split('-')[0])\n",
    "    q = Path(quarter_Xy_file).name.split('_')[-2]; print(q)\n",
    "    df_Q['Q'] = q\n",
    "    df_parts += [df_Q]\n",
    "\n",
    "df = pd.concat(df_parts)\n",
    "del df_Q\n",
    "\n",
    "\n",
    "ingresos_a_pobreza(df_ingresos = df, filename = filename, columnas_pesos = ['P47T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx\n",
    "\n",
    "# Up to here. The rest of the code is on another notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los niveles geograficos disponibles son:\n",
    " - Radios (RADIO_REF_ID)\n",
    " - Fracciones (IDFRAC, no es clave unica)\n",
    " - Dptos (DPTO)\n",
    " - Provs (PROV)\n",
    " - Aglos (AGLOMERADO)\n",
    " - (Region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import seaborn as sns\n",
    ">>> pal = sns.color_palette(\"RdYlGn_r\", 10)\n",
    ">>> print(pal.as_hex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import seaborn as sns\n",
    ">>> pal = sns.color_palette(\"cool\", 10)\n",
    ">>> print(pal.as_hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
