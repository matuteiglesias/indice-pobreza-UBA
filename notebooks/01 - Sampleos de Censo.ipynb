{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On this notebook we extract Censo 2010 individual data from their files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_184550/3391910190.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./../../samplerCensoARG/'):\n",
    "    !git clone https://github.com/matuteiglesias/samplerCensoARG.git ./../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python ./../../samplerCensoARG/samplear.py -dbp '/media/miglesia/Elements/suite/ext_CPV2010_basico_radio_pub' -f 0.01 -y 2005 2006 -n ARG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.read_csv('/home/miglesia/repositories/indice-pobreza-ExactasUBA/notebooks/../data/info/AGLO_rk/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar info accesoria (Regiones, aglomerados, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "radio_ref = pd.read_csv('./../data/info/radio_ref.csv')\n",
    "\n",
    "radio_AGLO = pd.read_csv('https://raw.githubusercontent.com/matuteiglesias/Aglomerados-EPH-INDEC/main/result/radios_aglo_EPH.csv')\n",
    "radio_AGLO['radio'] = radio_AGLO.COD_2010.str.replace('XX', '99').astype(int)\n",
    "radio_AGLO['AGLOMERADO'] = radio_AGLO.eph_codagl\n",
    "radio_AGLO['NOMAGLO'] = radio_AGLO.eph_aglome\n",
    "\n",
    "radio_ref = radio_ref.drop(['AGLOMERADO'], axis = 1).merge(radio_AGLO[['radio','AGLOMERADO', 'NOMAGLO']], how = 'left')\n",
    "radio_ref['AGLOMERADO'] = radio_ref['AGLOMERADO'].fillna(0).astype(int)\n",
    "\n",
    "# radio_ref[['PROV','NOMPROV','DPTO', 'NOMDPTO']].drop_duplicates().to_csv('./../data/DPTO_PROV.csv', index = False)\n",
    "dpto_region = pd.read_csv('./../data/info/DPTO_PROV_Region.csv')\n",
    "radio_ref = radio_ref.merge(dpto_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AGLO_rk = pd.read_csv('./../../encuestador-de-hogares/data/info/AGLO_rk')\n",
    "rk_table = AGLO_rk.set_index(['ANO4', 'AGLOMERADO']).unstack()\n",
    "AGLO_rk_filled = rk_table.fillna(rk_table.mean()).stack().reset_index()\n",
    "AGLO_rk = AGLO_rk_filled\n",
    "\n",
    "Reg_rk = pd.read_csv('./../../encuestador-de-hogares/data/info/Reg_rk')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop sampleo de censo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VIVIENDA_REF_ID', 'RADIO_REF_ID', 'TIPVV', 'V01', 'URP', 'DPTO',\n",
       "       'PROV', 'AGLOMERADO', 'HOGAR_REF_ID', 'H05', 'H06', 'H07', 'H08', 'H09',\n",
       "       'H10', 'H11', 'H12', 'H13', 'H14', 'H15', 'H16', 'PROP', 'TOTPERS',\n",
       "       'PERSONA_REF_ID', 'P01', 'P02', 'P03', 'P05', 'P06', 'P07', 'P12',\n",
       "       'P08', 'P09', 'P10', 'CONDACT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./../../samplerCensoARG/data/censo_samples/table_f'+str(frac)+'_'+yr+'_ARG.csv', nrows = 5).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n",
      "(423332, 39)\n",
      "(423332, 41)\n",
      "2016\n",
      "(428659, 39)\n",
      "(428659, 41)\n",
      "2017\n",
      "(434438, 39)\n",
      "(434438, 41)\n",
      "2018\n",
      "(438092, 39)\n",
      "(438092, 41)\n",
      "2019\n",
      "(444062, 39)\n",
      "(444062, 41)\n",
      "2020\n",
      "(447885, 39)\n",
      "(447885, 41)\n",
      "2021\n",
      "(452673, 39)\n",
      "(452673, 41)\n",
      "2022\n",
      "(454792, 39)\n",
      "(454792, 41)\n",
      "2023\n",
      "(458153, 39)\n",
      "(0, 41)\n"
     ]
    }
   ],
   "source": [
    "frac = 0.01 ## Frac needs to be the fraction used in the sampling (eg. -f 0.01 needs frac = 0.01)\n",
    "startyr = 2015\n",
    "endyr = 2024\n",
    "\n",
    "for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "    print(yr)\n",
    "    table = pd.read_csv('./../../samplerCensoARG/data/censo_samples/table_f'+str(frac)+'_'+yr+'_ARG.csv')\n",
    "    table['ANO4'] = int(yr)\n",
    "    \n",
    "    # Adaptamos las categorias de respuestas para que iguales las de la EPH\n",
    "    ## VIVIENDA\n",
    "    table['V01'] = table['V01'].map({1:1, 2:6, 3:6, 4:2, 5:3, 6:4, 7:5, 8:6})\n",
    "    ## HOGAR\n",
    "    table['H06'] = table['H06'].map({1:1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7, 8:9})\n",
    "    table['H09'] = table['H09'].map({1:1, 2:2, 3:3, 4:4, 5:4, 6:4})\n",
    "    table['H16'] = table['H16'].clip(0, 9)\n",
    "    table['H14'] = table['H14'].map({1:1, 2:4, 3:2, 4:2, 5:4, 6:3, 7:4, 8:9})\n",
    "    table['H13'] = table['H13'].map({1:1, 2:2, 4:0})\n",
    "    table['IX_TOT'] = table['TOTPERS']\n",
    "    # PERSONA\n",
    "    table['P07'] = table['P07'].map({1:1, 2:2, 0:2})\n",
    "\n",
    "    ## Agregar Region\n",
    "    table = table.merge(dpto_region[['DPTO', 'Region']])\n",
    "\n",
    "    ## ID DE PERSONAS SIMULADAS:\n",
    "    # Semilla ids\n",
    "    file_size = os.path.getsize('./../../samplerCensoARG/data/censo_samples/table_f'+str(frac)+'_'+yr+'_ARG.csv')\n",
    "    np.random.seed(file_size)\n",
    "\n",
    "    ## Aplicar IDs\n",
    "    # Generate a unique random number for each row in the DataFrame\n",
    "    n_digits = 8; n_rows = len(table)\n",
    "    random_numbers = np.random.randint(10**(n_digits - 1), 10**n_digits, n_rows)\n",
    "    # Extract the last two digits of the year\n",
    "    last_two_digits_year = table['ANO4'].apply(lambda x: int(str(x)[-2:]))\n",
    "    \n",
    "    # unique ID\n",
    "    table.insert(0, 'ID', random_numbers * 100 + last_two_digits_year)\n",
    "\n",
    "    ## Agregar ranking de Region y Aglo\n",
    "    print(table.shape)\n",
    "    table = table.merge(AGLO_rk[['AGLOMERADO', 'ANO4', 'AGLO_rk']]).merge(Reg_rk[['Region', 'ANO4', 'Reg_rk']])\n",
    "    print(table.shape)\n",
    "    \n",
    "    table.to_csv('/media/matias/Elements/suite/poblaciones/table_f'+str(frac)+'_'+yr+'_ARG.csv', index = False)  # Copias en carpeta yr_samples, en nuestra carpeta de indice de pobreza\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'VIVIENDA_REF_ID', 'RADIO_REF_ID', 'TIPVV', 'V01', 'URP', 'DPTO',\n",
       "       'PROV', 'AGLOMERADO', 'HOGAR_REF_ID', 'H05', 'H06', 'H07', 'H08', 'H09',\n",
       "       'H10', 'H11', 'H12', 'H13', 'H14', 'H15', 'H16', 'PROP', 'TOTPERS',\n",
       "       'PERSONA_REF_ID', 'P01', 'P02', 'P03', 'P05', 'P06', 'P07', 'P12',\n",
       "       'P08', 'P09', 'P10', 'CONDACT', 'IX_TOT', 'AGLO_rk', 'Region', 'ANO4',\n",
       "       'Reg_rk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
