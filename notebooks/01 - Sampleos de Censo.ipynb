{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On this notebook we extract Censo 2010 individual data from their files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./../../samplerCensoARG/'):\n",
    "    !git clone https://github.com/matuteiglesias/samplerCensoARG.git ./../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/miglesia/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/home/miglesia/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/home/miglesia/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "['/media/miglesia/Elements/suite/ext_CPV2010_basico_radio_pub']\n",
      "[0.01]\n",
      "['ARG']\n",
      "[2003, 2023]\n",
      "total_pais\n",
      "[                                        ] | 0% Completed |  0.0s^C\n",
      "[                                        ] | 0% Completed |  0.1s\n",
      "Traceback (most recent call last):\n",
      "  File \"./../../samplerCensoARG/samplear.py\", line 90, in <module>\n",
      "    HOGAR_DPTO = HOGAR.merge(VIVIENDA[['VIVIENDA_REF_ID', 'DPTO']]).compute()\n",
      "  File \"/home/miglesia/anaconda3/lib/python3.8/site-packages/dask/base.py\", line 167, in compute\n",
      "    (result,) = compute(self, traverse=False, **kwargs)\n",
      "  File \"/home/miglesia/anaconda3/lib/python3.8/site-packages/dask/base.py\", line 452, in compute\n",
      "    results = schedule(dsk, keys, **kwargs)\n",
      "  File \"/home/miglesia/anaconda3/lib/python3.8/site-packages/dask/threaded.py\", line 76, in get\n",
      "    results = get_async(\n",
      "  File \"/home/miglesia/anaconda3/lib/python3.8/site-packages/dask/local.py\", line 475, in get_async\n",
      "    key, res_info, failed = queue_get(queue)\n",
      "  File \"/home/miglesia/anaconda3/lib/python3.8/site-packages/dask/local.py\", line 133, in queue_get\n",
      "    return q.get()\n",
      "  File \"/home/miglesia/anaconda3/lib/python3.8/queue.py\", line 170, in get\n",
      "    self.not_empty.wait()\n",
      "  File \"/home/miglesia/anaconda3/lib/python3.8/threading.py\", line 302, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python ./../../samplerCensoARG/samplear.py -dbp '/media/miglesia/Elements/suite/ext_CPV2010_basico_radio_pub' -f 0.01 -y 2003 2023 -n ARG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.read_csv('/home/miglesia/repositories/indice-pobreza-ExactasUBA/notebooks/../data/info/AGLO_rk/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar info accesoria (Regiones, aglomerados, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "radio_ref = pd.read_csv('./../data/info/radio_ref.csv')\n",
    "\n",
    "radio_AGLO = pd.read_csv('https://raw.githubusercontent.com/matuteiglesias/Aglomerados-EPH-INDEC/main/result/radios_aglo_EPH.csv')\n",
    "radio_AGLO['radio'] = radio_AGLO.COD_2010.str.replace('XX', '99').astype(int)\n",
    "radio_AGLO['AGLOMERADO'] = radio_AGLO.eph_codagl\n",
    "radio_AGLO['NOMAGLO'] = radio_AGLO.eph_aglome\n",
    "\n",
    "radio_ref = radio_ref.drop(['AGLOMERADO'], axis = 1).merge(radio_AGLO[['radio','AGLOMERADO', 'NOMAGLO']], how = 'left')\n",
    "radio_ref['AGLOMERADO'] = radio_ref['AGLOMERADO'].fillna(0).astype(int)\n",
    "\n",
    "# radio_ref[['PROV','NOMPROV','DPTO', 'NOMDPTO']].drop_duplicates().to_csv('./../data/DPTO_PROV.csv', index = False)\n",
    "dpto_region = pd.read_csv('./../data/info/DPTO_PROV_Region.csv')\n",
    "radio_ref = radio_ref.merge(dpto_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AGLO_rk = pd.read_csv('./../../encuestador-de-hogares/data/info/AGLO_rk')\n",
    "rk_table = AGLO_rk.set_index(['ANO4', 'AGLOMERADO']).unstack()\n",
    "AGLO_rk_filled = rk_table.fillna(rk_table.mean()).stack().reset_index()\n",
    "AGLO_rk = AGLO_rk_filled\n",
    "\n",
    "Reg_rk = pd.read_csv('./../../encuestador-de-hogares/data/info/Reg_rk')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop sampleo de censo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003\n",
      "(364816, 38)\n",
      "(364816, 40)\n",
      "2004\n",
      "(371771, 38)\n",
      "(371771, 40)\n",
      "2005\n",
      "(376756, 38)\n",
      "(376756, 40)\n",
      "2006\n",
      "(381953, 38)\n",
      "(381953, 40)\n",
      "2007\n",
      "(388097, 38)\n",
      "(388097, 40)\n",
      "2008\n",
      "(389856, 38)\n",
      "(389856, 40)\n",
      "2009\n",
      "(399102, 38)\n",
      "(399102, 40)\n",
      "2010\n",
      "(399704, 38)\n",
      "(399704, 40)\n",
      "2011\n",
      "(404363, 38)\n",
      "(404363, 40)\n",
      "2012\n",
      "(411680, 38)\n",
      "(411680, 40)\n",
      "2013\n",
      "(415168, 38)\n",
      "(415168, 40)\n",
      "2014\n",
      "(419343, 38)\n",
      "(419343, 40)\n",
      "2015\n",
      "(425552, 38)\n",
      "(425552, 40)\n",
      "2016\n",
      "(428908, 38)\n",
      "(428908, 40)\n",
      "2017\n",
      "(435315, 38)\n",
      "(435315, 40)\n",
      "2018\n",
      "(435109, 38)\n",
      "(435109, 40)\n",
      "2019\n",
      "(441375, 38)\n",
      "(441375, 40)\n",
      "2020\n",
      "(446156, 38)\n",
      "(446156, 40)\n",
      "2021\n",
      "(453251, 38)\n",
      "(453251, 40)\n",
      "2022\n",
      "(455576, 38)\n",
      "(0, 40)\n"
     ]
    }
   ],
   "source": [
    "frac = 0.01 ## Frac needs to be the fraction used in the sampling (eg. -f 0.01 needs frac = 0.01)\n",
    "startyr = 2003\n",
    "endyr = 2023\n",
    "\n",
    "for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "    print(yr)\n",
    "    table = pd.read_csv('./../../samplerCensoARG/data/censo_samples/table_f'+str(frac)+'_'+yr+'_ARG.csv')\n",
    "    table['ANO4'] = int(yr)\n",
    "    \n",
    "    # Adaptamos las categorias de respuestas para que iguales las de la EPH\n",
    "    ## VIVIENDA\n",
    "    table['V01'] = table['V01'].map({1:1, 2:6, 3:6, 4:2, 5:3, 6:4, 7:5, 8:6})\n",
    "    ## HOGAR\n",
    "    table['H06'] = table['H06'].map({1:1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7, 8:9})\n",
    "    table['H09'] = table['H09'].map({1:1, 2:2, 3:3, 4:4, 5:4, 6:4})\n",
    "    table['H16'] = table['H16'].clip(0, 9)\n",
    "    table['H14'] = table['H14'].map({1:1, 2:4, 3:2, 4:2, 5:4, 6:3, 7:4, 8:9})\n",
    "    table['H13'] = table['H13'].map({1:1, 2:2, 4:0})\n",
    "    # PERSONA\n",
    "    table['P07'] = table['P07'].map({1:1, 2:2, 0:2})\n",
    "\n",
    "    ## Agregar Region\n",
    "    table = table.merge(dpto_region[['DPTO', 'Region']])\n",
    "\n",
    "    ## Agregar ranking de Region y Aglo\n",
    "    print(table.shape)\n",
    "    table = table.merge(AGLO_rk[['AGLOMERADO', 'ANO4', 'AGLO_rk']]).merge(Reg_rk[['Region', 'ANO4', 'Reg_rk']])\n",
    "    print(table.shape)\n",
    "    \n",
    "    table.to_csv('/media/miglesia/Elements/suite/yr_samples/table_f'+str(frac)+'_'+yr+'_ARG.csv', index = False)  # Copias en carpeta yr_samples, en nuestra carpeta de indice de pobreza\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
