{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estocasticidad\n",
    "\n",
    "**En esta notebook se repiten**\n",
    "\n",
    "- Entrenamiento de modelos \n",
    "- Sampleos de Censo\n",
    "\n",
    "Con el objetivo de evaluar la variabilidad por factores aleatorios en resultados de:\n",
    "    \n",
    "    - Pobreza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "startyr = 2019\n",
    "endyr = 2020\n",
    "\n",
    "# Column names\n",
    "y_cols = ['CAT_OCUP', 'P47T', 'PP10E', 'PP10D', 'PP07K', 'PP07I', 'V3_M', 'PP07G4', 'CH16', 'T_VI', \n",
    "          'V12_M', 'TOT_P12', 'PP07G3', 'V5_M', 'PP07H', 'V2_M', 'PP10C', \n",
    "          'PP08D1', 'PP07J', 'CAT_INAC', 'CH07', 'CH08', 'P21', 'PP07G1', 'PP07G_59', 'PP07G2']\n",
    "\n",
    "x_cols1 = ['IX_TOT', 'P02', 'P03', 'AGLO_rk', 'Reg_rk', 'V01', 'H05', 'H06',\n",
    "       'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14',\n",
    "       'H13', 'P07', 'P08', 'P09', 'P10', 'P05', 'CONDACT']\n",
    "\n",
    "predecir1 = ['CAT_OCUP', 'CAT_INAC', 'CH07']\n",
    "\n",
    "x_cols2 = x_cols1 + predecir1\n",
    "predecir2 = ['INGRESO', 'INGRESO_NLB', 'INGRESO_JUB', 'INGRESO_SBS']\n",
    "\n",
    "x_cols3 = x_cols2 + predecir2\n",
    "# La seccion PP07G pregunta si el trabajo es en blanco y que beneficios tiene. Puede ayudar a la regresion para ingresos.\n",
    "# predecir3 = ['PP07G1', 'PP07G2', 'PP07G3', 'PP07G4', 'PP07G_59', 'PP07H', 'PP07I', 'PP07J', 'PP07K']\n",
    "predecir3 = ['PP07G1','PP07G_59', 'PP07I', 'PP07J', 'PP07K']\n",
    "\n",
    "# Columnas de ingresos. Necesitan una regresion...\n",
    "columnas_pesos = [u'P21', u'P47T', u'PP08D1', u'TOT_P12', u'T_VI', u'V12_M', u'V2_M', u'V3_M', u'V5_M']\n",
    "\n",
    "x_cols4 = x_cols3 + predecir3\n",
    "# Columnas de ingresos. Necesitan una regresion...\n",
    "predecir4 = columnas_pesos\n",
    "y_cols4 = predecir4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save models at: (ocupan bastante memoria en disco)\n",
    "models_path = '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "def fit_model(train_data, x_cols, y_cols, out_filename,\n",
    "             model):\n",
    "    X = train_data[x_cols]\n",
    "    y = train_data[y_cols]\n",
    "    \n",
    "    X, X_test, y, y_test = train_test_split(X, y, test_size=0.1) # less memory used\n",
    "    \n",
    "    clf = model.fit(X.values, y.values)\n",
    "\n",
    "    # save the model to disk\n",
    "    if not os.path.exists(models_path + '/fitted_RF/'):\n",
    "        os.makedirs(models_path + '/fitted_RF/')\n",
    "    joblib.dump(model, out_filename, compress=3)\n",
    "    print('saved model at: ' + out_filename)\n",
    "\n",
    "#     print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "    del clf\n",
    "    del X; del y # liberar memoria eliminando los dataframes mas pesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import log10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000\n",
      "2019\n",
      "2019-11-15\n",
      "2019-08-15\n",
      "2019-05-15\n",
      "2019-02-15\n",
      "001\n",
      "2019\n",
      "2019-11-15\n",
      "2019-08-15\n",
      "2019-05-15\n",
      "2019-02-15\n",
      "002\n",
      "2019\n",
      "2019-11-15\n",
      "2019-08-15\n",
      "2019-05-15\n",
      "2019-02-15\n",
      "003\n",
      "2019\n",
      "2019-11-15\n",
      "2019-08-15\n",
      "2019-05-15\n",
      "2019-02-15\n",
      "004\n",
      "2019\n",
      "2019-11-15\n",
      "2019-08-15\n",
      "2019-05-15\n",
      "2019-02-15\n"
     ]
    }
   ],
   "source": [
    "training_sets_path = './../../encuestador-de-hogares/data/training/'\n",
    "\n",
    "n_models = 5\n",
    "\n",
    "for i in range(n_models):\n",
    "    models_tag = str(i).zfill(3)\n",
    "    print(models_tag)\n",
    "\n",
    "    for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "        print(yr)\n",
    "        train_data = pd.read_csv(training_sets_path + 'EPHARG_train_'+yr[2:]+'.csv')\n",
    "\n",
    "        ## ETAPA 1:\n",
    "        out = models_path + '/fitted_RF/clf1_'+yr+'_'+models_tag\n",
    "        if (not os.path.exists(out)) or (overwrite):\n",
    "            fit_model(train_data, x_cols = x_cols1, y_cols = predecir1, out_filename = out,\n",
    "                     model = RandomForestClassifier(n_estimators=100, max_depth = 20, n_jobs = -1))\n",
    "\n",
    "        ## ETAPA 2:\n",
    "        out = models_path + '/fitted_RF/clf2_'+yr+'_'+models_tag\n",
    "        if (not os.path.exists(out)) or (overwrite):\n",
    "            fit_model(train_data, x_cols = x_cols2, y_cols = predecir2, out_filename = out,\n",
    "                     model = RandomForestClassifier(n_estimators=100, max_depth = 20, n_jobs = -1))\n",
    "\n",
    "        ## ETAPA 3:\n",
    "        out = models_path + '/fitted_RF/clf3_'+yr+'_'+models_tag\n",
    "        if (not os.path.exists(out)) or (overwrite):\n",
    "            fit_model(train_data, x_cols = x_cols3, y_cols = predecir3, out_filename = out,\n",
    "                     model = RandomForestClassifier(n_estimators=100, max_depth = 20, n_jobs = -1))\n",
    "\n",
    "        ## ETAPA 4 (Regresion)\n",
    "        ## Tomar log de las columnas en pesos.\n",
    "        train_data[columnas_pesos] = log10(train_data[columnas_pesos].clip(-.9) + 1)\n",
    "\n",
    "        ## Entrenar modelo, para cada trimestre\n",
    "        for q in train_data.Q.unique():\n",
    "            print(q)\n",
    "            out = models_path + '/fitted_RF/clf4_'+q+'_'+models_tag\n",
    "            if (not os.path.exists(out)) or (overwrite):\n",
    "                train_q = train_data.loc[train_data.Q == q]\n",
    "                fit_model(train_q, x_cols = x_cols4, y_cols = y_cols4, out_filename = out,\n",
    "                         model = RandomForestRegressor(n_estimators=1, max_depth = 40, n_jobs = -1))\n",
    "                del train_q;\n",
    "\n",
    "        del train_data; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sampleo Censo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./../../samplerCensoARG/'):\n",
    "    !git clone https://github.com/matuteiglesias/samplerCensoARG.git ./../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar info accesoria (Regiones, aglomerados, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radio_ref = pd.read_csv('./../data/info/radio_ref.csv')\n",
    "\n",
    "# radio_AGLO = pd.read_csv('https://raw.githubusercontent.com/matuteiglesias/Aglomerados-EPH-INDEC/main/result/radios_aglo_EPH.csv')\n",
    "# radio_AGLO['radio'] = radio_AGLO.COD_2010.str.replace('XX', '99').astype(int)\n",
    "# radio_AGLO['AGLOMERADO'] = radio_AGLO.eph_codagl\n",
    "# radio_AGLO['NOMAGLO'] = radio_AGLO.eph_aglome\n",
    "\n",
    "# radio_ref = radio_ref.drop(['AGLOMERADO'], axis = 1).merge(radio_AGLO[['radio','AGLOMERADO', 'NOMAGLO']], how = 'left')\n",
    "# radio_ref['AGLOMERADO'] = radio_ref['AGLOMERADO'].fillna(0).astype(int)\n",
    "\n",
    "# # radio_ref[['PROV','NOMPROV','DPTO', 'NOMDPTO']].drop_duplicates().to_csv('./../data/DPTO_PROV.csv', index = False)\n",
    "# dpto_region = pd.read_csv('./../data/info/DPTO_PROV_Region.csv')\n",
    "# radio_ref = radio_ref.merge(dpto_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AGLO_rk = pd.read_csv('./../../encuestador-de-hogares/data/info/AGLO_rk')\n",
    "rk_table = AGLO_rk.set_index(['ANO4', 'AGLOMERADO']).unstack()\n",
    "AGLO_rk_filled = rk_table.fillna(rk_table.mean()).stack().reset_index()\n",
    "AGLO_rk = AGLO_rk_filled\n",
    "\n",
    "Reg_rk = pd.read_csv('./../../encuestador-de-hogares/data/info/Reg_rk')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop sampleo de censo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.01 ## Frac needs to be the fraction used in the sampling (eg. -f 0.01 needs frac = 0.01)\n",
    "startyr = 2019\n",
    "endyr = 2020\n",
    "\n",
    "# # Comentar si los datasets ya estan calculados\n",
    "# for j in range(2):\n",
    "#     sample_tag = str(10*j).zfill(3)\n",
    "#     print(sample_tag)\n",
    "    \n",
    "#     !python ./../../samplerCensoARG/samplear.py -dbp '/media/miglesia/Elements/suite/ext_CPV2010_basico_radio_pub' -f $frac -y $startyr $endyr -n $sample_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpto_region = pd.read_csv('./../data/info/DPTO_PROV_Region.csv')\n",
    "# ## Fix temporario, migracion a nombres de region oficiales\n",
    "# dpto_region['Region'] = dpto_region['Region'].map({'Gran Buenos Aires':'gran_buenos_aires', \n",
    "#                                                    'Pampeana':'pampeana', 'Noroeste':'noroeste', \n",
    "#                                                    'Noreste':'noreste','Patagónica': 'patagonia', 'Cuyo': 'cuyo'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000\n",
      "2019\n",
      "(439319, 38)\n",
      "(439319, 40)\n",
      "010\n",
      "2019\n",
      "(439083, 38)\n",
      "(439083, 40)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for j in range(2):\n",
    "    sample_tag = str(10*j).zfill(3)\n",
    "    print(sample_tag)\n",
    "    \n",
    "    for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "        print(yr)\n",
    "        table = pd.read_csv('./../../samplerCensoARG/data/censo_samples/table_f'+str(frac)+'_'+yr+'_'+sample_tag+'.csv')\n",
    "        table['ANO4'] = int(yr)\n",
    "\n",
    "        # Adaptamos las categorias de respuestas para que iguales las de la EPH\n",
    "        ## VIVIENDA\n",
    "        table['V01'] = table['V01'].map({1:1, 2:6, 3:6, 4:2, 5:3, 6:4, 7:5, 8:6})\n",
    "        ## HOGAR\n",
    "        table['H06'] = table['H06'].map({1:1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7, 8:9})\n",
    "        table['H09'] = table['H09'].map({1:1, 2:2, 3:3, 4:4, 5:4, 6:4})\n",
    "        table['H16'] = table['H16'].clip(0, 9)\n",
    "        table['H14'] = table['H14'].map({1:1, 2:4, 3:2, 4:2, 5:4, 6:3, 7:4, 8:9})\n",
    "        table['H13'] = table['H13'].map({1:1, 2:2, 4:0})\n",
    "        # PERSONA\n",
    "        table['P07'] = table['P07'].map({1:1, 2:2, 0:2})\n",
    "\n",
    "        ## Agregar Region\n",
    "        table = table.merge(dpto_region[['DPTO', 'Region']])\n",
    "\n",
    "        ## Agregar ranking de Region y Aglo\n",
    "        print(table.shape)\n",
    "        table = table.merge(AGLO_rk[['AGLOMERADO', 'ANO4', 'AGLO_rk']]).merge(Reg_rk[['Region', 'ANO4', 'Reg_rk']])\n",
    "        print(table.shape)\n",
    "\n",
    "        table.to_csv('/media/miglesia/Elements/suite/yr_samples/table_f'+str(frac)+'_'+yr+'_'+sample_tag+'.csv', index = False)  # Copias en carpeta yr_samples, en nuestra carpeta de indice de pobreza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predecir  (X --> y)\n",
    "\n",
    "## Info Empleo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0628729377307203"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empleo = pd.read_csv('https://raw.githubusercontent.com/matuteiglesias/empleoARG/main/datos/45.2_ECTDT.csv')\n",
    "empleo = empleo[['45.2_IT_0_T_13', '45.2_ECTDT_0_T_33']] # ('45.2_ECTDT_0_T_33' es tasa de desocupacion en total aglomerados)\n",
    "empleo['Q'] = pd.to_datetime(empleo['45.2_IT_0_T_13']) + pd.DateOffset(months=1, days = 14)\n",
    "empleo = empleo.set_index('Q').drop(['45.2_IT_0_T_13'], axis = 1)\n",
    "empleo = empleo.replace('s/d', np.nan).astype(float).round(4)\n",
    "empleo['censo2010_ratio'] = (empleo/empleo.loc['2010-11-15'])\n",
    "\n",
    "## notar que la tasa en Aglos, segun el censo, no es igual al valor de la serie de tiempo.\n",
    "# para oct 2010 el censo da (6.29 %) y la que tenemos en dato (7.5%)\n",
    "desoc_C2010 = pd.read_csv('./../data/info/desoc_AGLOsi_C2010.csv')\n",
    "tasa_C2010 = desoc_C2010.loc[desoc_C2010.AGLO_si == True]['Tasa desocupacion'].values[0]\n",
    "tasa_C2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-02-15_003',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-02-15_004',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-05-15_000',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-05-15_001',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-05-15_002',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-05-15_003',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-05-15_004',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-08-15_000',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-08-15_001',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-08-15_002',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-08-15_003',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-08-15_004',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-11-15_000',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-11-15_001',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-11-15_002',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-11-15_003',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-11-15_004',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-02-15_000',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-02-15_001',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-02-15_002',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-02-15_003',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-02-15_004',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-05-15_000',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-05-15_001',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-05-15_002',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-05-15_003',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-05-15_004',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-08-15_000',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-08-15_001',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-08-15_002',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-08-15_003',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-08-15_004',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-11-15_000',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-11-15_001',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-11-15_002',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-11-15_003',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2019-11-15_004',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-02-15_000',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-02-15_001',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-02-15_002',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-02-15_003',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-02-15_004',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-05-15_001',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-05-15_002',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-05-15_003',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-05-15_004',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-08-15_000',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-08-15_001',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-08-15_002',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-08-15_003',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-08-15_004',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-11-15_000',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-11-15_001',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-11-15_002',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-11-15_003',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-11-15_004',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-02-15_000',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-02-15_001',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2020-05-15_000',\n",
       " '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza/fitted_RF/clf4_2021-02-15_002']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "## Trimestres con ingresos disponibles (depende de disponibilidad de microdatos EPH)\n",
    "import glob\n",
    "\n",
    "fuente_modelos = 'estocasticidad_indice_pobreza' # 'indice-pobreza-ExactasUBA'\n",
    "path = '/media/miglesia/Elements/suite/'+fuente_modelos+'/fitted_RF/clf4_' # use your path\n",
    "# path = '/home/miglesia/repositories/encuestador-de-hogares/fitted_RF/clf4_'\n",
    "\n",
    "allFiles = []\n",
    "# allFiles += glob.glob(path +'*.sav')\n",
    "# allqs = [f[-18:-8] for f in allFiles]\n",
    "\n",
    "allFiles += glob.glob(path +'*')\n",
    "allFiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2019-02-15', '2019-05-15', '2019-08-15', '2019-11-15',\n",
       "       '2020-02-15', '2020-05-15', '2020-08-15', '2020-11-15',\n",
       "       '2021-02-15', '2021-05-15', '2021-08-15', '2021-11-15'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "qstrings = np.unique([Path(f).name.split('_')[-2] for f in  allFiles])\n",
    "qstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "### Funcion ajustar nivel de empleo\n",
    "\n",
    "def ajustar_empleo(data, verbose = False):\n",
    "\n",
    "        ratio = empleo.loc[pd.to_datetime(q)].censo2010_ratio\n",
    "        n_desempleados_ = ratio*(CONDACT_cnts[1] + CONDACT_cnts[2])*tasa_C2010\n",
    "        desemp_adic = round(n_desempleados_ - CONDACT_cnts.loc[2]) # Desempleados adicionales\n",
    "        \n",
    "        print(str(q)[:10])\n",
    "\n",
    "        if desemp_adic > 0:\n",
    "            data.loc[\n",
    "                data.query('CONDACT == 1').sample(desemp_adic).index,\n",
    "                'CONDACT'\n",
    "            ] = 2\n",
    "        elif desemp_adic < 0:\n",
    "            data.loc[\n",
    "                data.query('CONDACT == 2').sample(- desemp_adic).index,\n",
    "                'CONDACT'\n",
    "            ] = 1\n",
    "\n",
    "        if verbose:\n",
    "            desempleo = data.CONDACT.value_counts().loc[2] / (data.CONDACT.value_counts().loc[1] + data.CONDACT.value_counts().loc[2])\n",
    "            print('desempleo:' + str(desempleo))\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    \n",
    "def predict_save(X_data, x_cols, y_cols, model_filename, out_filename, balance_proba, tag, overwrite = False):\n",
    "\n",
    "        # Si todavia no existe la training data de ese anio, o si la opcion overwrite esta activada:\n",
    "        if (not os.path.exists(out_filename)) or (overwrite): \n",
    "\n",
    "            CLF = joblib.load(model_filename)\n",
    "            \n",
    "            if balance_proba: ## Prediccion usando predict proba y factores de balance.\n",
    "                y_out = pd.DataFrame([])\n",
    "                proba_values = CLF.predict_proba(X_data[x_cols])\n",
    "\n",
    "                ## Leer factores de archivo json\n",
    "                with open('/home/miglesia/repositories/encuestador-de-hogares/data/training/factors/'+tag+'.json', 'r') as file:\n",
    "                    info = json.load(file)\n",
    "                factors_mean = pd.DataFrame(json.loads(info[tag])).stack()\n",
    "                factors_mean.index.names = ['variable', 'valor']\n",
    "                factors_mean.index = factors_mean.index.set_levels(factors_mean.index.levels[1].astype(float).astype(int), level='valor')\n",
    "\n",
    "                for j, y_col in enumerate(y_cols):\n",
    "\n",
    "                    y_probas = pd.DataFrame(proba_values[j], columns = factors_mean.loc[y_col].index.values)\n",
    "                    y_out[y_col] = (y_probas/factors_mean.loc[y_col]).idxmax(1)#.value_counts().sort_index()\n",
    "                \n",
    "            else: ## Prediccion sin balance\n",
    "                y_out = CLF.predict(X_data[x_cols].values)\n",
    "\n",
    "            ## Listo\n",
    "            y_censo_fit = pd.DataFrame(y_out, index = X_data.index, columns=y_cols)\n",
    "            \n",
    "            Xy_censo = pd.concat([X_data, y_censo_fit], axis = 1)\n",
    "\n",
    "#             save\n",
    "            Xy_censo.to_csv(out_filename, index = False)\n",
    "            print('File saved at '+ out_filename)\n",
    "            del X_data; del Xy_censo; del CLF\n",
    "#             gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000\n",
      "2019\n",
      "['2019-02-15' '2019-05-15' '2019-08-15' '2019-11-15' '2020-02-15'\n",
      " '2020-05-15' '2020-08-15' '2020-11-15' '2021-02-15' '2021-05-15'\n",
      " '2021-08-15' '2021-11-15']\n",
      "Nuevo trimestre.\n",
      "2019-02-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-02-15_000.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-02-15_000.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-02-15_000.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-05-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-05-15_000.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-05-15_000.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-05-15_000.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-08-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-08-15_000.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-08-15_000.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-08-15_000.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-11-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-11-15_000.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-11-15_000.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-11-15_000.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-02-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-05-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-08-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-11-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-02-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-05-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-08-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-11-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "010\n",
      "2019\n",
      "['2019-02-15' '2019-05-15' '2019-08-15' '2019-11-15' '2020-02-15'\n",
      " '2020-05-15' '2020-08-15' '2020-11-15' '2021-02-15' '2021-05-15'\n",
      " '2021-08-15' '2021-11-15']\n",
      "Nuevo trimestre.\n",
      "2019-02-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-02-15_010.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-02-15_010.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-02-15_010.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-05-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-05-15_010.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-05-15_010.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-05-15_010.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-08-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-08-15_010.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-08-15_010.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-08-15_010.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-11-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-11-15_010.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-11-15_010.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-11-15_010.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-02-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-05-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-08-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-11-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-02-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-05-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-08-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-11-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "001\n",
      "2019\n",
      "['2019-02-15' '2019-05-15' '2019-08-15' '2019-11-15' '2020-02-15'\n",
      " '2020-05-15' '2020-08-15' '2020-11-15' '2021-02-15' '2021-05-15'\n",
      " '2021-08-15' '2021-11-15']\n",
      "Nuevo trimestre.\n",
      "2019-02-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-02-15_001.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-02-15_001.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-02-15_001.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-05-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-05-15_001.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-05-15_001.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-05-15_001.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-08-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-08-15_001.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-08-15_001.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-08-15_001.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-11-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-11-15_001.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-11-15_001.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-11-15_001.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-02-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-05-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-08-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-11-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-02-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-05-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-08-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-11-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "011\n",
      "2019\n",
      "['2019-02-15' '2019-05-15' '2019-08-15' '2019-11-15' '2020-02-15'\n",
      " '2020-05-15' '2020-08-15' '2020-11-15' '2021-02-15' '2021-05-15'\n",
      " '2021-08-15' '2021-11-15']\n",
      "Nuevo trimestre.\n",
      "2019-02-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-02-15_011.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-02-15_011.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-02-15_011.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-05-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-05-15_011.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-05-15_011.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-05-15_011.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-08-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-08-15_011.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-08-15_011.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-08-15_011.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-11-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-11-15_011.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-11-15_011.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-11-15_011.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-02-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-05-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-08-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-11-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-02-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-05-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-08-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-11-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "002\n",
      "2019\n",
      "['2019-02-15' '2019-05-15' '2019-08-15' '2019-11-15' '2020-02-15'\n",
      " '2020-05-15' '2020-08-15' '2020-11-15' '2021-02-15' '2021-05-15'\n",
      " '2021-08-15' '2021-11-15']\n",
      "Nuevo trimestre.\n",
      "2019-02-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-02-15_002.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-02-15_002.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-02-15_002.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-05-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-05-15_002.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-05-15_002.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-05-15_002.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-08-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-08-15_002.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-08-15_002.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-08-15_002.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-11-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-11-15_002.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-11-15_002.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-11-15_002.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-02-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-05-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-08-15\n",
      "C1\n",
      "C2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-11-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-02-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-05-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-08-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-11-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "012\n",
      "2019\n",
      "['2019-02-15' '2019-05-15' '2019-08-15' '2019-11-15' '2020-02-15'\n",
      " '2020-05-15' '2020-08-15' '2020-11-15' '2021-02-15' '2021-05-15'\n",
      " '2021-08-15' '2021-11-15']\n",
      "Nuevo trimestre.\n",
      "2019-02-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-02-15_012.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-02-15_012.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-02-15_012.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-05-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-05-15_012.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-05-15_012.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-05-15_012.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-08-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-08-15_012.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-08-15_012.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-08-15_012.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-11-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-11-15_012.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-11-15_012.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-11-15_012.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-02-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-05-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-08-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2020-11-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-02-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-05-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-08-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2021-11-15\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "reg\n",
      "003\n",
      "2019\n",
      "['2019-02-15' '2019-05-15' '2019-08-15' '2019-11-15' '2020-02-15'\n",
      " '2020-05-15' '2020-08-15' '2020-11-15' '2021-02-15' '2021-05-15'\n",
      " '2021-08-15' '2021-11-15']\n",
      "Nuevo trimestre.\n",
      "2019-02-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-02-15_003.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-02-15_003.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-02-15_003.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-05-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2019-05-15_003.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2019-05-15_003.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2019-05-15_003.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2019-08-15\n",
      "C1\n"
     ]
    }
   ],
   "source": [
    "overwrite = False\n",
    "\n",
    "### IMPORTANTE ELEGIR ANIOS\n",
    "startyr = 2019\n",
    "endyr = 2020\n",
    "\n",
    "## Elegir el dataset usado como X:\n",
    "frac = '0.01'\n",
    "\n",
    "# models_path = '/media/miglesia/Elements/suite/estocasticidad_indice_pobreza'\n",
    "\n",
    "balance_proba = False\n",
    "\n",
    "for i in range(n_models):\n",
    "    models_tag = str(i).zfill(3)\n",
    "\n",
    "    for j in range(2):\n",
    "        sample_tag = str(10*j).zfill(3)\n",
    "        experiment_tag = str(int(models_tag) + int(sample_tag)).zfill(3)\n",
    "        \n",
    "        print(experiment_tag)\n",
    "\n",
    "        for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "            print(yr)\n",
    "            file_ = '/media/miglesia/Elements/suite/yr_samples/table_f'+str(frac)+'_'+yr+'_'+sample_tag+'.csv'\n",
    "\n",
    "            X_censo = pd.read_csv(file_, usecols = ['DPTO','RADIO_REF_ID','PERSONA_REF_ID', 'HOGAR_REF_ID','IX_TOT', 'P02', 'P03', 'CONDACT', 'AGLOMERADO', 'URP', 'V01', 'H05', 'H06',\n",
    "                   'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14', 'AGLO_rk', 'Reg_rk',\n",
    "                   'H13', 'P07', 'P08', 'P09', 'P10', 'P05']).fillna(0)\n",
    "\n",
    "            ## Tratamiento trimestral \n",
    "#             qs = np.array(allqs)[[i for i, si in enumerate(allqs) if si.startswith(yr)]]\n",
    "            qs = qstrings\n",
    "            print(qs)\n",
    "\n",
    "            CONDACT_cnts = X_censo.CONDACT.value_counts()\n",
    "\n",
    "#             print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "            ### Cargar modelos de la parte no trimestral (anual).\n",
    "            for q in sorted(qs):\n",
    "\n",
    "                ### AJUSTAR NIVEL DE DESEMPLEO\n",
    "                X_q = X_censo.copy()\n",
    "                X_q['Q'] = q\n",
    "                print('Nuevo trimestre.')\n",
    "\n",
    "                X_q = ajustar_empleo(X_q)\n",
    "\n",
    "                #################################    #################################    #################################\n",
    "\n",
    "                print('C1')\n",
    "                ## CLASIF 1\n",
    "                X_data = X_q;\n",
    "                y_cols1 = ['CAT_OCUP', 'CAT_INAC', 'CH07']\n",
    "                x_cols1 = ['IX_TOT', 'P02', 'P03', 'AGLO_rk', 'Reg_rk', 'V01', 'H05', 'H06',\n",
    "               'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14',\n",
    "               'H13', 'P07', 'P08', 'P09', 'P10', 'P05', 'CONDACT']\n",
    "                out_filename1 = '/media/miglesia/Elements/suite/yr_samples/RFC1_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "                predict_save(X_data,\n",
    "                             x_cols = x_cols1,\n",
    "                             y_cols = y_cols1,\n",
    "                             out_filename = out_filename1,\n",
    "                             model_filename = models_path + '/fitted_RF/clf1_'+yr+'_'+models_tag,\n",
    "                             balance_proba = balance_proba,\n",
    "                             tag = 'clf1_'+yr+'_'+models_tag,\n",
    "                            overwrite = overwrite)\n",
    "\n",
    "                del X_q; del X_data\n",
    "        #         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "                #################################    #################################    #################################\n",
    "\n",
    "                print('C2')\n",
    "                ## CLASIF 2\n",
    "                X_data = pd.read_csv(out_filename1)\n",
    "                y_cols2 = ['INGRESO', 'INGRESO_NLB', 'INGRESO_JUB', 'INGRESO_SBS']\n",
    "                x_cols2 = x_cols1 + y_cols1\n",
    "                out_filename2 = '/media/miglesia/Elements/suite/yr_samples/RFC2_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "                predict_save(X_data,\n",
    "                             x_cols = x_cols2,\n",
    "                             y_cols = y_cols2,\n",
    "                             out_filename = out_filename2,\n",
    "                             model_filename = models_path + '/fitted_RF/clf2_'+yr+'_'+models_tag,\n",
    "                             balance_proba = balance_proba,\n",
    "                             tag = 'clf2_'+yr+'_'+models_tag,\n",
    "                            overwrite = overwrite)\n",
    "\n",
    "                del X_data\n",
    "        #         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "                #################################    #################################    #################################\n",
    "\n",
    "                print('C3')\n",
    "\n",
    "                ## CLASIF 3\n",
    "                X_data = pd.read_csv(out_filename2)\n",
    "                y_cols3 = ['PP07G1','PP07G_59', 'PP07I', 'PP07J', 'PP07K']\n",
    "                x_cols3 = x_cols2 + y_cols2\n",
    "                out_filename3 = '/media/miglesia/Elements/suite/yr_samples/RFC3_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "                predict_save(X_data,\n",
    "                             x_cols = x_cols3,\n",
    "                             y_cols = y_cols3,\n",
    "                             out_filename = out_filename3,\n",
    "                             model_filename = models_path + '/fitted_RF/clf3_'+yr+'_'+models_tag,\n",
    "                             balance_proba = balance_proba,\n",
    "                             tag = 'clf3_'+yr+'_'+models_tag,\n",
    "                            overwrite = overwrite)\n",
    "                del X_data\n",
    "        #         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "                #################################    #################################    #################################\n",
    "\n",
    "\n",
    "                # Columnas de ingresos. Necesitan una regresion...\n",
    "                columnas_pesos = [u'P21', u'P47T', u'PP08D1', u'TOT_P12', u'T_VI', u'V12_M', u'V2_M', u'V3_M', u'V5_M']\n",
    "\n",
    "                x_cols4 = x_cols3 + y_cols3\n",
    "                # Columnas de ingresos. Necesitan una regresion...\n",
    "                predecir4 = columnas_pesos\n",
    "                y_cols4 = predecir4\n",
    "\n",
    "\n",
    "                print('reg')\n",
    "                # REGRESION            \n",
    "                out_filename4 = '/media/miglesia/Elements/suite/yr_samples/RFReg_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "                if (not os.path.exists(out_filename4)) or (overwrite): \n",
    "\n",
    "                    ## Cargar Modelo\n",
    "                    model_filename4 = models_path + '/fitted_RF/clf4_'+str(q)[:10]+'_'+models_tag\n",
    "            #         filename = '/media/miglesia/Elements/CENSO_dirs/Pobreza/fitted_RF/clf4_0.02_'+str(q)[:10]+'_'+experiment_tag+'.sav'\n",
    "        #             clf4 = pickle.load(open(model_filename4+'sav', 'rb'))\n",
    "                    clf4 = joblib.load(model_filename4)\n",
    "\n",
    "                    Xy3_censo = pd.read_csv(out_filename3)\n",
    "                    y_out4 = clf4.predict(Xy3_censo[x_cols4].values); del clf4\n",
    "                    y_censo_fit4 = pd.DataFrame(y_out4, index = Xy3_censo.index, columns=predecir4)\n",
    "\n",
    "                    Xy4_censo = pd.concat([Xy3_censo, y_censo_fit4], axis = 1)\n",
    "        #             save\n",
    "                    Xy4_censo.to_csv(out_filename4, index = False)\n",
    "\n",
    "                    del Xy4_censo;\n",
    "\n",
    "            del X_censo; #del clf1; del clf2; del clf3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Computar Pobreza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adulto equivalente. Cuanto cuesta la manutencion de las personas segun sexo y edad.\n",
    "ad_eq = pd.read_csv('./../data/info/adulto_eq.csv')\n",
    "\n",
    "#Importar canasta basica regional deflac\n",
    "CB_ipc = pd.read_csv('./../data/info/CB_Reg_defl.csv')\n",
    "# ppp_defl = pd.read_csv('./../data/info/ppp_defl.csv')\n",
    "\n",
    "# Load radio ref. Merge regiones.\n",
    "# Anything that is AGLOMERADO 33 should be region Gran Buenos Aires\n",
    "\n",
    "# radio_ref = pd.read_csv('./../data/info/radio_ref.csv').merge(pd.read_csv('./../data/info/prov_regs.csv'), how = 'left')\n",
    "\n",
    "radio_ref = pd.read_csv('./../data/info/radio_ref.csv')#.merge(aglo_labels)\n",
    "dpto_region = pd.read_csv('./../data/info/DPTO_PROV_Region.csv')\n",
    "## Fix temporario, migracion a nombres de region oficiales\n",
    "dpto_region['Region'] = dpto_region['Region'].map({'Gran Buenos Aires':'gran_buenos_aires', \n",
    "                                                   'Pampeana':'pampeana', 'Noroeste':'noroeste', \n",
    "                                                   'Noreste':'noreste','Patagónica': 'patagonia', 'Cuyo': 'cuyo'})\n",
    "\n",
    "radio_ref = radio_ref.merge(dpto_region)\n",
    "\n",
    "# DPTO_Region = radio_ref[['DPTO', 'Region']].drop_duplicates()\n",
    "\n",
    "# dpto_region = pd.read_csv('./../data/info/DPTO_PROV_Region.csv')\n",
    "DPTO_Region = radio_ref[['DPTO', 'Region']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./../data/Pobreza/'):\n",
    "    os.makedirs('./../data/Pobreza/')\n",
    "\n",
    "frac = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ingresos_a_pobreza(df_ingresos, filename, columnas_pesos = ['P47T']):\n",
    "\n",
    "    df_ingresos[columnas_pesos] = np.power(10, df_ingresos[columnas_pesos]) - 1\n",
    "    \n",
    "#     # Editar columnas:\n",
    "#     ## Nivel Educativo\n",
    "#     df_ingresos['P10'] = 2 - df_ingresos['P10']  ## Re codificacion de pregunta 'termino el nivel'\n",
    "#     df_ingresos['P09'] = df_ingresos.P09.replace(5, 4) # Polimodal tomado como secundario \n",
    "#     df_ingresos['P0910'] = df_ingresos.P09.astype(str) + df_ingresos.P10.astype(str)\n",
    "    \n",
    "#     ## Grupos Etarios\n",
    "#     df_ingresos['Grupo_Etario_3'] = pd.cut(df_ingresos.P03, np.arange(-1, 80, 3)).astype(str)#.round(-1)\n",
    "#     df_ingresos['Grupo_Etario_INDEC'] = pd.cut(df_ingresos.P03, np.array([0, 13, 29, 64, 110])).astype(str)#.round(-1)\n",
    "#     df_ingresos['Grupo_Etario_q10'] = pd.cut(df_ingresos.P03, np.array([-0.001, 5.0,  11.0, 17.0, 23.0, 29.0, 36.0, 44.0, 53.0, 65.0, 110.0])).astype(str)#.round(-1)\n",
    "#     # df = pd.read_csv('file.csv', dtype={'Col' : 'category'}) # Despues podemos necesitar...\n",
    "\n",
    "    df = df_ingresos.reset_index()\n",
    "\n",
    "    ## CANASTA: Datos mergeado con adulto equivalente, region y serie de tiempo canasta\n",
    "    df_cb = df_ingresos.merge(ad_eq).merge(DPTO_Region).merge(CB_ipc)#.merge(ppp_defl[['Q', 'ppp_5usd_ARS_deflac']])\n",
    "    df_cb['CBA'] = df_cb['CBA']*df_cb['CB_EQUIV']  ## Con este paso el valor de canasta de una persona YA INCORPORA EL AD EQ\n",
    "    df_cb['CBT'] = df_cb['CBT']*df_cb['CB_EQUIV']  ## Con este paso el valor de canasta de una persona YA INCORPORA EL AD EQ\n",
    "\n",
    "    ## VARIABLES A NIVEL HOGARES\n",
    "#     df_cb_hogares = df_cb.groupby(['HOGAR_REF_ID', 'Q'])[['P47T','CBA', 'CBT', 'CB_EQUIV', 'ppp_5usd_ARS_deflac']].sum()\n",
    "    df_cb_hogares = df_cb.groupby(['HOGAR_REF_ID', 'Q'])[['P47T','CBA', 'CBT', 'CB_EQUIV']].sum()\n",
    "    df_cb_hogares['Pobreza'] = df_cb_hogares['P47T'] < df_cb_hogares['CBT']\n",
    "    df_cb_hogares['Indigencia'] = df_cb_hogares['P47T'] < df_cb_hogares['CBA']\n",
    "#     df_cb_hogares['Pobreza_5usd'] = df_cb_hogares['P47T'] < df_cb_hogares['ppp_5usd_ARS_deflac']\n",
    "#     pobreza_hogares = df_cb_hogares[['P47T','CBA','CBT', 'CB_EQUIV','Pobreza', 'Indigencia', 'Pobreza_5usd']].reset_index()\n",
    "    pobreza_hogares = df_cb_hogares[['P47T','CBA','CBT', 'CB_EQUIV','Pobreza', 'Indigencia']].reset_index()\n",
    "    pobreza_hogares['gap_pobreza'] = pobreza_hogares.P47T - pobreza_hogares.CBT\n",
    "    pobreza_hogares['gap_indigencia'] = pobreza_hogares.P47T - pobreza_hogares.CBA\n",
    "    pobreza_hogares = pobreza_hogares.rename(columns = {'P47T': 'P47T_hogar'})\n",
    "\n",
    "    ## UNION DE DATOS DE HOGARES A REGISTROS INDIVIDUALES\n",
    "    data = df_ingresos.merge(pobreza_hogares, on = ['HOGAR_REF_ID', 'Q'])#, how = 'left')\n",
    "    del df; del pobreza_hogares # Ahorrar memoria\n",
    "    data = data.rename(columns = {'P47T': 'P47T_persona'}) # Renombrar la variable P47T para aclarar que es a nivel persona.\n",
    "\n",
    "    ## UNIR INFO GEOGRAFICA\n",
    "    data = data.merge(radio_ref[['RADIO_REF_ID', 'IDFRAC', 'PROV', 'NOMPROV', 'AGLOMERADO', 'Region']].drop_duplicates())\n",
    "\n",
    "    n_q = data.Q.nunique()\n",
    "    print(\"Poblacion: \"+str(len(data)/frac/n_q))\n",
    "#     display(data[['Pobreza', 'Indigencia', 'Pobreza_5usd']].mean())\n",
    "    data.to_csv(filename, index = False) ## Aca si ya existen no deberian sobreescribirse (o si)\n",
    "    \n",
    "    print(filename+' saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "n_models = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(n_models):\n",
    "    models_tag = str(i).zfill(3)\n",
    "\n",
    "    for j in range(2):\n",
    "        sample_tag = str(10*j).zfill(3)\n",
    "        experiment_tag = str(int(models_tag) + int(sample_tag)).zfill(3)\n",
    "\n",
    "        print(experiment_tag)\n",
    "\n",
    "        files = ['/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2019-02-15_'+experiment_tag+'.csv', \n",
    "                 '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2019-05-15_'+experiment_tag+'.csv',\n",
    "                 '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2019-08-15_'+experiment_tag+'.csv', \n",
    "                 '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2019-11-15_'+experiment_tag+'.csv',\n",
    "                 '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2020-02-15_'+experiment_tag+'.csv', \n",
    "                 '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2020-05-15_'+experiment_tag+'.csv',\n",
    "                 '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2020-08-15_'+experiment_tag+'.csv', \n",
    "                 '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2020-11-15_'+experiment_tag+'.csv',\n",
    "                 '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2021-02-15_'+experiment_tag+'.csv', \n",
    "                 '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2021-05-15_'+experiment_tag+'.csv',\n",
    "                 '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2021-08-15_'+experiment_tag+'.csv', \n",
    "                 '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2021-11-15_'+experiment_tag+'.csv']\n",
    "\n",
    "        df_parts = []\n",
    "        for quarter_Xy_file in sorted(files):# ultimo anio\n",
    "            df_Q = pd.read_csv(quarter_Xy_file, \n",
    "                                   usecols = ['HOGAR_REF_ID','RADIO_REF_ID','P47T', 'P03','P02'])\n",
    "\n",
    "            df_Q['ANO4'] = int(Path(quarter_Xy_file).name.split('_')[-2].split('-')[0])\n",
    "            q = Path(quarter_Xy_file).name.split('_')[-2]; print(q)\n",
    "            df_Q['Q'] = q\n",
    "            df_parts += [df_Q]\n",
    "\n",
    "        df = pd.concat(df_parts)\n",
    "        del df_Q\n",
    "\n",
    "        filename = '/media/miglesia/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_'+'_'.join([str(frac), experiment_tag])+'.csv'\n",
    "\n",
    "        ingresos_a_pobreza(df_ingresos = df, filename = filename, columnas_pesos = ['P47T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = 5\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list = []; out_listH = []\n",
    "\n",
    "for i in range(n_models):\n",
    "    models_tag = str(i).zfill(3)\n",
    "\n",
    "    for j in range(2):\n",
    "        sample_tag = str(10*j).zfill(3)\n",
    "        experiment_tag = str(int(models_tag) + int(sample_tag)).zfill(3)\n",
    "\n",
    "        print(experiment_tag)\n",
    "\n",
    "        df = pd.read_csv('/media/miglesia/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_0.01_'+experiment_tag+'.csv')\n",
    "        df['AGLO_si'] = df['AGLOMERADO'] != 0\n",
    "        df['Q'] = pd.to_datetime(df['Q'])\n",
    "        df['SEMESTRE'] = df['Q'].dt.year.astype(str) + 'S'+ np.where(df['Q'].dt.quarter.gt(2),2,1).astype(str)\n",
    "        \n",
    "        ### PERSONAS\n",
    "        table = 100*df.loc[df.AGLO_si == True].groupby(['SEMESTRE'])[['Pobreza', 'Indigencia']].mean()\n",
    "#         display(table.round(4))\n",
    "        table['model'] = models_tag\n",
    "        table['sample'] = sample_tag\n",
    "        \n",
    "        ### HOGARES\n",
    "        dfH = df.copy()\n",
    "        dfH = dfH[['AGLO_si', 'SEMESTRE', 'Q', 'HOGAR_REF_ID', 'Pobreza', 'Indigencia']]\n",
    "        # dfH.drop_duplicates().shape\n",
    "        dfH = dfH.drop_duplicates()\n",
    "        tableH = 100*dfH.loc[dfH.AGLO_si == True].groupby(['SEMESTRE'])[['Pobreza', 'Indigencia']].mean()\n",
    "        tableH['model'] = models_tag\n",
    "        tableH['sample'] = sample_tag\n",
    "\n",
    "        out_list += [table]\n",
    "        out_listH += [tableH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(out_list).reset_index()\n",
    "dataH = pd.concat(out_listH).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoch_from_model = data.groupby(['SEMESTRE', 'sample'])['Pobreza', 'Indigencia'].agg(['mean', 'std'])\n",
    "stoch_from_model.groupby(level = 0).mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoch_from_sample = data.groupby(['SEMESTRE', 'model'])['Pobreza', 'Indigencia'].agg(['mean', 'std'])\n",
    "# stoch_from_sample\n",
    "stoch_from_sample.groupby(level = 0).mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Info de INDEC\n",
    "# info = pd.DataFrame([[10.7, 40.6], [8.2, 37.3]], index = ['2021S1', '2021S2'], columns = ['Indigencia', 'Pobreza'])\n",
    "info = pd.read_csv('./../data/info/pob_pers_INDEC.csv', index_col = 0)\n",
    "infoH = pd.read_csv('./../data/info/pob_hogs_INDEC.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = data.set_index(['SEMESTRE', 'model', 'sample']).stack().reset_index()\n",
    "data_ = data_.rename(columns = {'level_3': 'Variable', 0: 'pct'})\n",
    "\n",
    "dataH_ = dataH.set_index(['SEMESTRE', 'model', 'sample']).stack().reset_index()\n",
    "dataH_ = dataH_.rename(columns = {'level_3': 'Variable', 0: 'pct'})\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (10, 4))\n",
    "\n",
    "ax = axs[0]\n",
    "ax.set_title('Personas')\n",
    "info.plot(marker = 'o', lw = 0, ax = ax)\n",
    "sns.stripplot(data=data_, x=\"SEMESTRE\", y=\"pct\", color = '.7', ax = ax, alpha = .5, jitter = .04)\n",
    "ax.set_ylim(0, 45); ax.grid(linestyle = '--'); ax.set_ylabel('INCIDENCIA (%)')\n",
    "\n",
    "ax = axs[1]\n",
    "ax.set_title('Hogares')\n",
    "infoH.plot(marker = 'o', lw = 0, ax = ax)\n",
    "sns.stripplot(data=dataH_, x=\"SEMESTRE\", y=\"pct\", color = '.7', ax = ax, alpha = .5, jitter = .04)\n",
    "ax.set_ylim(0, 45); ax.grid(linestyle = '--'); ax.set_ylabel('INCIDENCIA (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./../images/comparacion_INDEC.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataH_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
