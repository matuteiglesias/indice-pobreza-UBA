{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on CENSO samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modulos\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar info empleo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0628729377307203"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "empleo = pd.read_csv('https://raw.githubusercontent.com/matuteiglesias/empleoARG/main/datos/45.2_ECTDT.csv')\n",
    "empleo = empleo[['45.2_IT_0_T_13', '45.2_ECTDT_0_T_33']] # ('45.2_ECTDT_0_T_33' es tasa de desocupacion en total aglomerados)\n",
    "empleo['Q'] = pd.to_datetime(empleo['45.2_IT_0_T_13']) + pd.DateOffset(months=1, days = 14)\n",
    "empleo = empleo.set_index('Q').drop(['45.2_IT_0_T_13'], axis = 1)\n",
    "empleo = empleo.replace('s/d', np.nan).astype(float).round(4)\n",
    "empleo['censo2010_ratio'] = (empleo/empleo.loc['2010-11-15'])\n",
    "\n",
    "# **Tasa de desempleo en censo 2010**\n",
    "## notar que la tasa en Aglos, segun el censo, no es igual al valor de la serie de tiempo.\n",
    "# para oct 2010 el censo da (6.29 %) y la que tenemos en dato (7.5%)\n",
    "desoc_C2010 = pd.read_csv('./../data/info/desoc_AGLOsi_C2010.csv')\n",
    "tasa_C2010 = desoc_C2010.loc[desoc_C2010.AGLO_si == True]['Tasa desocupacion'].values[0]\n",
    "tasa_C2010\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de trimestres con modelos ya calculados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "## Trimestres con ingresos disponibles (depende de disponibilidad de microdatos EPH)\n",
    "import glob\n",
    "\n",
    "path = './../../encuestador-de-hogares/fitted_RF/clf4_' # use your path\n",
    "\n",
    "allFiles = []\n",
    "\n",
    "allFiles += glob.glob(path +'*')\n",
    "allFiles = sorted(allFiles)\n",
    "# allFiles[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-02-15_ARG', '-05-15_ARG', '2003-08-15', '2003-11-15', '2004-02-15', '2004-05-15', '2004-08-15', '2004-11-15', '2005-02-15', '2005-05-15']\n",
      "['2020-11-15', '2021-02-15', '2021-05-15', '2021-08-15', '2021-11-15', '2022-02-15', '2022-05-15', '2022-08-15', '2022-11-15', '2023-02-15']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "allqs = [f[-14:-4] for f in allFiles]\n",
    "print(sorted(allqs)[:10])\n",
    "print(sorted(allqs)[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./../data/resultados'):\n",
    "    os.makedirs('./../data/resultados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros\n",
    "\n",
    "### Anios a calcular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTANTE ELEGIR ANIOS\n",
    "startyr = 2015\n",
    "endyr = 2023\n",
    "\n",
    "## Elegir el dataset usado como X:\n",
    "experiment_tag = 'ARG'\n",
    "models_tag = 'ARG'\n",
    "frac = '0.01'\n",
    "\n",
    "# 1174037/(18645609 + 1174037)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Funcion ajustar nivel de empleo\n",
    "\n",
    "\n",
    "def ajustar_empleo(data, q, verbose = False):\n",
    "\n",
    "        ratio = empleo.loc[pd.to_datetime(q)].censo2010_ratio\n",
    "        n_desempleados_ = ratio*(CONDACT_cnts[1] + CONDACT_cnts[2])*tasa_C2010\n",
    "        desemp_adic = round(n_desempleados_ - CONDACT_cnts.loc[2]) # Desempleados adicionales\n",
    "        \n",
    "        print(str(q)[:10])\n",
    "\n",
    "        if desemp_adic > 0:\n",
    "            data.loc[\n",
    "                data.query('CONDACT == 1').sample(desemp_adic).index,\n",
    "                'CONDACT'\n",
    "            ] = 2\n",
    "        elif desemp_adic < 0:\n",
    "            data.loc[\n",
    "                data.query('CONDACT == 2').sample(- desemp_adic).index,\n",
    "                'CONDACT'\n",
    "            ] = 1\n",
    "\n",
    "        if verbose:\n",
    "            desempleo = data.CONDACT.value_counts().loc[2] / (data.CONDACT.value_counts().loc[1] + data.CONDACT.value_counts().loc[2])\n",
    "            print('desempleo:' + str(desempleo))\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# import gc\n",
    "\n",
    "def predict_save(X_data, x_cols, y_cols, model_filename, out_filename, tag, overwrite = False):\n",
    "\n",
    "    # Si todavia no existe la training data de ese anio, o si la opcion overwrite esta activada:\n",
    "    if (not os.path.exists(out_filename)) or (overwrite): \n",
    "\n",
    "        CLF = joblib.load(model_filename)\n",
    "        \n",
    "        y_out = CLF.predict(X_data[x_cols].values)\n",
    "\n",
    "        ## Listo\n",
    "        y_censo_fit = pd.DataFrame(y_out, index = X_data.index, columns=y_cols)\n",
    "        \n",
    "        # Xy_censo = pd.concat([X_data, y_censo_fit], axis = 1)\n",
    "\n",
    "#             save\n",
    "        y_censo_fit.to_csv(out_filename, index = True) #, index_label = 'ID')\n",
    "        print('File saved at '+ out_filename)\n",
    "        del X_data; del CLF\n",
    "\n",
    "    # return y_censo_fit\n",
    "#             gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./../../../repos/encuestador-de-hogares/data/info')\n",
    "from variables import *  # x_cols1, x_cols2, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n",
      "['2015-02-15' '2015-05-15']\n",
      "Nuevo trimestre.\n",
      "2015-02-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2015-02-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2015-05-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2015-05-15_ARG.csv\n",
      "2016\n",
      "['2016-05-15' '2016-08-15' '2016-11-15']\n",
      "Nuevo trimestre.\n",
      "2016-05-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2016-05-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2016-08-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2016-08-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2016-11-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2016-11-15_ARG.csv\n",
      "2017\n",
      "['2017-02-15' '2017-05-15' '2017-08-15' '2017-11-15']\n",
      "Nuevo trimestre.\n",
      "2017-02-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2017-02-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2017-05-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2017-05-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2017-08-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2017-08-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2017-11-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2017-11-15_ARG.csv\n",
      "2018\n",
      "['2018-02-15' '2018-05-15' '2018-08-15' '2018-11-15']\n",
      "Nuevo trimestre.\n",
      "2018-02-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2018-02-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2018-05-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2018-05-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2018-08-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2018-08-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2018-11-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2018-11-15_ARG.csv\n",
      "2019\n",
      "['2019-02-15' '2019-05-15' '2019-08-15' '2019-11-15']\n",
      "Nuevo trimestre.\n",
      "2019-02-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2019-02-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2019-05-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2019-05-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2019-08-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2019-08-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2019-11-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2019-11-15_ARG.csv\n",
      "2020\n",
      "['2020-02-15' '2020-05-15' '2020-08-15' '2020-11-15']\n",
      "Nuevo trimestre.\n",
      "2020-02-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2020-02-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2020-05-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2020-05-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2020-08-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2020-08-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2020-11-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2020-11-15_ARG.csv\n",
      "2021\n",
      "['2021-02-15' '2021-05-15' '2021-08-15' '2021-11-15']\n",
      "Nuevo trimestre.\n",
      "2021-02-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.01_2021-02-15_ARG.csv\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2021-02-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2021-05-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2021-05-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2021-08-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2021-08-15_ARG.csv\n",
      "Nuevo trimestre.\n",
      "2021-11-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.01_2021-11-15_ARG.csv\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2021-11-15_ARG.csv\n",
      "2022\n",
      "['2022-02-15' '2022-05-15' '2022-08-15' '2022-11-15']\n",
      "Nuevo trimestre.\n",
      "2022-02-15\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC1_0.01_2022-02-15_ARG.csv\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC2_0.01_2022-02-15_ARG.csv\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.01_2022-02-15_ARG.csv\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.01_2022-02-15_ARG.csv\n",
      "Nuevo trimestre.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Timestamp('2022-05-15 00:00:00')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/_libs/index.pyx:581\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1652572800000000000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/_libs/index.pyx:549\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/_libs/index.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2022-05-15 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:584\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m     \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39;49mget_loc(\u001b[39mself\u001b[39;49m, key)\n\u001b[1;32m    585\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2022-05-15 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[183], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m X_q[\u001b[39m'\u001b[39m\u001b[39mQ\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m q\n\u001b[1;32m     33\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNuevo trimestre.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m X_q \u001b[39m=\u001b[39m ajustar_empleo(X_q, q)\n\u001b[1;32m     38\u001b[0m \u001b[39m# Define the first iteration separately\u001b[39;00m\n\u001b[1;32m     39\u001b[0m predict_save_iter_dict1 \u001b[39m=\u001b[39m {\n\u001b[1;32m     40\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mX_data\u001b[39m\u001b[39m'\u001b[39m: X_q,\n\u001b[1;32m     41\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mx_cols\u001b[39m\u001b[39m'\u001b[39m: x_cols1, \u001b[39m'\u001b[39m\u001b[39my_cols\u001b[39m\u001b[39m'\u001b[39m: y_cols1,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[39m'\u001b[39m\u001b[39moverwrite\u001b[39m\u001b[39m'\u001b[39m: overwrite\n\u001b[1;32m     46\u001b[0m }\n",
      "Cell \u001b[0;32mIn[164], line 6\u001b[0m, in \u001b[0;36majustar_empleo\u001b[0;34m(data, q, verbose)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39majustar_empleo\u001b[39m(data, q, verbose \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m----> 6\u001b[0m         ratio \u001b[39m=\u001b[39m empleo\u001b[39m.\u001b[39;49mloc[pd\u001b[39m.\u001b[39;49mto_datetime(q)]\u001b[39m.\u001b[39mcenso2010_ratio\n\u001b[1;32m      7\u001b[0m         n_desempleados_ \u001b[39m=\u001b[39m ratio\u001b[39m*\u001b[39m(CONDACT_cnts[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m CONDACT_cnts[\u001b[39m2\u001b[39m])\u001b[39m*\u001b[39mtasa_C2010\n\u001b[1;32m      8\u001b[0m         desemp_adic \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(n_desempleados_ \u001b[39m-\u001b[39m CONDACT_cnts\u001b[39m.\u001b[39mloc[\u001b[39m2\u001b[39m]) \u001b[39m# Desempleados adicionales\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1342\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1343\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexing.py:1293\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1292\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1293\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/generic.py:4095\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4093\u001b[0m             new_index \u001b[39m=\u001b[39m index[loc]\n\u001b[1;32m   4094\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4095\u001b[0m     loc \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   4097\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m   4098\u001b[0m         \u001b[39mif\u001b[39;00m loc\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_:\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:586\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39mget_loc(\u001b[39mself\u001b[39m, key)\n\u001b[1;32m    585\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 586\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(orig_key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2022-05-15 00:00:00')"
     ]
    }
   ],
   "source": [
    "models_path = './../../encuestador-de-hogares'\n",
    "adapted_Censo_files_path = '/media/matias/Elements/suite/poblaciones/'\n",
    "\n",
    "def run_predict_save(iter_dict):\n",
    "    predict_save(**iter_dict)\n",
    "    return pd.read_csv(iter_dict['out_filename'], index_col=['ID'])\n",
    "\n",
    "for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "    print(yr)\n",
    "    file_ = adapted_Censo_files_path + '/table_f'+str(frac)+'_'+yr+'_'+experiment_tag+'.csv'\n",
    "\n",
    "    X_censo = pd.read_csv(file_, usecols = x_cols1 + \n",
    "    ['ID','AGLOMERADO', 'DPTO', 'HOGAR_REF_ID', 'PERSONA_REF_ID', 'RADIO_REF_ID', 'URP'], \n",
    "    index_col=['ID']).fillna(0)\n",
    "\n",
    "    ## Tratamiento trimestral \n",
    "    qs = np.array(allqs)[[i for i, si in enumerate(allqs) if si.startswith(yr)]]\n",
    "    print(qs)\n",
    "    \n",
    "    CONDACT_cnts = X_censo.CONDACT.value_counts()\n",
    "        \n",
    "    ### Cargar modelos de la parte no trimestral (anual).\n",
    "    for q in sorted(qs):\n",
    "\n",
    "        out_filename1 = '/media/matias/Elements/suite/resultados/RFC1_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "        out_filename2 = '/media/matias/Elements/suite/resultados/RFC2_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "        out_filename3 = '/media/matias/Elements/suite/resultados/RFC3_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "        out_filename4 = '/media/matias/Elements/suite/resultados/RFReg_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "        ### AJUSTAR NIVEL DE DESEMPLEO\n",
    "        X_q = X_censo.copy()\n",
    "        X_q['Q'] = q\n",
    "        print('Nuevo trimestre.')\n",
    "\n",
    "        X_q = ajustar_empleo(X_q, q)\n",
    "\n",
    "\n",
    "        # Define the first iteration separately\n",
    "        predict_save_iter_dict1 = {\n",
    "            'X_data': X_q,\n",
    "            'x_cols': x_cols1, 'y_cols': y_cols1,\n",
    "            'out_filename': out_filename1,\n",
    "            'model_filename': models_path + '/fitted_RF/clf1_'+yr+'_'+models_tag,\n",
    "            'tag': 'clf1_'+yr+'_'+models_tag,\n",
    "            'overwrite': overwrite\n",
    "        }\n",
    "        result1 = run_predict_save(predict_save_iter_dict1)\n",
    "\n",
    "        # Second iteration\n",
    "        predict_save_iter_dict2 = {\n",
    "            'X_data': pd.concat([X_q, result1], axis=1),\n",
    "            'x_cols': x_cols2, 'y_cols': y_cols2,\n",
    "            'out_filename': out_filename2,\n",
    "            'model_filename': models_path + '/fitted_RF/clf2_'+yr+'_'+models_tag,\n",
    "            'tag': 'clf2_'+yr+'_'+models_tag,\n",
    "            'overwrite': overwrite\n",
    "        }\n",
    "        result2 = run_predict_save(predict_save_iter_dict2)\n",
    "\n",
    "        # Third iteration\n",
    "        predict_save_iter_dict3 = {\n",
    "            'X_data': pd.concat([X_q, result1, result2], axis=1),\n",
    "            'x_cols': x_cols3, 'y_cols': y_cols3,\n",
    "            'out_filename': out_filename3,\n",
    "            'model_filename': models_path + '/fitted_RF/clf3_'+yr+'_'+models_tag,\n",
    "            'tag': 'clf3_'+yr+'_'+models_tag,\n",
    "            'overwrite': overwrite\n",
    "        }\n",
    "        result3 = run_predict_save(predict_save_iter_dict3)\n",
    "\n",
    "        # Fourth iteration\n",
    "        predict_save_iter_dict4 = {\n",
    "            'X_data': pd.concat([X_q, result1, result2, result3], axis=1),\n",
    "            'x_cols': x_cols4, 'y_cols': columnas_pesos,\n",
    "            'out_filename': out_filename4,\n",
    "            'model_filename': models_path + '/fitted_RF/clf4_'+str(q)[:10]+'_'+models_tag,\n",
    "            'tag': 'clf4_'+yr+'_'+models_tag,\n",
    "            'overwrite': True,\n",
    "        }\n",
    "        result4 = run_predict_save(predict_save_iter_dict4)\n",
    "\n",
    "                                \n",
    "    del X_censo; #del clf1; del clf2; del clf3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugger\n",
    "# import pandas as pd\n",
    "\n",
    "# # List of filenames\n",
    "# filenames = [\n",
    "#     '/media/matias/Elements/suite/resultados/RFC1_0.01_2019-05-15_ARG.csv',\n",
    "#     '/media/matias/Elements/suite/resultados/RFC2_0.01_2019-05-15_ARG.csv',\n",
    "#     '/media/matias/Elements/suite/resultados/RFC3_0.01_2019-05-15_ARG.csv',\n",
    "#     '/media/matias/Elements/suite/resultados/RFReg_0.01_2019-05-15_ARG.csv'\n",
    "# ]\n",
    "\n",
    "# # Loop through each filename and print the columns\n",
    "# for filename in filenames:\n",
    "#     df = pd.read_csv(filename, nrows=1) # Reading only the first row\n",
    "#     print(f\"Dtypes in {filename}: {df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n",
      "['2005-02-15' '2005-05-15' '2005-08-15' '2005-11-15']\n",
      "Nuevo trimestre.\n",
      "2005-02-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-02-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-02-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-02-15_ARG.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2005-05-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-05-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-05-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-05-15_ARG.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2005-08-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-08-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-08-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-08-15_ARG.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2005-11-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-11-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-11-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-11-15_ARG.csv\n",
      "reg\n"
     ]
    }
   ],
   "source": [
    "# # import sys\n",
    "# # # These are the usual ipython objects, including this one you are creating\n",
    "# # ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "\n",
    "# for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "#     print(yr)\n",
    "#     file_ = '/media/matias/Elements/suite/yr_samples/table_f'+str(frac)+'_'+yr+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#     X_censo = pd.read_csv(file_, usecols = ['DPTO','RADIO_REF_ID','PERSONA_REF_ID', 'HOGAR_REF_ID','IX_TOT', 'P02', 'P03', 'CONDACT', 'AGLOMERADO', 'URP', 'V01', 'H05', 'H06',\n",
    "#            'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14', 'AGLO_rk', 'Reg_rk',\n",
    "#            'H13', 'P07', 'P08', 'P09', 'P10', 'P05']).fillna(0)\n",
    "\n",
    "#     ## Tratamiento trimestral \n",
    "#     qs = np.array(allqs)[[i for i, si in enumerate(allqs) if si.startswith(yr)]]\n",
    "#     print(qs)\n",
    "    \n",
    "#     CONDACT_cnts = X_censo.CONDACT.value_counts()\n",
    "    \n",
    "# #     print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "    \n",
    "#     ### Cargar modelos de la parte no trimestral (anual).\n",
    "#     for q in sorted(qs):\n",
    "        \n",
    "#         ### AJUSTAR NIVEL DE DESEMPLEO\n",
    "#         X_q = X_censo.copy()\n",
    "#         X_q['Q'] = q\n",
    "#         print('Nuevo trimestre.')\n",
    "\n",
    "#         X_q = ajustar_empleo(X_q)\n",
    "\n",
    "# # import sys\n",
    "# # # These are the usual ipython objects, including this one you are creating\n",
    "# # ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "\n",
    "# for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "#     print(yr)\n",
    "#     file_ = '/media/matias/Elements/suite/yr_samples/table_f'+str(frac)+'_'+yr+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#     X_censo = pd.read_csv(file_, usecols = ['DPTO','RADIO_REF_ID','PERSONA_REF_ID', 'HOGAR_REF_ID','IX_TOT', 'P02', 'P03', 'CONDACT', 'AGLOMERADO', 'URP', 'V01', 'H05', 'H06',\n",
    "#            'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14', 'AGLO_rk', 'Reg_rk',\n",
    "#            'H13', 'P07', 'P08', 'P09', 'P10', 'P05']).fillna(0)\n",
    "\n",
    "#     ## Tratamiento trimestral \n",
    "#     qs = np.array(allqs)[[i for i, si in enumerate(allqs) if si.startswith(yr)]]\n",
    "#     print(qs)\n",
    "    \n",
    "#     CONDACT_cnts = X_censo.CONDACT.value_counts()\n",
    "    \n",
    "# #     print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "    \n",
    "#     ### Cargar modelos de la parte no trimestral (anual).\n",
    "#     for q in sorted(qs):\n",
    "        \n",
    "#         ### AJUSTAR NIVEL DE DESEMPLEO\n",
    "#         X_q = X_censo.copy()\n",
    "#         X_q['Q'] = q\n",
    "#         print('Nuevo trimestre.')\n",
    "\n",
    "#         X_q = ajustar_empleo(X_q)\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "        \n",
    "#         print('C1')\n",
    "#         ## CLASIF 1\n",
    "#         X_data = X_q;\n",
    "#         y_cols1 = ['CAT_OCUP', 'CAT_INAC', 'CH07']\n",
    "#         x_cols1 = ['IX_TOT', 'P02', 'P03', 'AGLO_rk', 'Reg_rk', 'V01', 'H05', 'H06',\n",
    "#        'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14',\n",
    "#        'H13', 'P07', 'P08', 'P09', 'P10', 'P05', 'CONDACT']\n",
    "#         out_filename1 = '/media/miglesia/Elements/suite/yr_samples/RFC1_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                      x_cols = x_cols1,\n",
    "#                      y_cols = y_cols1,\n",
    "#                      out_filename = out_filename1,\n",
    "#                      model_filename = models_path + '/fitted_RF/clf1_'+yr+'_'+models_tag,\n",
    "#                      tag = 'clf1_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "        \n",
    "#         del X_q; del X_data\n",
    "# #         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "\n",
    "#         print('C2')\n",
    "#         ## CLASIF 2\n",
    "#         X_data = pd.read_csv(out_filename1)\n",
    "#         y_cols2 = ['INGRESO', 'INGRESO_NLB', 'INGRESO_JUB', 'INGRESO_SBS']\n",
    "#         x_cols2 = x_cols1 + y_cols1\n",
    "#         out_filename2 = '/media/miglesia/Elements/suite/yr_samples/RFC2_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                      x_cols = x_cols2,\n",
    "#                      y_cols = y_cols2,\n",
    "#                      out_filename = out_filename2,\n",
    "#                      model_filename = models_path + '/fitted_RF/clf2_'+yr+'_'+models_tag,\n",
    "#                      tag = 'clf2_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "\n",
    "#         del X_data\n",
    "# #         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "\n",
    "#         print('C3')\n",
    "\n",
    "#         ## CLASIF 3\n",
    "#         X_data = pd.read_csv(out_filename2)\n",
    "#         y_cols3 = ['PP07G1','PP07G_59', 'PP07I', 'PP07J', 'PP07K']\n",
    "#         x_cols3 = x_cols2 + y_cols2\n",
    "#         out_filename3 = '/media/miglesia/Elements/suite/yr_samples/RFC3_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                      x_cols = x_cols3,\n",
    "#                      y_cols = y_cols3,\n",
    "#                      out_filename = out_filename3,\n",
    "#                      model_filename = models_path + '/fitted_RF/clf3_'+yr+'_'+models_tag,\n",
    "#                      tag = 'clf3_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "#         del X_data\n",
    "# #         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "\n",
    "# #         print('reg')\n",
    "# #         # REGRESION\n",
    "# #     \n",
    "#         # Columnas de ingresos. Necesitan una regresion...\n",
    "#         columnas_pesos = [u'P21', u'P47T', u'PP08D1', u'TOT_P12', u'T_VI', u'V12_M', u'V2_M', u'V3_M', u'V5_M']\n",
    "\n",
    "#         x_cols4 = x_cols3 + y_cols3\n",
    "#         y_cols4 = columnas_pesos\n",
    "\n",
    "#         X_data = pd.read_csv(out_filename3)\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                     x_cols = x_cols4,\n",
    "#                     y_cols = columnas_pesos,\n",
    "#                     out_filename = '/media/miglesia/Elements/suite/yr_samples/RFReg_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv',\n",
    "#                     model_filename = models_path + '/fitted_RF/clf4_'+str(q)[:10]+'_'+models_tag,\n",
    "#                     tag = 'clf4_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "                                \n",
    "#     del X_censo; #del clf1; del clf2; del clf3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "1cef6941c3b284b72330916f92da3863815d2ff6730070ac04dc0833f8840e48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
