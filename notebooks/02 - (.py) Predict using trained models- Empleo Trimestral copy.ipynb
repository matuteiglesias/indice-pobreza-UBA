{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on CENSO samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modulos\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar info empleo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0628729377307203"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "empleo = pd.read_csv('https://raw.githubusercontent.com/matuteiglesias/empleoARG/main/datos/45.2_ECTDT.csv')\n",
    "empleo = empleo[['45.2_IT_0_T_13', '45.2_ECTDT_0_T_33']] # ('45.2_ECTDT_0_T_33' es tasa de desocupacion en total aglomerados)\n",
    "empleo['Q'] = pd.to_datetime(empleo['45.2_IT_0_T_13']) + pd.DateOffset(months=1, days = 14)\n",
    "empleo = empleo.set_index('Q').drop(['45.2_IT_0_T_13'], axis = 1)\n",
    "empleo = empleo.replace('s/d', np.nan).astype(float).round(4)\n",
    "empleo['censo2010_ratio'] = (empleo/empleo.loc['2010-11-15'])\n",
    "\n",
    "# **Tasa de desempleo en censo 2010**\n",
    "## notar que la tasa en Aglos, segun el censo, no es igual al valor de la serie de tiempo.\n",
    "# para oct 2010 el censo da (6.29 %) y la que tenemos en dato (7.5%)\n",
    "desoc_C2010 = pd.read_csv('./../data/info/desoc_AGLOsi_C2010.csv')\n",
    "tasa_C2010 = desoc_C2010.loc[desoc_C2010.AGLO_si == True]['Tasa desocupacion'].values[0]\n",
    "tasa_C2010\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de trimestres con modelos ya calculados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "## Trimestres con ingresos disponibles (depende de disponibilidad de microdatos EPH)\n",
    "import glob\n",
    "\n",
    "path = './../../encuestador-de-hogares/fitted_RF/clf4_' # use your path\n",
    "\n",
    "allFiles = []\n",
    "\n",
    "allFiles += glob.glob(path +'*')\n",
    "allFiles = sorted(allFiles)\n",
    "# allFiles[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2003-08-15', '2003-11-15', '2004-02-15', '2004-05-15', '2004-08-15', '2004-11-15', '2005-02-15', '2005-05-15', '2005-08-15', '2005-11-15']\n",
      "['2020-02-15', '2020-05-15', '2020-08-15', '2020-11-15', '2021-02-15', '2021-05-15', '2021-08-15', '2021-11-15', '2022-02-15', '2022-05-15']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "allqs = [f[-14:-4] for f in allFiles]\n",
    "print(sorted(allqs)[:10])\n",
    "print(sorted(allqs)[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./../data/yr_samples'):\n",
    "    os.makedirs('./../data/yr_samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros\n",
    "\n",
    "### Anios a calcular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTANTE ELEGIR ANIOS\n",
    "startyr = 2015\n",
    "endyr = 2016\n",
    "\n",
    "## Elegir el dataset usado como X:\n",
    "experiment_tag = 'ARG'\n",
    "models_tag = 'ARG'\n",
    "frac = '0.01'\n",
    "\n",
    "# 1174037/(18645609 + 1174037)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059236022681737104"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Funcion ajustar nivel de empleo\n",
    "\n",
    "\n",
    "def ajustar_empleo(data, q, verbose = False):\n",
    "\n",
    "        ratio = empleo.loc[pd.to_datetime(q)].censo2010_ratio\n",
    "        n_desempleados_ = ratio*(CONDACT_cnts[1] + CONDACT_cnts[2])*tasa_C2010\n",
    "        desemp_adic = round(n_desempleados_ - CONDACT_cnts.loc[2]) # Desempleados adicionales\n",
    "        \n",
    "        print(str(q)[:10])\n",
    "\n",
    "        if desemp_adic > 0:\n",
    "            data.loc[\n",
    "                data.query('CONDACT == 1').sample(desemp_adic).index,\n",
    "                'CONDACT'\n",
    "            ] = 2\n",
    "        elif desemp_adic < 0:\n",
    "            data.loc[\n",
    "                data.query('CONDACT == 2').sample(- desemp_adic).index,\n",
    "                'CONDACT'\n",
    "            ] = 1\n",
    "\n",
    "        if verbose:\n",
    "            desempleo = data.CONDACT.value_counts().loc[2] / (data.CONDACT.value_counts().loc[1] + data.CONDACT.value_counts().loc[2])\n",
    "            print('desempleo:' + str(desempleo))\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# import gc\n",
    "\n",
    "def predict_save(X_data, x_cols, y_cols, model_filename, out_filename, tag, overwrite = False):\n",
    "\n",
    "        # Si todavia no existe la training data de ese anio, o si la opcion overwrite esta activada:\n",
    "        if (not os.path.exists(out_filename)) or (overwrite): \n",
    "\n",
    "            CLF = joblib.load(model_filename)\n",
    "            \n",
    "            y_out = CLF.predict(X_data[x_cols].values)\n",
    "\n",
    "            ## Listo\n",
    "            y_censo_fit = pd.DataFrame(y_out, index = X_data.index, columns=y_cols)\n",
    "            \n",
    "            Xy_censo = pd.concat([X_data, y_censo_fit], axis = 1)\n",
    "\n",
    "#             save\n",
    "            Xy_censo.to_csv(out_filename, index = False)\n",
    "            print('File saved at '+ out_filename)\n",
    "            del X_data; del Xy_censo; del CLF\n",
    "#             gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./../../../Repos/encuestador-de-hogares/data/info')\n",
    "from variables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = './../../encuestador-de-hogares'\n",
    "adapted_Censo_files_path = '/media/matias/Elements/suite/yr_samples'\n",
    "\n",
    "for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "    print(yr)\n",
    "    file_ = adapted_Censo_files_path + '/table_f'+str(frac)+'_'+yr+'_'+experiment_tag+'.csv'\n",
    "\n",
    "    X_censo = pd.read_csv(file_, usecols = x_cols1 + \n",
    "    ['AGLOMERADO', 'DPTO', 'HOGAR_REF_ID', 'PERSONA_REF_ID', 'RADIO_REF_ID', 'URP']).fillna(0)\n",
    "\n",
    "    ## Tratamiento trimestral \n",
    "    qs = np.array(allqs)[[i for i, si in enumerate(allqs) if si.startswith(yr)]]\n",
    "    print(qs)\n",
    "    \n",
    "    CONDACT_cnts = X_censo.CONDACT.value_counts()\n",
    "        \n",
    "    ### Cargar modelos de la parte no trimestral (anual).\n",
    "    for q in sorted(qs):\n",
    "\n",
    "        out_filename1 = '/media/miglesia/Elements/suite/yr_samples/RFC1_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "        out_filename2 = '/media/miglesia/Elements/suite/yr_samples/RFC2_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "        out_filename3 = '/media/miglesia/Elements/suite/yr_samples/RFC3_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "        out_filename3 = '/media/miglesia/Elements/suite/yr_samples/RFReg_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "        ### AJUSTAR NIVEL DE DESEMPLEO\n",
    "        X_q = X_censo.copy()\n",
    "        X_q['Q'] = q\n",
    "        print('Nuevo trimestre.')\n",
    "\n",
    "        X_q = ajustar_empleo(X_q, q)\n",
    "\n",
    "        predict_save_iter_list = [{'X_data': X_q,\n",
    "                                'x_cols': x_cols1, 'y_cols': y_cols1,\n",
    "                                'out_filename': out_filename1,\n",
    "                                'model_filename': models_path + '/fitted_RF/clf1_'+yr+'_'+models_tag,\n",
    "                                'tag': 'clf1_'+yr+'_'+models_tag,'overwrite': overwrite}\n",
    "\n",
    "                                {'X_data': pd.read_csv(out_filename1),\n",
    "                                'x_cols': x_cols2, 'y_cols': y_cols2,\n",
    "                                'out_filename': out_filename2,\n",
    "                                'model_filename': models_path + '/fitted_RF/clf2_'+yr+'_'+models_tag,\n",
    "                                'tag': 'clf2_'+yr+'_'+models_tag,'overwrite': overwrite}\n",
    "                                \n",
    "                                {'X_data': pd.read_csv(out_filename2),\n",
    "                                'x_cols': x_cols3, 'y_cols': y_cols3,\n",
    "                                'out_filename': out_filename4,\n",
    "                                'model_filename': models_path + '/fitted_RF/clf3_'+yr+'_'+models_tag,\n",
    "                                'tag': 'clf3_'+yr+'_'+models_tag,'overwrite': overwrite}\n",
    "\n",
    "                                {'X_data': pd.read_csv(out_filename3),\n",
    "                                'x_cols': x_cols4, 'y_cols': columnas_pesos,\n",
    "                                'out_filename': out_filename4,\n",
    "                                'model_filename': models_path + '/fitted_RF/clf4_'+str(q)[:10]+'_'+models_tag,\n",
    "                                'tag': 'clf4_'+yr+'_'+models_tag, 'overwrite': overwrite}\n",
    "                                    ]\n",
    "            \n",
    "        # \n",
    "        for predict_save_iter_dict in predict_save_iter_list:\n",
    "            predict_save(**predict_save_iter_dict)\n",
    "            del predict_save_iter_dict['X_data']\n",
    "\n",
    "\n",
    "                                \n",
    "    del X_censo; #del clf1; del clf2; del clf3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n",
      "['2005-02-15' '2005-05-15' '2005-08-15' '2005-11-15']\n",
      "Nuevo trimestre.\n",
      "2005-02-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-02-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-02-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-02-15_ARG.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2005-05-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-05-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-05-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-05-15_ARG.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2005-08-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-08-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-08-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-08-15_ARG.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2005-11-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-11-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-11-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-11-15_ARG.csv\n",
      "reg\n"
     ]
    }
   ],
   "source": [
    "# # import sys\n",
    "# # # These are the usual ipython objects, including this one you are creating\n",
    "# # ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "\n",
    "# for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "#     print(yr)\n",
    "#     file_ = '/media/matias/Elements/suite/yr_samples/table_f'+str(frac)+'_'+yr+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#     X_censo = pd.read_csv(file_, usecols = ['DPTO','RADIO_REF_ID','PERSONA_REF_ID', 'HOGAR_REF_ID','IX_TOT', 'P02', 'P03', 'CONDACT', 'AGLOMERADO', 'URP', 'V01', 'H05', 'H06',\n",
    "#            'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14', 'AGLO_rk', 'Reg_rk',\n",
    "#            'H13', 'P07', 'P08', 'P09', 'P10', 'P05']).fillna(0)\n",
    "\n",
    "#     ## Tratamiento trimestral \n",
    "#     qs = np.array(allqs)[[i for i, si in enumerate(allqs) if si.startswith(yr)]]\n",
    "#     print(qs)\n",
    "    \n",
    "#     CONDACT_cnts = X_censo.CONDACT.value_counts()\n",
    "    \n",
    "# #     print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "    \n",
    "#     ### Cargar modelos de la parte no trimestral (anual).\n",
    "#     for q in sorted(qs):\n",
    "        \n",
    "#         ### AJUSTAR NIVEL DE DESEMPLEO\n",
    "#         X_q = X_censo.copy()\n",
    "#         X_q['Q'] = q\n",
    "#         print('Nuevo trimestre.')\n",
    "\n",
    "#         X_q = ajustar_empleo(X_q)\n",
    "\n",
    "# # import sys\n",
    "# # # These are the usual ipython objects, including this one you are creating\n",
    "# # ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "\n",
    "# for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "#     print(yr)\n",
    "#     file_ = '/media/matias/Elements/suite/yr_samples/table_f'+str(frac)+'_'+yr+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#     X_censo = pd.read_csv(file_, usecols = ['DPTO','RADIO_REF_ID','PERSONA_REF_ID', 'HOGAR_REF_ID','IX_TOT', 'P02', 'P03', 'CONDACT', 'AGLOMERADO', 'URP', 'V01', 'H05', 'H06',\n",
    "#            'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14', 'AGLO_rk', 'Reg_rk',\n",
    "#            'H13', 'P07', 'P08', 'P09', 'P10', 'P05']).fillna(0)\n",
    "\n",
    "#     ## Tratamiento trimestral \n",
    "#     qs = np.array(allqs)[[i for i, si in enumerate(allqs) if si.startswith(yr)]]\n",
    "#     print(qs)\n",
    "    \n",
    "#     CONDACT_cnts = X_censo.CONDACT.value_counts()\n",
    "    \n",
    "# #     print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "    \n",
    "#     ### Cargar modelos de la parte no trimestral (anual).\n",
    "#     for q in sorted(qs):\n",
    "        \n",
    "#         ### AJUSTAR NIVEL DE DESEMPLEO\n",
    "#         X_q = X_censo.copy()\n",
    "#         X_q['Q'] = q\n",
    "#         print('Nuevo trimestre.')\n",
    "\n",
    "#         X_q = ajustar_empleo(X_q)\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "        \n",
    "#         print('C1')\n",
    "#         ## CLASIF 1\n",
    "#         X_data = X_q;\n",
    "#         y_cols1 = ['CAT_OCUP', 'CAT_INAC', 'CH07']\n",
    "#         x_cols1 = ['IX_TOT', 'P02', 'P03', 'AGLO_rk', 'Reg_rk', 'V01', 'H05', 'H06',\n",
    "#        'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14',\n",
    "#        'H13', 'P07', 'P08', 'P09', 'P10', 'P05', 'CONDACT']\n",
    "#         out_filename1 = '/media/miglesia/Elements/suite/yr_samples/RFC1_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                      x_cols = x_cols1,\n",
    "#                      y_cols = y_cols1,\n",
    "#                      out_filename = out_filename1,\n",
    "#                      model_filename = models_path + '/fitted_RF/clf1_'+yr+'_'+models_tag,\n",
    "#                      tag = 'clf1_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "        \n",
    "#         del X_q; del X_data\n",
    "# #         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "\n",
    "#         print('C2')\n",
    "#         ## CLASIF 2\n",
    "#         X_data = pd.read_csv(out_filename1)\n",
    "#         y_cols2 = ['INGRESO', 'INGRESO_NLB', 'INGRESO_JUB', 'INGRESO_SBS']\n",
    "#         x_cols2 = x_cols1 + y_cols1\n",
    "#         out_filename2 = '/media/miglesia/Elements/suite/yr_samples/RFC2_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                      x_cols = x_cols2,\n",
    "#                      y_cols = y_cols2,\n",
    "#                      out_filename = out_filename2,\n",
    "#                      model_filename = models_path + '/fitted_RF/clf2_'+yr+'_'+models_tag,\n",
    "#                      tag = 'clf2_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "\n",
    "#         del X_data\n",
    "# #         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "\n",
    "#         print('C3')\n",
    "\n",
    "#         ## CLASIF 3\n",
    "#         X_data = pd.read_csv(out_filename2)\n",
    "#         y_cols3 = ['PP07G1','PP07G_59', 'PP07I', 'PP07J', 'PP07K']\n",
    "#         x_cols3 = x_cols2 + y_cols2\n",
    "#         out_filename3 = '/media/miglesia/Elements/suite/yr_samples/RFC3_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                      x_cols = x_cols3,\n",
    "#                      y_cols = y_cols3,\n",
    "#                      out_filename = out_filename3,\n",
    "#                      model_filename = models_path + '/fitted_RF/clf3_'+yr+'_'+models_tag,\n",
    "#                      tag = 'clf3_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "#         del X_data\n",
    "# #         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "\n",
    "# #         print('reg')\n",
    "# #         # REGRESION\n",
    "# #     \n",
    "#         # Columnas de ingresos. Necesitan una regresion...\n",
    "#         columnas_pesos = [u'P21', u'P47T', u'PP08D1', u'TOT_P12', u'T_VI', u'V12_M', u'V2_M', u'V3_M', u'V5_M']\n",
    "\n",
    "#         x_cols4 = x_cols3 + y_cols3\n",
    "#         y_cols4 = columnas_pesos\n",
    "\n",
    "#         X_data = pd.read_csv(out_filename3)\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                     x_cols = x_cols4,\n",
    "#                     y_cols = columnas_pesos,\n",
    "#                     out_filename = '/media/miglesia/Elements/suite/yr_samples/RFReg_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv',\n",
    "#                     model_filename = models_path + '/fitted_RF/clf4_'+str(q)[:10]+'_'+models_tag,\n",
    "#                     tag = 'clf4_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "                                \n",
    "#     del X_censo; #del clf1; del clf2; del clf3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "# from IPython.core.display import display, HTML\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "1cef6941c3b284b72330916f92da3863815d2ff6730070ac04dc0833f8840e48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
