{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on CENSO samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modulos\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar info empleo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0628729377307203"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "empleo = pd.read_csv('https://raw.githubusercontent.com/matuteiglesias/empleoARG/main/datos/45.2_ECTDT.csv')\n",
    "empleo = empleo[['45.2_IT_0_T_13', '45.2_ECTDT_0_T_33']] # ('45.2_ECTDT_0_T_33' es tasa de desocupacion en total aglomerados)\n",
    "empleo['Q'] = pd.to_datetime(empleo['45.2_IT_0_T_13']) + pd.DateOffset(months=1, days = 14)\n",
    "empleo = empleo.set_index('Q').drop(['45.2_IT_0_T_13'], axis = 1)\n",
    "empleo = empleo.replace('s/d', np.nan).astype(float).round(4)\n",
    "empleo['censo2010_ratio'] = (empleo/empleo.loc['2010-11-15'])\n",
    "\n",
    "# **Tasa de desempleo en censo 2010**\n",
    "## notar que la tasa en Aglos, segun el censo, no es igual al valor de la serie de tiempo.\n",
    "# para oct 2010 el censo da (6.29 %) y la que tenemos en dato (7.5%)\n",
    "desoc_C2010 = pd.read_csv('./../data/info/desoc_AGLOsi_C2010.csv')\n",
    "tasa_C2010 = desoc_C2010.loc[desoc_C2010.AGLO_si == True]['Tasa desocupacion'].values[0]\n",
    "tasa_C2010\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de trimestres con modelos ya calculados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "## Trimestres con ingresos disponibles (depende de disponibilidad de microdatos EPH)\n",
    "import glob\n",
    "\n",
    "path = './../../encuestador-de-hogares/fitted_RF/clf4_' # use your path\n",
    "\n",
    "allFiles = []\n",
    "\n",
    "allFiles += glob.glob(path +'*')\n",
    "allFiles = sorted(allFiles)\n",
    "# allFiles[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-02-15_ARG', '-05-15_ARG', '2003-08-15', '2003-11-15', '2004-02-15', '2004-05-15', '2004-08-15', '2004-11-15', '2005-02-15', '2005-05-15']\n",
      "['2020-11-15', '2021-02-15', '2021-05-15', '2021-08-15', '2021-11-15', '2022-02-15', '2022-05-15', '2022-08-15', '2022-11-15', '2023-02-15']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "allqs = [f[-14:-4] for f in allFiles]\n",
    "print(sorted(allqs)[:10])\n",
    "print(sorted(allqs)[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./../data/resultados'):\n",
    "    os.makedirs('./../data/resultados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros\n",
    "\n",
    "### Anios a calcular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTANTE ELEGIR ANIOS\n",
    "startyr = 2019\n",
    "endyr = 2023\n",
    "\n",
    "## Elegir el dataset usado como X:\n",
    "experiment_tag = 'ARG'\n",
    "models_tag = 'ARG'\n",
    "frac = '0.05'\n",
    "\n",
    "# 1174037/(18645609 + 1174037)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Funcion ajustar nivel de empleo\n",
    "\n",
    "\n",
    "def ajustar_empleo(data, q, verbose = False):\n",
    "\n",
    "        ratio = empleo.loc[pd.to_datetime(q)].censo2010_ratio\n",
    "        n_desempleados_ = ratio*(CONDACT_cnts[1] + CONDACT_cnts[2])*tasa_C2010\n",
    "        desemp_adic = round(n_desempleados_ - CONDACT_cnts.loc[2]) # Desempleados adicionales\n",
    "        \n",
    "        print(str(q)[:10])\n",
    "\n",
    "        if desemp_adic > 0:\n",
    "            data.loc[\n",
    "                data.query('CONDACT == 1').sample(desemp_adic).index,\n",
    "                'CONDACT'\n",
    "            ] = 2\n",
    "        elif desemp_adic < 0:\n",
    "            data.loc[\n",
    "                data.query('CONDACT == 2').sample(- desemp_adic).index,\n",
    "                'CONDACT'\n",
    "            ] = 1\n",
    "\n",
    "        if verbose:\n",
    "            desempleo = data.CONDACT.value_counts().loc[2] / (data.CONDACT.value_counts().loc[1] + data.CONDACT.value_counts().loc[2])\n",
    "            print('desempleo:' + str(desempleo))\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# import gc\n",
    "\n",
    "def predict_save(X_data, x_cols, y_cols, model_filename, out_filename, tag, overwrite = False):\n",
    "\n",
    "    # Si todavia no existe la training data de ese anio, o si la opcion overwrite esta activada:\n",
    "    if (not os.path.exists(out_filename)) or (overwrite): \n",
    "\n",
    "        CLF = joblib.load(model_filename)\n",
    "        \n",
    "        y_out = CLF.predict(X_data[x_cols].values)\n",
    "\n",
    "        ## Listo\n",
    "        y_censo_fit = pd.DataFrame(y_out, index = X_data.index, columns=y_cols)\n",
    "        \n",
    "        # Xy_censo = pd.concat([X_data, y_censo_fit], axis = 1)\n",
    "\n",
    "#             save\n",
    "        y_censo_fit.to_csv(out_filename, index = True) #, index_label = 'ID')\n",
    "        print('File saved at '+ out_filename)\n",
    "        del X_data; del CLF\n",
    "\n",
    "    # return y_censo_fit\n",
    "#             gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./../../../repos/encuestador-de-hogares/data/info')\n",
    "from variables import *  # x_cols1, x_cols2, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n",
      "['2019-02-15' '2019-05-15' '2019-08-15' '2019-11-15']\n",
      "Nuevo trimestre.\n",
      "2019-02-15\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC1_0.05_2019-02-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC2_0.05_2019-02-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.05_2019-02-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.05_2019-02-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "Nuevo trimestre.\n",
      "2019-05-15\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC1_0.05_2019-05-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC2_0.05_2019-05-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.05_2019-05-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.05_2019-05-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "Nuevo trimestre.\n",
      "2019-08-15\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC1_0.05_2019-08-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC2_0.05_2019-08-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.05_2019-08-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.05_2019-08-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "Nuevo trimestre.\n",
      "2019-11-15\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC1_0.05_2019-11-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC2_0.05_2019-11-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.05_2019-11-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.05_2019-11-15_ARG.csv\n",
      "Poblacion:  44333140.0\n",
      "2020\n",
      "['2020-02-15' '2020-05-15' '2020-08-15' '2020-11-15']\n",
      "Nuevo trimestre.\n",
      "2020-02-15\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC1_0.05_2020-02-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC2_0.05_2020-02-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.05_2020-02-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.05_2020-02-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "Nuevo trimestre.\n",
      "2020-05-15\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC1_0.05_2020-05-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC2_0.05_2020-05-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.05_2020-05-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.05_2020-05-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "Nuevo trimestre.\n",
      "2020-08-15\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC1_0.05_2020-08-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC2_0.05_2020-08-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.05_2020-08-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.05_2020-08-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "Nuevo trimestre.\n",
      "2020-11-15\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC1_0.05_2020-11-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC2_0.05_2020-11-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.05_2020-11-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.05_2020-11-15_ARG.csv\n",
      "Poblacion:  44692980.0\n",
      "2021\n",
      "['2021-02-15' '2021-05-15' '2021-08-15' '2021-11-15']\n",
      "Nuevo trimestre.\n",
      "2021-02-15\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC1_0.05_2021-02-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC2_0.05_2021-02-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.05_2021-02-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.05_2021-02-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "Nuevo trimestre.\n",
      "2021-05-15\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC1_0.05_2021-05-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC2_0.05_2021-05-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.05_2021-05-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.05_2021-05-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "Nuevo trimestre.\n",
      "2021-08-15\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC1_0.05_2021-08-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC2_0.05_2021-08-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.05_2021-08-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.05_2021-08-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "Nuevo trimestre.\n",
      "2021-11-15\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC1_0.05_2021-11-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC2_0.05_2021-11-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.05_2021-11-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.05_2021-11-15_ARG.csv\n",
      "Poblacion:  45055000.0\n",
      "2022\n",
      "['2022-02-15' '2022-05-15' '2022-08-15' '2022-11-15']\n",
      "Nuevo trimestre.\n",
      "2022-02-15\n",
      "Poblacion:  45385680.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC1_0.05_2022-02-15_ARG.csv\n",
      "Poblacion:  45385680.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC2_0.05_2022-02-15_ARG.csv\n",
      "Poblacion:  45385680.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.05_2022-02-15_ARG.csv\n",
      "Poblacion:  45385680.0\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.05_2022-02-15_ARG.csv\n",
      "Poblacion:  45385680.0\n",
      "Nuevo trimestre.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Timestamp('2022-05-15 00:00:00')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/_libs/index.pyx:581\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1652572800000000000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/_libs/index.pyx:549\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/_libs/index.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2022-05-15 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:584\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m     \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39;49mget_loc(\u001b[39mself\u001b[39;49m, key)\n\u001b[1;32m    585\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2022-05-15 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[275], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m X_q[\u001b[39m'\u001b[39m\u001b[39mQ\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m q\n\u001b[1;32m     33\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNuevo trimestre.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m X_q \u001b[39m=\u001b[39m ajustar_empleo(X_q, q)\n\u001b[1;32m     36\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPoblacion: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(X_q)\u001b[39m/\u001b[39m\u001b[39mfloat\u001b[39m(frac))\n\u001b[1;32m     39\u001b[0m \u001b[39m# Define the first iteration separately\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[271], line 6\u001b[0m, in \u001b[0;36majustar_empleo\u001b[0;34m(data, q, verbose)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39majustar_empleo\u001b[39m(data, q, verbose \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m----> 6\u001b[0m         ratio \u001b[39m=\u001b[39m empleo\u001b[39m.\u001b[39;49mloc[pd\u001b[39m.\u001b[39;49mto_datetime(q)]\u001b[39m.\u001b[39mcenso2010_ratio\n\u001b[1;32m      7\u001b[0m         n_desempleados_ \u001b[39m=\u001b[39m ratio\u001b[39m*\u001b[39m(CONDACT_cnts[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m CONDACT_cnts[\u001b[39m2\u001b[39m])\u001b[39m*\u001b[39mtasa_C2010\n\u001b[1;32m      8\u001b[0m         desemp_adic \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(n_desempleados_ \u001b[39m-\u001b[39m CONDACT_cnts\u001b[39m.\u001b[39mloc[\u001b[39m2\u001b[39m]) \u001b[39m# Desempleados adicionales\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1342\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1343\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexing.py:1293\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1292\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1293\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/generic.py:4095\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4093\u001b[0m             new_index \u001b[39m=\u001b[39m index[loc]\n\u001b[1;32m   4094\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4095\u001b[0m     loc \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   4097\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m   4098\u001b[0m         \u001b[39mif\u001b[39;00m loc\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_:\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:586\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39mget_loc(\u001b[39mself\u001b[39m, key)\n\u001b[1;32m    585\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 586\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(orig_key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2022-05-15 00:00:00')"
     ]
    }
   ],
   "source": [
    "models_path = './../../encuestador-de-hogares'\n",
    "adapted_Censo_files_path = '/media/matias/Elements/suite/poblaciones/'\n",
    "\n",
    "def run_predict_save(iter_dict):\n",
    "    predict_save(**iter_dict)\n",
    "    return pd.read_csv(iter_dict['out_filename'], index_col=['ID'])\n",
    "\n",
    "for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "    print(yr)\n",
    "    file_ = adapted_Censo_files_path + '/table_f'+str(frac)+'_'+yr+'_'+experiment_tag+'.csv'\n",
    "\n",
    "    X_censo = pd.read_csv(file_, usecols = x_cols1 + \n",
    "    ['ID','AGLOMERADO', 'DPTO', 'HOGAR_REF_ID', 'PERSONA_REF_ID', 'RADIO_REF_ID', 'URP'], \n",
    "    index_col=['ID']).fillna(0)\n",
    "\n",
    "    ## Tratamiento trimestral \n",
    "    qs = np.array(allqs)[[i for i, si in enumerate(allqs) if si.startswith(yr)]]\n",
    "    print(qs)\n",
    "    \n",
    "    CONDACT_cnts = X_censo.CONDACT.value_counts()\n",
    "        \n",
    "    ### Cargar modelos de la parte no trimestral (anual).\n",
    "    for q in sorted(qs):\n",
    "\n",
    "        out_filename1 = '/media/matias/Elements/suite/resultados/RFC1_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "        out_filename2 = '/media/matias/Elements/suite/resultados/RFC2_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "        out_filename3 = '/media/matias/Elements/suite/resultados/RFC3_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "        out_filename4 = '/media/matias/Elements/suite/resultados/RFReg_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "        ### AJUSTAR NIVEL DE DESEMPLEO\n",
    "        X_q = X_censo.copy()\n",
    "        X_q['Q'] = q\n",
    "        print('Nuevo trimestre.')\n",
    "\n",
    "        X_q = ajustar_empleo(X_q, q)\n",
    "        print('Poblacion: ', len(X_q)/float(frac))\n",
    "\n",
    "\n",
    "        # Define the first iteration separately\n",
    "        predict_save_iter_dict1 = {\n",
    "            'X_data': X_q,\n",
    "            'x_cols': x_cols1, 'y_cols': y_cols1,\n",
    "            'out_filename': out_filename1,\n",
    "            'model_filename': models_path + '/fitted_RF/clf1_'+yr+'_'+models_tag,\n",
    "            'tag': 'clf1_'+yr+'_'+models_tag,\n",
    "            'overwrite': overwrite\n",
    "        }\n",
    "        result1 = run_predict_save(predict_save_iter_dict1)\n",
    "        print('Poblacion: ', len(result1)/float(frac))\n",
    "\n",
    "        # Second iteration\n",
    "        predict_save_iter_dict2 = {\n",
    "            'X_data': pd.concat([X_q, result1], axis=1),\n",
    "            'x_cols': x_cols2, 'y_cols': y_cols2,\n",
    "            'out_filename': out_filename2,\n",
    "            'model_filename': models_path + '/fitted_RF/clf2_'+yr+'_'+models_tag,\n",
    "            'tag': 'clf2_'+yr+'_'+models_tag,\n",
    "            'overwrite': overwrite\n",
    "        }\n",
    "        result2 = run_predict_save(predict_save_iter_dict2)\n",
    "        print('Poblacion: ', len(result2)/float(frac))\n",
    "\n",
    "        # Third iteration\n",
    "        predict_save_iter_dict3 = {\n",
    "            'X_data': pd.concat([X_q, result1, result2], axis=1),\n",
    "            'x_cols': x_cols3, 'y_cols': y_cols3,\n",
    "            'out_filename': out_filename3,\n",
    "            'model_filename': models_path + '/fitted_RF/clf3_'+yr+'_'+models_tag,\n",
    "            'tag': 'clf3_'+yr+'_'+models_tag,\n",
    "            'overwrite': overwrite\n",
    "        }\n",
    "        result3 = run_predict_save(predict_save_iter_dict3)\n",
    "        print('Poblacion: ', len(result3)/float(frac))\n",
    "\n",
    "        # Fourth iteration\n",
    "        predict_save_iter_dict4 = {\n",
    "            'X_data': pd.concat([X_q, result1, result2, result3], axis=1),\n",
    "            'x_cols': x_cols4, 'y_cols': columnas_pesos,\n",
    "            'out_filename': out_filename4,\n",
    "            'model_filename': models_path + '/fitted_RF/clf4_'+str(q)[:10]+'_'+models_tag,\n",
    "            'tag': 'clf4_'+yr+'_'+models_tag,\n",
    "            'overwrite': True,\n",
    "        }\n",
    "        result4 = run_predict_save(predict_save_iter_dict4)\n",
    "        print('Poblacion: ', len(result4)/float(frac))\n",
    "\n",
    "                                \n",
    "    del X_censo; #del clf1; del clf2; del clf3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2216657"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_q.reset_index()['ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([73807214819, 30423055419, 34416671619, 30203173819, 91440759019,\n",
       "       84184536919, 78237969419, 79210603819, 57285309219, 26782205619,\n",
       "       ...\n",
       "       93311449219, 46821331819, 21243686719, 44173939819, 45149030219,\n",
       "       65556038619, 51138346319, 25163700219, 73814969119, 42916481319],\n",
       "      dtype='int64', name='ID', length=2216657)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_q.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([6141843519, 7972274719, 7904497319, 6277325019, 4727717819, 1913777819,\n",
       "       3575979319, 8164317919, 9899577019, 3599100819,\n",
       "       ...\n",
       "       3424829519, 4195493619, 2237885319, 8430669719, 5068540419, 4022512119,\n",
       "       9657089119, 4054818819, 2001774219, 9351239519],\n",
       "      dtype='int64', name='ID', length=1285695)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[216], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pd\u001b[39m.\u001b[39;49mconcat([X_q, result1], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/reshape/concat.py:385\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    370\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    372\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    373\u001b[0m     objs,\n\u001b[1;32m    374\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m    383\u001b[0m )\n\u001b[0;32m--> 385\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/reshape/concat.py:612\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m         obj_labels \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39maxes[\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m ax]\n\u001b[1;32m    611\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m new_labels\u001b[39m.\u001b[39mequals(obj_labels):\n\u001b[0;32m--> 612\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39;49mget_indexer(new_labels)\n\u001b[1;32m    614\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[1;32m    616\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[1;32m    617\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_axes, concat_axis\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbm_axis, copy\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[1;32m    618\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexes/base.py:3731\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3728\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3730\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3731\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidIndexError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3733\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   3734\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "pd.concat([X_q, result1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>RADIO_REF_ID</th>\n",
       "      <th>V01</th>\n",
       "      <th>URP</th>\n",
       "      <th>DPTO</th>\n",
       "      <th>AGLOMERADO</th>\n",
       "      <th>HOGAR_REF_ID</th>\n",
       "      <th>H05</th>\n",
       "      <th>H06</th>\n",
       "      <th>H07</th>\n",
       "      <th>...</th>\n",
       "      <th>P05</th>\n",
       "      <th>P07</th>\n",
       "      <th>P08</th>\n",
       "      <th>P09</th>\n",
       "      <th>P10</th>\n",
       "      <th>CONDACT</th>\n",
       "      <th>IX_TOT</th>\n",
       "      <th>AGLO_rk</th>\n",
       "      <th>Reg_rk</th>\n",
       "      <th>Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6141843519</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.833</td>\n",
       "      <td>2019-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7972274719</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.833</td>\n",
       "      <td>2019-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7904497319</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.833</td>\n",
       "      <td>2019-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6277325019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.833</td>\n",
       "      <td>2019-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4727717819</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>32</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.833</td>\n",
       "      <td>2019-02-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  RADIO_REF_ID  V01  URP  DPTO  AGLOMERADO  HOGAR_REF_ID  H05  \\\n",
       "0  6141843519             1  1.0    1  2001          32             2    1   \n",
       "1  7972274719             1  1.0    1  2001          32             3    1   \n",
       "2  7904497319             1  1.0    1  2001          32             3    1   \n",
       "3  6277325019             1  0.0    1  2001          32            40    0   \n",
       "4  4727717819             1  0.0    1  2001          32            44    0   \n",
       "\n",
       "   H06  H07  ...  P05  P07  P08  P09  P10  CONDACT  IX_TOT  AGLO_rk  Reg_rk  \\\n",
       "0  1.0    1  ...    1    1    2    4    1        1       1    0.939   0.833   \n",
       "1  3.0    1  ...    1    1    2    7    2        1       2    0.939   0.833   \n",
       "2  3.0    1  ...    1    1    2    6    1        3       2    0.939   0.833   \n",
       "3  0.0    0  ...    1    1    1    4    2        1       0    0.939   0.833   \n",
       "4  0.0    0  ...    1    1    2    7    2        3       0    0.939   0.833   \n",
       "\n",
       "            Q  \n",
       "0  2019-02-15  \n",
       "1  2019-02-15  \n",
       "2  2019-02-15  \n",
       "3  2019-02-15  \n",
       "4  2019-02-15  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_q.head().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugger\n",
    "# import pandas as pd\n",
    "\n",
    "# # List of filenames\n",
    "# filenames = [\n",
    "#     '/media/matias/Elements/suite/resultados/RFC1_0.01_2019-05-15_ARG.csv',\n",
    "#     '/media/matias/Elements/suite/resultados/RFC2_0.01_2019-05-15_ARG.csv',\n",
    "#     '/media/matias/Elements/suite/resultados/RFC3_0.01_2019-05-15_ARG.csv',\n",
    "#     '/media/matias/Elements/suite/resultados/RFReg_0.01_2019-05-15_ARG.csv'\n",
    "# ]\n",
    "\n",
    "# # Loop through each filename and print the columns\n",
    "# for filename in filenames:\n",
    "#     df = pd.read_csv(filename, nrows=1) # Reading only the first row\n",
    "#     print(f\"Dtypes in {filename}: {df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n",
      "['2005-02-15' '2005-05-15' '2005-08-15' '2005-11-15']\n",
      "Nuevo trimestre.\n",
      "2005-02-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-02-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-02-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-02-15_ARG.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2005-05-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-05-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-05-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-05-15_ARG.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2005-08-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-08-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-08-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-08-15_ARG.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2005-11-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-11-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-11-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-11-15_ARG.csv\n",
      "reg\n"
     ]
    }
   ],
   "source": [
    "# # import sys\n",
    "# # # These are the usual ipython objects, including this one you are creating\n",
    "# # ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "\n",
    "# for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "#     print(yr)\n",
    "#     file_ = '/media/matias/Elements/suite/yr_samples/table_f'+str(frac)+'_'+yr+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#     X_censo = pd.read_csv(file_, usecols = ['DPTO','RADIO_REF_ID','PERSONA_REF_ID', 'HOGAR_REF_ID','IX_TOT', 'P02', 'P03', 'CONDACT', 'AGLOMERADO', 'URP', 'V01', 'H05', 'H06',\n",
    "#            'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14', 'AGLO_rk', 'Reg_rk',\n",
    "#            'H13', 'P07', 'P08', 'P09', 'P10', 'P05']).fillna(0)\n",
    "\n",
    "#     ## Tratamiento trimestral \n",
    "#     qs = np.array(allqs)[[i for i, si in enumerate(allqs) if si.startswith(yr)]]\n",
    "#     print(qs)\n",
    "    \n",
    "#     CONDACT_cnts = X_censo.CONDACT.value_counts()\n",
    "    \n",
    "# #     print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "    \n",
    "#     ### Cargar modelos de la parte no trimestral (anual).\n",
    "#     for q in sorted(qs):\n",
    "        \n",
    "#         ### AJUSTAR NIVEL DE DESEMPLEO\n",
    "#         X_q = X_censo.copy()\n",
    "#         X_q['Q'] = q\n",
    "#         print('Nuevo trimestre.')\n",
    "\n",
    "#         X_q = ajustar_empleo(X_q)\n",
    "\n",
    "# # import sys\n",
    "# # # These are the usual ipython objects, including this one you are creating\n",
    "# # ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "\n",
    "# for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "#     print(yr)\n",
    "#     file_ = '/media/matias/Elements/suite/yr_samples/table_f'+str(frac)+'_'+yr+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#     X_censo = pd.read_csv(file_, usecols = ['DPTO','RADIO_REF_ID','PERSONA_REF_ID', 'HOGAR_REF_ID','IX_TOT', 'P02', 'P03', 'CONDACT', 'AGLOMERADO', 'URP', 'V01', 'H05', 'H06',\n",
    "#            'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14', 'AGLO_rk', 'Reg_rk',\n",
    "#            'H13', 'P07', 'P08', 'P09', 'P10', 'P05']).fillna(0)\n",
    "\n",
    "#     ## Tratamiento trimestral \n",
    "#     qs = np.array(allqs)[[i for i, si in enumerate(allqs) if si.startswith(yr)]]\n",
    "#     print(qs)\n",
    "    \n",
    "#     CONDACT_cnts = X_censo.CONDACT.value_counts()\n",
    "    \n",
    "# #     print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "    \n",
    "#     ### Cargar modelos de la parte no trimestral (anual).\n",
    "#     for q in sorted(qs):\n",
    "        \n",
    "#         ### AJUSTAR NIVEL DE DESEMPLEO\n",
    "#         X_q = X_censo.copy()\n",
    "#         X_q['Q'] = q\n",
    "#         print('Nuevo trimestre.')\n",
    "\n",
    "#         X_q = ajustar_empleo(X_q)\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "        \n",
    "#         print('C1')\n",
    "#         ## CLASIF 1\n",
    "#         X_data = X_q;\n",
    "#         y_cols1 = ['CAT_OCUP', 'CAT_INAC', 'CH07']\n",
    "#         x_cols1 = ['IX_TOT', 'P02', 'P03', 'AGLO_rk', 'Reg_rk', 'V01', 'H05', 'H06',\n",
    "#        'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14',\n",
    "#        'H13', 'P07', 'P08', 'P09', 'P10', 'P05', 'CONDACT']\n",
    "#         out_filename1 = '/media/miglesia/Elements/suite/yr_samples/RFC1_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                      x_cols = x_cols1,\n",
    "#                      y_cols = y_cols1,\n",
    "#                      out_filename = out_filename1,\n",
    "#                      model_filename = models_path + '/fitted_RF/clf1_'+yr+'_'+models_tag,\n",
    "#                      tag = 'clf1_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "        \n",
    "#         del X_q; del X_data\n",
    "# #         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "\n",
    "#         print('C2')\n",
    "#         ## CLASIF 2\n",
    "#         X_data = pd.read_csv(out_filename1)\n",
    "#         y_cols2 = ['INGRESO', 'INGRESO_NLB', 'INGRESO_JUB', 'INGRESO_SBS']\n",
    "#         x_cols2 = x_cols1 + y_cols1\n",
    "#         out_filename2 = '/media/miglesia/Elements/suite/yr_samples/RFC2_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                      x_cols = x_cols2,\n",
    "#                      y_cols = y_cols2,\n",
    "#                      out_filename = out_filename2,\n",
    "#                      model_filename = models_path + '/fitted_RF/clf2_'+yr+'_'+models_tag,\n",
    "#                      tag = 'clf2_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "\n",
    "#         del X_data\n",
    "# #         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "\n",
    "#         print('C3')\n",
    "\n",
    "#         ## CLASIF 3\n",
    "#         X_data = pd.read_csv(out_filename2)\n",
    "#         y_cols3 = ['PP07G1','PP07G_59', 'PP07I', 'PP07J', 'PP07K']\n",
    "#         x_cols3 = x_cols2 + y_cols2\n",
    "#         out_filename3 = '/media/miglesia/Elements/suite/yr_samples/RFC3_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                      x_cols = x_cols3,\n",
    "#                      y_cols = y_cols3,\n",
    "#                      out_filename = out_filename3,\n",
    "#                      model_filename = models_path + '/fitted_RF/clf3_'+yr+'_'+models_tag,\n",
    "#                      tag = 'clf3_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "#         del X_data\n",
    "# #         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "\n",
    "# #         print('reg')\n",
    "# #         # REGRESION\n",
    "# #     \n",
    "#         # Columnas de ingresos. Necesitan una regresion...\n",
    "#         columnas_pesos = [u'P21', u'P47T', u'PP08D1', u'TOT_P12', u'T_VI', u'V12_M', u'V2_M', u'V3_M', u'V5_M']\n",
    "\n",
    "#         x_cols4 = x_cols3 + y_cols3\n",
    "#         y_cols4 = columnas_pesos\n",
    "\n",
    "#         X_data = pd.read_csv(out_filename3)\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                     x_cols = x_cols4,\n",
    "#                     y_cols = columnas_pesos,\n",
    "#                     out_filename = '/media/miglesia/Elements/suite/yr_samples/RFReg_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv',\n",
    "#                     model_filename = models_path + '/fitted_RF/clf4_'+str(q)[:10]+'_'+models_tag,\n",
    "#                     tag = 'clf4_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "                                \n",
    "#     del X_censo; #del clf1; del clf2; del clf3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "1cef6941c3b284b72330916f92da3863815d2ff6730070ac04dc0833f8840e48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
