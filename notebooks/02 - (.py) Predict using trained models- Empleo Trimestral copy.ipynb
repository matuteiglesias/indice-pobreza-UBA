{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on CENSO samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modulos\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar info empleo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0628729377307203"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "empleo = pd.read_csv('https://raw.githubusercontent.com/matuteiglesias/empleoARG/main/datos/45.2_ECTDT.csv')\n",
    "empleo = empleo[['45.2_IT_0_T_13', '45.2_ECTDT_0_T_33']] # ('45.2_ECTDT_0_T_33' es tasa de desocupacion en total aglomerados)\n",
    "empleo['Q'] = pd.to_datetime(empleo['45.2_IT_0_T_13']) + pd.DateOffset(months=1, days = 14)\n",
    "empleo = empleo.set_index('Q').drop(['45.2_IT_0_T_13'], axis = 1)\n",
    "empleo = empleo.replace('s/d', np.nan).astype(float).round(4)\n",
    "empleo['censo2010_ratio'] = (empleo/empleo.loc['2010-11-15'])\n",
    "\n",
    "# **Tasa de desempleo en censo 2010**\n",
    "## notar que la tasa en Aglos, segun el censo, no es igual al valor de la serie de tiempo.\n",
    "# para oct 2010 el censo da (6.29 %) y la que tenemos en dato (7.5%)\n",
    "desoc_C2010 = pd.read_csv('./../data/info/desoc_AGLOsi_C2010.csv')\n",
    "tasa_C2010 = desoc_C2010.loc[desoc_C2010.AGLO_si == True]['Tasa desocupacion'].values[0]\n",
    "tasa_C2010\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de trimestres con modelos ya calculados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "## Trimestres con ingresos disponibles (depende de disponibilidad de microdatos EPH)\n",
    "import glob\n",
    "\n",
    "# path = './../../encuestador-de-hogares/fitted_RF/clf4_' # use your path\n",
    "path = './../../encuestador-de-hogares/fitted_RF/clf4_' # use your path\n",
    "\n",
    "allFiles = []\n",
    "\n",
    "allFiles += glob.glob(path +'*')\n",
    "allFiles = sorted(allFiles)\n",
    "# allFiles[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-02-15_ARG', '-05-15_ARG', '2003-08-15', '2003-11-15', '2004-02-15', '2004-05-15', '2004-08-15', '2004-11-15', '2005-02-15', '2005-05-15']\n",
      "['2020-11-15', '2021-02-15', '2021-05-15', '2021-08-15', '2021-11-15', '2022-02-15', '2022-05-15', '2022-08-15', '2022-11-15', '2023-02-15']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "allqs = [f[-14:-4] for f in allFiles]\n",
    "print(sorted(allqs)[:10])\n",
    "print(sorted(allqs)[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./../data/resultados'):\n",
    "    os.makedirs('./../data/resultados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros\n",
    "\n",
    "### Anios a calcular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTANTE ELEGIR ANIOS\n",
    "startyr = 2022\n",
    "endyr = 2023\n",
    "\n",
    "## Elegir el dataset usado como X:\n",
    "experiment_tag = 'ARG'\n",
    "models_tag = 'ARG'\n",
    "frac = '0.05'\n",
    "\n",
    "# 1174037/(18645609 + 1174037)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Funcion ajustar nivel de empleo\n",
    "\n",
    "\n",
    "def ajustar_empleo(data, q, verbose = False):\n",
    "\n",
    "        ratio = empleo.loc[pd.to_datetime(q)].censo2010_ratio\n",
    "        n_desempleados_ = ratio*(CONDACT_cnts[1] + CONDACT_cnts[2])*tasa_C2010\n",
    "        desemp_adic = round(n_desempleados_ - CONDACT_cnts.loc[2]) # Desempleados adicionales\n",
    "        \n",
    "        print(str(q)[:10])\n",
    "\n",
    "        if desemp_adic > 0:\n",
    "            data.loc[\n",
    "                data.query('CONDACT == 1').sample(desemp_adic).index,\n",
    "                'CONDACT'\n",
    "            ] = 2\n",
    "        elif desemp_adic < 0:\n",
    "            data.loc[\n",
    "                data.query('CONDACT == 2').sample(- desemp_adic).index,\n",
    "                'CONDACT'\n",
    "            ] = 1\n",
    "\n",
    "        if verbose:\n",
    "            desempleo = data.CONDACT.value_counts().loc[2] / (data.CONDACT.value_counts().loc[1] + data.CONDACT.value_counts().loc[2])\n",
    "            print('desempleo:' + str(desempleo))\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# import gc\n",
    "\n",
    "def predict_save(X_data, x_cols, y_cols, model_filename, out_filename, tag, overwrite = False):\n",
    "\n",
    "    # Si todavia no existe la training data de ese anio, o si la opcion overwrite esta activada:\n",
    "    if (not os.path.exists(out_filename)) or (overwrite): \n",
    "        # display(X_data.count())\n",
    "\n",
    "        CLF = joblib.load(model_filename)\n",
    "        \n",
    "        y_out = CLF.predict(X_data[x_cols].values)\n",
    "\n",
    "        ## Listo\n",
    "        y_censo_fit = pd.DataFrame(y_out, index = X_data.index, columns=y_cols)\n",
    "        \n",
    "        # Xy_censo = pd.concat([X_data, y_censo_fit], axis = 1)\n",
    "\n",
    "#             save\n",
    "        y_censo_fit = y_censo_fit.round(5)\n",
    "        if out_filename == '/media/matias/Elements/suite/resultados/RFReg_0.05_2022-08-15_ARG.csv': \n",
    "            out_filename = '/media/matias/Elements/suite/resultados/RFReg_0.05_2022-08-15_ARG_.csv'\n",
    "        print(out_filename)\n",
    "        y_censo_fit.to_csv(out_filename, index = True) #, index_label = 'ID')\n",
    "        print('File saved at '+ out_filename)\n",
    "        del X_data; del CLF\n",
    "\n",
    "    # return y_censo_fit\n",
    "#             gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./../../../repos/encuestador-de-hogares/data/info')\n",
    "from variables import *  # x_cols1, x_cols2, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n",
      "['2022-02-15' '2022-05-15' '2022-08-15' '2022-11-15']\n",
      "Nuevo trimestre.\n",
      "2022-11-15\n",
      "Poblacion:  45385680.0\n",
      "/media/matias/Elements/suite/resultados/RFC1_0.05_2022-11-15_ARG.csv\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC1_0.05_2022-11-15_ARG.csv\n",
      "Poblacion:  45385680.0\n",
      "/media/matias/Elements/suite/resultados/RFC2_0.05_2022-11-15_ARG.csv\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC2_0.05_2022-11-15_ARG.csv\n",
      "Poblacion:  45385680.0\n",
      "/media/matias/Elements/suite/resultados/RFC3_0.05_2022-11-15_ARG.csv\n",
      "File saved at /media/matias/Elements/suite/resultados/RFC3_0.05_2022-11-15_ARG.csv\n",
      "Poblacion:  45385680.0\n",
      "/media/matias/Elements/suite/resultados/RFReg_0.05_2022-11-15_ARG.csv\n",
      "File saved at /media/matias/Elements/suite/resultados/RFReg_0.05_2022-11-15_ARG.csv\n",
      "Poblacion:  45385680.0\n"
     ]
    }
   ],
   "source": [
    "models_path = './../../encuestador-de-hogares'\n",
    "adapted_Censo_files_path = '/media/matias/Elements/suite/poblaciones'\n",
    "\n",
    "def run_predict_save(iter_dict):\n",
    "    predict_save(**iter_dict)\n",
    "    out_filename = iter_dict['out_filename']\n",
    "    if out_filename == '/media/matias/Elements/suite/resultados/RFReg_0.05_2022-08-15_ARG.csv': \n",
    "        out_filename = '/media/matias/Elements/suite/resultados/RFReg_0.05_2022-08-15_ARG_.csv'\n",
    "    return pd.read_csv(out_filename, index_col=['ID'])\n",
    "\n",
    "for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "    print(yr)\n",
    "    file_ = adapted_Censo_files_path + '/table_f'+str(frac)+'_'+yr+'_'+experiment_tag+'.csv'\n",
    "\n",
    "    X_censo = pd.read_csv(file_, usecols = x_cols1 + \n",
    "    ['ID','AGLOMERADO', 'DPTO', 'HOGAR_REF_ID', 'PERSONA_REF_ID', 'RADIO_REF_ID', 'URP'], \n",
    "    index_col=['ID']).fillna(0)\n",
    "\n",
    "    ## Tratamiento trimestral \n",
    "    qs = np.array(allqs)[[i for i, si in enumerate(allqs) if si.startswith(yr)]]\n",
    "    print(qs)\n",
    "    \n",
    "    CONDACT_cnts = X_censo.CONDACT.value_counts()\n",
    "        \n",
    "    ### Cargar modelos de la parte no trimestral (anual).\n",
    "    for q in sorted(qs):\n",
    "        if q in ['2022-11-15']: #######ojo############################################################################\n",
    "\n",
    "            out_filename1 = '/media/matias/Elements/suite/resultados/RFC1_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "            out_filename2 = '/media/matias/Elements/suite/resultados/RFC2_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "            out_filename3 = '/media/matias/Elements/suite/resultados/RFC3_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "            out_filename4 = '/media/matias/Elements/suite/resultados/RFReg_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "            ### AJUSTAR NIVEL DE DESEMPLEO\n",
    "            X_q = X_censo.copy()\n",
    "            X_q['Q'] = q\n",
    "            print('Nuevo trimestre.')\n",
    "\n",
    "            X_q = ajustar_empleo(X_q, q)\n",
    "            print('Poblacion: ', len(X_q)/float(frac))\n",
    "\n",
    "\n",
    "            # Define the first iteration separately\n",
    "            predict_save_iter_dict1 = {\n",
    "                'X_data': X_q,\n",
    "                'x_cols': x_cols1, 'y_cols': y_cols1,\n",
    "                'out_filename': out_filename1,\n",
    "                'model_filename': models_path + '/fitted_RF/clf1_'+yr+'_'+models_tag,\n",
    "                'tag': 'clf1_'+yr+'_'+models_tag,\n",
    "                'overwrite': overwrite\n",
    "            }\n",
    "            result1 = run_predict_save(predict_save_iter_dict1)\n",
    "            print('Poblacion: ', len(result1)/float(frac))\n",
    "\n",
    "            # Second iteration\n",
    "            predict_save_iter_dict2 = {\n",
    "                'X_data': pd.concat([X_q, result1], axis=1),\n",
    "                'x_cols': x_cols2, 'y_cols': y_cols2,\n",
    "                'out_filename': out_filename2,\n",
    "                'model_filename': models_path + '/fitted_RF/clf2_'+yr+'_'+models_tag,\n",
    "                'tag': 'clf2_'+yr+'_'+models_tag,\n",
    "                'overwrite': overwrite\n",
    "            }\n",
    "            result2 = run_predict_save(predict_save_iter_dict2)\n",
    "            print('Poblacion: ', len(result2)/float(frac))\n",
    "\n",
    "            # Third iteration\n",
    "            predict_save_iter_dict3 = {\n",
    "                'X_data': pd.concat([X_q, result1, result2], axis=1),\n",
    "                'x_cols': x_cols3, 'y_cols': y_cols3,\n",
    "                'out_filename': out_filename3,\n",
    "                'model_filename': models_path + '/fitted_RF/clf3_'+yr+'_'+models_tag,\n",
    "                'tag': 'clf3_'+yr+'_'+models_tag,\n",
    "                'overwrite': overwrite\n",
    "            }\n",
    "            result3 = run_predict_save(predict_save_iter_dict3)\n",
    "            print('Poblacion: ', len(result3)/float(frac))\n",
    "\n",
    "            # Fourth iteration\n",
    "            predict_save_iter_dict4 = {\n",
    "                'X_data': pd.concat([X_q, result1, result2, result3], axis=1),\n",
    "                'x_cols': x_cols4, 'y_cols': columnas_pesos,\n",
    "                'out_filename': out_filename4,\n",
    "                'model_filename': models_path + '/fitted_RF/clf4_'+str(q)[:10]+'_'+models_tag,\n",
    "                'tag': 'clf4_'+yr+'_'+models_tag,\n",
    "                'overwrite': True,\n",
    "            }\n",
    "            result4 = run_predict_save(predict_save_iter_dict4)\n",
    "            print('Poblacion: ', len(result4)/float(frac))\n",
    "                                    \n",
    "        # del X_censo; #del clf1; del clf2; del clf3\n",
    "# tarda 5 minutos por quarter, frac = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./../../encuestador-de-hogares/fitted_RF/clf3_2023-02-15_ARG',)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_path + '/fitted_RF/clf3_'+str(q)[:10]+'_'+models_tag,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = './../../encuestador-de-hogares/fitted_RF/clf4_2022-02-15_ARG'\n",
    "model = joblib.load(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m xx\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xx' is not defined"
     ]
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/matias/Elements/suite/resultados/RFReg_0.05_2022-08-15_ARG_.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run_predict_save(predict_save_iter_dict4)\n",
      "Cell \u001b[0;32mIn[90], line 5\u001b[0m, in \u001b[0;36mrun_predict_save\u001b[0;34m(iter_dict)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_predict_save\u001b[39m(iter_dict):\n\u001b[0;32m----> 5\u001b[0m     predict_save(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49miter_dict)\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mread_csv(iter_dict[\u001b[39m'\u001b[39m\u001b[39mout_filename\u001b[39m\u001b[39m'\u001b[39m], index_col\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mID\u001b[39m\u001b[39m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[94], line 24\u001b[0m, in \u001b[0;36mpredict_save\u001b[0;34m(X_data, x_cols, y_cols, model_filename, out_filename, tag, overwrite)\u001b[0m\n\u001b[1;32m     22\u001b[0m     out_filename \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/media/matias/Elements/suite/resultados/RFReg_0.05_2022-08-15_ARG_.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(out_filename)\n\u001b[0;32m---> 24\u001b[0m y_censo_fit\u001b[39m.\u001b[39;49mto_csv(out_filename, index \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m) \u001b[39m#, index_label = 'ID')\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFile saved at \u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m out_filename)\n\u001b[1;32m     26\u001b[0m \u001b[39mdel\u001b[39;00m X_data; \u001b[39mdel\u001b[39;00m CLF\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3761\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m   3763\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3764\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[1;32m   3765\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[1;32m   3770\u001b[0m )\n\u001b[0;32m-> 3772\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[1;32m   3773\u001b[0m     path_or_buf,\n\u001b[1;32m   3774\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[1;32m   3775\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m   3776\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   3777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   3778\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3779\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[1;32m   3780\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   3781\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   3782\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   3783\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   3784\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[1;32m   3785\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   3786\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[1;32m   3787\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[1;32m   3788\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3789\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/io/formats/format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1168\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1169\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[1;32m   1185\u001b[0m )\n\u001b[0;32m-> 1186\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/io/formats/csvs.py:259\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    248\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[1;32m    250\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m    251\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[1;32m    257\u001b[0m     )\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save()\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/io/formats/csvs.py:264\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    263\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_header()\n\u001b[0;32m--> 264\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_body()\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/io/formats/csvs.py:302\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m start_i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m end_i:\n\u001b[1;32m    301\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_chunk(start_i, end_i)\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/io/formats/csvs.py:312\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    309\u001b[0m res \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mto_native_types(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_number_format)\n\u001b[1;32m    310\u001b[0m data \u001b[39m=\u001b[39m [res\u001b[39m.\u001b[39miget_values(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(res\u001b[39m.\u001b[39mitems))]\n\u001b[0;32m--> 312\u001b[0m ix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_index[slicer]\u001b[39m.\u001b[39;49m_format_native_types(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_number_format)\n\u001b[1;32m    313\u001b[0m libwriters\u001b[39m.\u001b[39mwrite_csv_rows(\n\u001b[1;32m    314\u001b[0m     data,\n\u001b[1;32m    315\u001b[0m     ix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter,\n\u001b[1;32m    319\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexes/base.py:1391\u001b[0m, in \u001b[0;36mIndex._format_native_types\u001b[0;34m(self, na_rep, decimal, float_format, date_format, quoting)\u001b[0m\n\u001b[1;32m   1389\u001b[0m mask \u001b[39m=\u001b[39m isna(\u001b[39mself\u001b[39m)\n\u001b[1;32m   1390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_object_dtype(\u001b[39mself\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m quoting:\n\u001b[0;32m-> 1391\u001b[0m     values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n\u001b[1;32m   1392\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1393\u001b[0m     values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_predict_save(predict_save_iter_dict4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/media/matias/Elements/suite/resultados/RFReg_0.05_2019-02-15_ARG.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.round(6).to_csv('./test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>P21</th>\n",
       "      <th>P47T</th>\n",
       "      <th>PP08D1</th>\n",
       "      <th>TOT_P12</th>\n",
       "      <th>T_VI</th>\n",
       "      <th>V12_M</th>\n",
       "      <th>V2_M</th>\n",
       "      <th>V3_M</th>\n",
       "      <th>V5_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73807214819</td>\n",
       "      <td>3.928</td>\n",
       "      <td>3.928</td>\n",
       "      <td>3.928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30423055419</td>\n",
       "      <td>4.239</td>\n",
       "      <td>4.239</td>\n",
       "      <td>4.239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34416671619</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.841</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.841</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30203173819</td>\n",
       "      <td>4.017</td>\n",
       "      <td>4.176</td>\n",
       "      <td>4.017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91440759019</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.563</td>\n",
       "      <td>3.063</td>\n",
       "      <td>3.398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216652</th>\n",
       "      <td>65556038619</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216653</th>\n",
       "      <td>51138346319</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216654</th>\n",
       "      <td>25163700219</td>\n",
       "      <td>4.151</td>\n",
       "      <td>4.151</td>\n",
       "      <td>4.151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216655</th>\n",
       "      <td>73814969119</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216656</th>\n",
       "      <td>42916481319</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2216657 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID    P21   P47T  PP08D1  TOT_P12   T_VI  V12_M   V2_M  \\\n",
       "0        73807214819  3.928  3.928   3.928      0.0  0.000  0.000  0.000   \n",
       "1        30423055419  4.239  4.239   4.239      0.0  0.000  0.000  0.000   \n",
       "2        34416671619  0.000  3.841   0.000      0.0  3.841  0.000  3.841   \n",
       "3        30203173819  4.017  4.176   4.017      0.0  0.000  0.000  0.000   \n",
       "4        91440759019  0.000  3.563   0.000      0.0  3.563  3.063  3.398   \n",
       "...              ...    ...    ...     ...      ...    ...    ...    ...   \n",
       "2216652  65556038619  0.000  0.000   0.000      0.0  0.000  0.000  0.000   \n",
       "2216653  51138346319  4.000  4.000   4.000      0.0  0.000  0.000  0.000   \n",
       "2216654  25163700219  4.151  4.151   4.151      0.0  0.000  0.000  0.000   \n",
       "2216655  73814969119  0.000  0.000   0.000      0.0  0.000  0.000  0.000   \n",
       "2216656  42916481319  0.000  0.000   0.000      0.0  0.000  0.000  0.000   \n",
       "\n",
       "         V3_M  V5_M  \n",
       "0         0.0   0.0  \n",
       "1         0.0   0.0  \n",
       "2         0.0   0.0  \n",
       "3         0.0   0.0  \n",
       "4         0.0   0.0  \n",
       "...       ...   ...  \n",
       "2216652   0.0   0.0  \n",
       "2216653   0.0   0.0  \n",
       "2216654   0.0   0.0  \n",
       "2216655   0.0   0.0  \n",
       "2216656   0.0   0.0  \n",
       "\n",
       "[2216657 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([73807214819, 30423055419, 34416671619, 30203173819, 91440759019,\n",
       "       84184536919, 78237969419, 79210603819, 57285309219, 26782205619,\n",
       "       ...\n",
       "       93311449219, 46821331819, 21243686719, 44173939819, 45149030219,\n",
       "       65556038619, 51138346319, 25163700219, 73814969119, 42916481319],\n",
       "      dtype='int64', name='ID', length=2216657)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_q.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([6141843519, 7972274719, 7904497319, 6277325019, 4727717819, 1913777819,\n",
       "       3575979319, 8164317919, 9899577019, 3599100819,\n",
       "       ...\n",
       "       3424829519, 4195493619, 2237885319, 8430669719, 5068540419, 4022512119,\n",
       "       9657089119, 4054818819, 2001774219, 9351239519],\n",
       "      dtype='int64', name='ID', length=1285695)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[216], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pd\u001b[39m.\u001b[39;49mconcat([X_q, result1], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/reshape/concat.py:385\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    370\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    372\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    373\u001b[0m     objs,\n\u001b[1;32m    374\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m    383\u001b[0m )\n\u001b[0;32m--> 385\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/reshape/concat.py:612\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m         obj_labels \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39maxes[\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m ax]\n\u001b[1;32m    611\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m new_labels\u001b[39m.\u001b[39mequals(obj_labels):\n\u001b[0;32m--> 612\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39;49mget_indexer(new_labels)\n\u001b[1;32m    614\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[1;32m    616\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[1;32m    617\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_axes, concat_axis\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbm_axis, copy\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[1;32m    618\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/indexes/base.py:3731\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3728\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3730\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3731\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidIndexError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3733\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   3734\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "pd.concat([X_q, result1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>RADIO_REF_ID</th>\n",
       "      <th>V01</th>\n",
       "      <th>URP</th>\n",
       "      <th>DPTO</th>\n",
       "      <th>AGLOMERADO</th>\n",
       "      <th>HOGAR_REF_ID</th>\n",
       "      <th>H05</th>\n",
       "      <th>H06</th>\n",
       "      <th>H07</th>\n",
       "      <th>...</th>\n",
       "      <th>P05</th>\n",
       "      <th>P07</th>\n",
       "      <th>P08</th>\n",
       "      <th>P09</th>\n",
       "      <th>P10</th>\n",
       "      <th>CONDACT</th>\n",
       "      <th>IX_TOT</th>\n",
       "      <th>AGLO_rk</th>\n",
       "      <th>Reg_rk</th>\n",
       "      <th>Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6141843519</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.833</td>\n",
       "      <td>2019-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7972274719</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.833</td>\n",
       "      <td>2019-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7904497319</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.833</td>\n",
       "      <td>2019-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6277325019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.833</td>\n",
       "      <td>2019-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4727717819</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>32</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.833</td>\n",
       "      <td>2019-02-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  RADIO_REF_ID  V01  URP  DPTO  AGLOMERADO  HOGAR_REF_ID  H05  \\\n",
       "0  6141843519             1  1.0    1  2001          32             2    1   \n",
       "1  7972274719             1  1.0    1  2001          32             3    1   \n",
       "2  7904497319             1  1.0    1  2001          32             3    1   \n",
       "3  6277325019             1  0.0    1  2001          32            40    0   \n",
       "4  4727717819             1  0.0    1  2001          32            44    0   \n",
       "\n",
       "   H06  H07  ...  P05  P07  P08  P09  P10  CONDACT  IX_TOT  AGLO_rk  Reg_rk  \\\n",
       "0  1.0    1  ...    1    1    2    4    1        1       1    0.939   0.833   \n",
       "1  3.0    1  ...    1    1    2    7    2        1       2    0.939   0.833   \n",
       "2  3.0    1  ...    1    1    2    6    1        3       2    0.939   0.833   \n",
       "3  0.0    0  ...    1    1    1    4    2        1       0    0.939   0.833   \n",
       "4  0.0    0  ...    1    1    2    7    2        3       0    0.939   0.833   \n",
       "\n",
       "            Q  \n",
       "0  2019-02-15  \n",
       "1  2019-02-15  \n",
       "2  2019-02-15  \n",
       "3  2019-02-15  \n",
       "4  2019-02-15  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_q.head().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugger\n",
    "# import pandas as pd\n",
    "\n",
    "# # List of filenames\n",
    "# filenames = [\n",
    "#     '/media/matias/Elements/suite/resultados/RFC1_0.01_2019-05-15_ARG.csv',\n",
    "#     '/media/matias/Elements/suite/resultados/RFC2_0.01_2019-05-15_ARG.csv',\n",
    "#     '/media/matias/Elements/suite/resultados/RFC3_0.01_2019-05-15_ARG.csv',\n",
    "#     '/media/matias/Elements/suite/resultados/RFReg_0.01_2019-05-15_ARG.csv'\n",
    "# ]\n",
    "\n",
    "# # Loop through each filename and print the columns\n",
    "# for filename in filenames:\n",
    "#     df = pd.read_csv(filename, nrows=1) # Reading only the first row\n",
    "#     print(f\"Dtypes in {filename}: {df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n",
      "['2005-02-15' '2005-05-15' '2005-08-15' '2005-11-15']\n",
      "Nuevo trimestre.\n",
      "2005-02-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-02-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-02-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-02-15_ARG.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2005-05-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-05-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-05-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-05-15_ARG.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2005-08-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-08-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-08-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-08-15_ARG.csv\n",
      "reg\n",
      "Nuevo trimestre.\n",
      "2005-11-15\n",
      "C1\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC1_0.01_2005-11-15_ARG.csv\n",
      "C2\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC2_0.01_2005-11-15_ARG.csv\n",
      "C3\n",
      "File saved at /media/miglesia/Elements/suite/yr_samples/RFC3_0.01_2005-11-15_ARG.csv\n",
      "reg\n"
     ]
    }
   ],
   "source": [
    "# # import sys\n",
    "# # # These are the usual ipython objects, including this one you are creating\n",
    "# # ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "\n",
    "# for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "#     print(yr)\n",
    "#     file_ = '/media/matias/Elements/suite/yr_samples/table_f'+str(frac)+'_'+yr+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#     X_censo = pd.read_csv(file_, usecols = ['DPTO','RADIO_REF_ID','PERSONA_REF_ID', 'HOGAR_REF_ID','IX_TOT', 'P02', 'P03', 'CONDACT', 'AGLOMERADO', 'URP', 'V01', 'H05', 'H06',\n",
    "#            'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14', 'AGLO_rk', 'Reg_rk',\n",
    "#            'H13', 'P07', 'P08', 'P09', 'P10', 'P05']).fillna(0)\n",
    "\n",
    "#     ## Tratamiento trimestral \n",
    "#     qs = np.array(allqs)[[i for i, si in enumerate(allqs) if si.startswith(yr)]]\n",
    "#     print(qs)\n",
    "    \n",
    "#     CONDACT_cnts = X_censo.CONDACT.value_counts()\n",
    "    \n",
    "# #     print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "    \n",
    "#     ### Cargar modelos de la parte no trimestral (anual).\n",
    "#     for q in sorted(qs):\n",
    "        \n",
    "#         ### AJUSTAR NIVEL DE DESEMPLEO\n",
    "#         X_q = X_censo.copy()\n",
    "#         X_q['Q'] = q\n",
    "#         print('Nuevo trimestre.')\n",
    "\n",
    "#         X_q = ajustar_empleo(X_q)\n",
    "\n",
    "# # import sys\n",
    "# # # These are the usual ipython objects, including this one you are creating\n",
    "# # ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "\n",
    "# for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "#     print(yr)\n",
    "#     file_ = '/media/matias/Elements/suite/yr_samples/table_f'+str(frac)+'_'+yr+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#     X_censo = pd.read_csv(file_, usecols = ['DPTO','RADIO_REF_ID','PERSONA_REF_ID', 'HOGAR_REF_ID','IX_TOT', 'P02', 'P03', 'CONDACT', 'AGLOMERADO', 'URP', 'V01', 'H05', 'H06',\n",
    "#            'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14', 'AGLO_rk', 'Reg_rk',\n",
    "#            'H13', 'P07', 'P08', 'P09', 'P10', 'P05']).fillna(0)\n",
    "\n",
    "#     ## Tratamiento trimestral \n",
    "#     qs = np.array(allqs)[[i for i, si in enumerate(allqs) if si.startswith(yr)]]\n",
    "#     print(qs)\n",
    "    \n",
    "#     CONDACT_cnts = X_censo.CONDACT.value_counts()\n",
    "    \n",
    "# #     print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "    \n",
    "#     ### Cargar modelos de la parte no trimestral (anual).\n",
    "#     for q in sorted(qs):\n",
    "        \n",
    "#         ### AJUSTAR NIVEL DE DESEMPLEO\n",
    "#         X_q = X_censo.copy()\n",
    "#         X_q['Q'] = q\n",
    "#         print('Nuevo trimestre.')\n",
    "\n",
    "#         X_q = ajustar_empleo(X_q)\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "        \n",
    "#         print('C1')\n",
    "#         ## CLASIF 1\n",
    "#         X_data = X_q;\n",
    "#         y_cols1 = ['CAT_OCUP', 'CAT_INAC', 'CH07']\n",
    "#         x_cols1 = ['IX_TOT', 'P02', 'P03', 'AGLO_rk', 'Reg_rk', 'V01', 'H05', 'H06',\n",
    "#        'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14',\n",
    "#        'H13', 'P07', 'P08', 'P09', 'P10', 'P05', 'CONDACT']\n",
    "#         out_filename1 = '/media/miglesia/Elements/suite/yr_samples/RFC1_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                      x_cols = x_cols1,\n",
    "#                      y_cols = y_cols1,\n",
    "#                      out_filename = out_filename1,\n",
    "#                      model_filename = models_path + '/fitted_RF/clf1_'+yr+'_'+models_tag,\n",
    "#                      tag = 'clf1_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "        \n",
    "#         del X_q; del X_data\n",
    "# #         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "\n",
    "#         print('C2')\n",
    "#         ## CLASIF 2\n",
    "#         X_data = pd.read_csv(out_filename1)\n",
    "#         y_cols2 = ['INGRESO', 'INGRESO_NLB', 'INGRESO_JUB', 'INGRESO_SBS']\n",
    "#         x_cols2 = x_cols1 + y_cols1\n",
    "#         out_filename2 = '/media/miglesia/Elements/suite/yr_samples/RFC2_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                      x_cols = x_cols2,\n",
    "#                      y_cols = y_cols2,\n",
    "#                      out_filename = out_filename2,\n",
    "#                      model_filename = models_path + '/fitted_RF/clf2_'+yr+'_'+models_tag,\n",
    "#                      tag = 'clf2_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "\n",
    "#         del X_data\n",
    "# #         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "\n",
    "#         print('C3')\n",
    "\n",
    "#         ## CLASIF 3\n",
    "#         X_data = pd.read_csv(out_filename2)\n",
    "#         y_cols3 = ['PP07G1','PP07G_59', 'PP07I', 'PP07J', 'PP07K']\n",
    "#         x_cols3 = x_cols2 + y_cols2\n",
    "#         out_filename3 = '/media/miglesia/Elements/suite/yr_samples/RFC3_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv'\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                      x_cols = x_cols3,\n",
    "#                      y_cols = y_cols3,\n",
    "#                      out_filename = out_filename3,\n",
    "#                      model_filename = models_path + '/fitted_RF/clf3_'+yr+'_'+models_tag,\n",
    "#                      tag = 'clf3_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "#         del X_data\n",
    "# #         print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "#         #################################    #################################    #################################\n",
    "\n",
    "# #         print('reg')\n",
    "# #         # REGRESION\n",
    "# #     \n",
    "#         # Columnas de ingresos. Necesitan una regresion...\n",
    "#         columnas_pesos = [u'P21', u'P47T', u'PP08D1', u'TOT_P12', u'T_VI', u'V12_M', u'V2_M', u'V3_M', u'V5_M']\n",
    "\n",
    "#         x_cols4 = x_cols3 + y_cols3\n",
    "#         y_cols4 = columnas_pesos\n",
    "\n",
    "#         X_data = pd.read_csv(out_filename3)\n",
    "\n",
    "#         predict_save(X_data,\n",
    "#                     x_cols = x_cols4,\n",
    "#                     y_cols = columnas_pesos,\n",
    "#                     out_filename = '/media/miglesia/Elements/suite/yr_samples/RFReg_'+str(frac)+'_'+str(q)[:10]+'_'+experiment_tag+'.csv',\n",
    "#                     model_filename = models_path + '/fitted_RF/clf4_'+str(q)[:10]+'_'+models_tag,\n",
    "#                     tag = 'clf4_'+yr+'_'+models_tag,\n",
    "#                     overwrite = overwrite)\n",
    "                                \n",
    "#     del X_censo; #del clf1; del clf2; del clf3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "1cef6941c3b284b72330916f92da3863815d2ff6730070ac04dc0833f8840e48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
