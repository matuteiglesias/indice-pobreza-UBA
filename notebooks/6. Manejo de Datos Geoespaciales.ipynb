{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# time.sleep(2100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Manejo de Datos Geoespaciales.ipynb**\n",
    "  - **4.1. Introducción a niveles geográficos:** Descripción de los niveles geográficos disponibles.\n",
    "  - **4.2. Carga y procesamiento de geometrías:** \n",
    "    - **4.2.1.** Importación de datos de polígonos.\n",
    "    - **4.2.2.** Ajuste del Sistema de Referencia de Coordenadas (CRS).\n",
    "    - **4.2.3.** Cálculo del área en km^2.\n",
    "  - **4.3. Guardado de datos geoespaciales:** \n",
    "    - **4.3.1.** Funciones para guardar datos en formato GeoJSON.\n",
    "    - **4.3.2.** Procesamiento y guardado de datos en diferentes niveles geográficos.\n",
    "\n",
    "---\n",
    "\n",
    "**CONTENIDO**\n",
    "\n",
    "- Cargar data CS\n",
    "- Resultados Complejos observables en CS\n",
    "- Procesamiento para datasets geograficos\n",
    "    - Mapas Ejemplo (Base Personas)\n",
    "    - Comandos Mapbox CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from funciones import generate_Qs_from_year\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------\n",
    "# Parameters and Configuration\n",
    "# -------------------\n",
    "\n",
    "FRAC = 0.01\n",
    "START_YEAR = 2015\n",
    "END_YEAR = 2019\n",
    "EXPERIMENT_TAG = 'ARG'\n",
    "\n",
    "PATH_POBREZA = './../data/Pobreza/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Cargar el índice de precios al consumidor (CPI) desde la fuente\n",
    "cpi = pd.read_csv('https://raw.githubusercontent.com/matuteiglesias/IPC-Argentina/main/data/info/indice_precios_M.csv', index_col=0)\n",
    "cpi.index = pd.to_datetime(cpi.index)\n",
    "\n",
    "# Obtener la fecha de hoy en formato año-mes\n",
    "hoy = datetime.today().strftime('%Y-%m')\n",
    "\n",
    "# Calcular el ratio de precios de hoy con respecto a los precios con índice en base al modelo\n",
    "ix = cpi.loc[hoy, 'index'].values[0] / cpi.loc['2016-01', 'index'].values[0]\n",
    "\n",
    "# Lista de columnas relacionadas con montos en pesos\n",
    "columnas_pesos = ['P47T_persona', 'P47T_hogar', 'CBA', 'gap_indigencia', 'CBT', 'gap_pobreza']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for year 2021...\n",
      "Procesando fecha Q: 2021-02-15\n",
      "Procesando fecha Q: 2021-05-15\n",
      "Procesando fecha Q: 2021-08-15\n",
      "Procesando fecha Q: 2021-11-15\n",
      "Processing data for year 2022...\n",
      "Procesando fecha Q: 2022-02-15\n",
      "Procesando fecha Q: 2022-05-15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/matias/repos/indice-pobreza-UBA/notebooks/6. Manejo de Datos Geoespaciales.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matias/repos/indice-pobreza-UBA/notebooks/6.%20Manejo%20de%20Datos%20Geoespaciales.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m hogares_geo \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(hogares_geo_file)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matias/repos/indice-pobreza-UBA/notebooks/6.%20Manejo%20de%20Datos%20Geoespaciales.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Fusiones para obtener los datasets consolidados\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/matias/repos/indice-pobreza-UBA/notebooks/6.%20Manejo%20de%20Datos%20Geoespaciales.ipynb#W5sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m info_personas \u001b[39m=\u001b[39m personas_ingresos_Q\u001b[39m.\u001b[39;49mmerge(pobreza_hogares, on\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mHOGAR_REF_ID\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mQ\u001b[39;49m\u001b[39m'\u001b[39;49m], how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mmerge(hogares_geo, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mHOGAR_REF_ID\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matias/repos/indice-pobreza-UBA/notebooks/6.%20Manejo%20de%20Datos%20Geoespaciales.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m info_hogares \u001b[39m=\u001b[39m pobreza_hogares\u001b[39m.\u001b[39mmerge(hogares_geo, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mHOGAR_REF_ID\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matias/repos/indice-pobreza-UBA/notebooks/6.%20Manejo%20de%20Datos%20Geoespaciales.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Añadir los conjuntos de datos consolidados a las listas\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/frame.py:9843\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   9824\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   9825\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m   9826\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9839\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   9840\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   9841\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmerge\u001b[39;00m \u001b[39mimport\u001b[39;00m merge\n\u001b[0;32m-> 9843\u001b[0m     \u001b[39mreturn\u001b[39;00m merge(\n\u001b[1;32m   9844\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   9845\u001b[0m         right,\n\u001b[1;32m   9846\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m   9847\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m   9848\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[1;32m   9849\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[1;32m   9850\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[1;32m   9851\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[1;32m   9852\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   9853\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[1;32m   9854\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   9855\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[1;32m   9856\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m   9857\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/reshape/merge.py:162\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    132\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    147\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m    148\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    149\u001b[0m         left,\n\u001b[1;32m    150\u001b[0m         right,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result(copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/reshape/merge.py:809\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n\u001b[1;32m    807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[0;32m--> 809\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_join_info()\n\u001b[1;32m    811\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_and_concat(\n\u001b[1;32m    812\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    813\u001b[0m )\n\u001b[1;32m    814\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_type)\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1065\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     join_index, right_indexer, left_indexer \u001b[39m=\u001b[39m _left_join_on_index(\n\u001b[1;32m   1062\u001b[0m         right_ax, left_ax, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys, sort\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort\n\u001b[1;32m   1063\u001b[0m     )\n\u001b[1;32m   1064\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1065\u001b[0m     (left_indexer, right_indexer) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_join_indexers()\n\u001b[1;32m   1067\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_index:\n\u001b[1;32m   1068\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1038\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_join_indexers\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mintp], npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mintp]]:\n\u001b[1;32m   1037\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"return the join indexers\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1038\u001b[0m     \u001b[39mreturn\u001b[39;00m get_join_indexers(\n\u001b[1;32m   1039\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleft_join_keys, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mright_join_keys, sort\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msort, how\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhow\n\u001b[1;32m   1040\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1665\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[0;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m \u001b[39m# get left & right join labels and num. of levels at each location\u001b[39;00m\n\u001b[1;32m   1661\u001b[0m mapped \u001b[39m=\u001b[39m (\n\u001b[1;32m   1662\u001b[0m     _factorize_keys(left_keys[n], right_keys[n], sort\u001b[39m=\u001b[39msort, how\u001b[39m=\u001b[39mhow)\n\u001b[1;32m   1663\u001b[0m     \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(left_keys))\n\u001b[1;32m   1664\u001b[0m )\n\u001b[0;32m-> 1665\u001b[0m zipped \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mmapped)\n\u001b[1;32m   1666\u001b[0m llab, rlab, shape \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m zipped)\n\u001b[1;32m   1668\u001b[0m \u001b[39m# get flat i8 keys from label lists\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1662\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1658\u001b[0m         \u001b[39mreturn\u001b[39;00m _get_no_sort_one_missing_indexer(left_n, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1660\u001b[0m \u001b[39m# get left & right join labels and num. of levels at each location\u001b[39;00m\n\u001b[1;32m   1661\u001b[0m mapped \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 1662\u001b[0m     _factorize_keys(left_keys[n], right_keys[n], sort\u001b[39m=\u001b[39;49msort, how\u001b[39m=\u001b[39;49mhow)\n\u001b[1;32m   1663\u001b[0m     \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(left_keys))\n\u001b[1;32m   1664\u001b[0m )\n\u001b[1;32m   1665\u001b[0m zipped \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mmapped)\n\u001b[1;32m   1666\u001b[0m llab, rlab, shape \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m zipped)\n",
      "File \u001b[0;32m~/anaconda3/envs/base2/lib/python3.11/site-packages/pandas/core/reshape/merge.py:2429\u001b[0m, in \u001b[0;36m_factorize_keys\u001b[0;34m(lk, rk, sort, how)\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2425\u001b[0m     \u001b[39m# Argument 1 to \"factorize\" of \"ObjectFactorizer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   2426\u001b[0m     \u001b[39m# \"Union[ndarray[Any, dtype[signedinteger[_64Bit]]],\u001b[39;00m\n\u001b[1;32m   2427\u001b[0m     \u001b[39m# ndarray[Any, dtype[object_]]]\"; expected \"ndarray[Any, dtype[object_]]\"\u001b[39;00m\n\u001b[1;32m   2428\u001b[0m     llab \u001b[39m=\u001b[39m rizer\u001b[39m.\u001b[39mfactorize(lk)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m-> 2429\u001b[0m     rlab \u001b[39m=\u001b[39m rizer\u001b[39m.\u001b[39;49mfactorize(rk)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   2430\u001b[0m \u001b[39massert\u001b[39;00m llab\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mintp), llab\u001b[39m.\u001b[39mdtype\n\u001b[1;32m   2431\u001b[0m \u001b[39massert\u001b[39;00m rlab\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mintp), rlab\u001b[39m.\u001b[39mdtype\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# data = pd.read_csv('/media/matias/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_0.02_ARGCSactual.csv', encoding_errors='ignore')\n",
    "#                     # /media/matias/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_0.02_ARGCSactual.csv\n",
    "# ## Deflacta a precios actuales\n",
    "\n",
    "# # Lista de fechas Q que se van a procesar\n",
    "# Qs = ['2022-05-15', '2022-08-15', '2022-11-15', '2023-02-15']\n",
    "\n",
    "# Listas para almacenar los datos consolidados de cada Q\n",
    "all_info_personas = []\n",
    "all_info_hogares = []\n",
    "\n",
    "# Loop through the years\n",
    "for yr in range(2021, 2023):\n",
    "    yr = str(yr)  # Convert year to string for consistency with quarters\n",
    "    print(f\"Processing data for year {yr}...\")\n",
    "\n",
    "    # Processing data for each quarter of the specified year\n",
    "    relevant_quarters = generate_Qs_from_year(yr)\n",
    "    for Q in relevant_quarters:\n",
    "        print(f\"Procesando fecha Q: {Q}\")\n",
    "        \n",
    "        # Nombres de los archivos dependientes de Q\n",
    "        personas_ingresos_Q_file = f'{PATH_POBREZA}personas_ingresos_f{FRAC}_{Q}_{EXPERIMENT_TAG}.csv'\n",
    "        pobreza_hogares_file = f'{PATH_POBREZA}pobreza_hogares_f{FRAC}_q{Q}.csv'\n",
    "        hogares_geo_file = f'{PATH_POBREZA}hogares_geo_f{FRAC}_{Q.split(\"-\")[0]}_{EXPERIMENT_TAG}.csv'\n",
    "\n",
    "        # Cargar los archivos\n",
    "        personas_ingresos_Q = pd.read_csv(personas_ingresos_Q_file)\n",
    "        pobreza_hogares = pd.read_csv(pobreza_hogares_file)\n",
    "        hogares_geo = pd.read_csv(hogares_geo_file)\n",
    "\n",
    "        # Fusiones para obtener los datasets consolidados\n",
    "        info_personas = personas_ingresos_Q.merge(pobreza_hogares, on=['HOGAR_REF_ID', 'Q'], how='left').merge(hogares_geo, on='HOGAR_REF_ID', how='left')\n",
    "        info_hogares = pobreza_hogares.merge(hogares_geo, on='HOGAR_REF_ID', how='left')\n",
    "        \n",
    "        # Añadir los conjuntos de datos consolidados a las listas\n",
    "        all_info_personas.append(info_personas)\n",
    "        all_info_hogares.append(info_hogares)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Concatenar todos los conjuntos de datos de las diferentes fechas\n",
    "cross_section_personas = pd.concat(all_info_personas, ignore_index=True)\n",
    "cross_section_hogares = pd.concat(all_info_hogares, ignore_index=True)\n",
    "\n",
    "\n",
    "## Adaptar datos (Pesos actuales, AGLOS si, IDFRAC)\n",
    "for df in [cross_section_personas, cross_section_hogares]:\n",
    "    for col in columnas_pesos:\n",
    "        if col in df.columns: \n",
    "            if col == 'P47T_persona': df[col] = np.power(10, df[col]) - 1\n",
    "            df[col] = (ix*df[col]).round(-1).astype(int)\n",
    "            \n",
    "    # df = df.merge(radio_ref, axis = 1), on = ['RADIO_REF_ID', 'AGLOMERADO'], how = 'left')\n",
    "    df['AGLOSI'] = df.AGLOMERADO != 0\n",
    "\n",
    "    df['IDFRAC'] = df['COD_2010'].astype(str).str.zfill(9).str[:-2] + '00'\n",
    "\n",
    "\n",
    "# -------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/shapely/measurement.py:45: RuntimeWarning: invalid value encountered in area\n",
      "  return lib.area(geometry, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "def compute_area_km2(geo_df):\n",
    "    \"\"\"Calcula el área en km^2 de un GeoDataFrame y lo añade como una nueva columna.\"\"\"\n",
    "    geo_df['area_km2'] = geo_df['geometry'].to_crs('epsg:3395').map(lambda p: p.area / 10**6)\n",
    "    return geo_df\n",
    "\n",
    "# Rutas de los archivos de polígonos\n",
    "admin310_f = './../../geoespacial-censo-IGN/censos_shp_CONICET_dissolved/fracs_2010.shp'\n",
    "admin210_f = './../../geoespacial-censo-IGN/censos_shp_CONICET_dissolved/dptos_2010.shp'\n",
    "admin1_f = './../../geoespacial-censo-IGN/IGN_shp/ign_provincia'\n",
    "\n",
    "# Cargar polígonos de provincias del IGN\n",
    "admin1 = gpd.read_file(admin1_f)\n",
    "admin1['PROV'] = admin1.IN1.astype(int)\n",
    "admin1 = admin1[['PROV', 'geometry']]\n",
    "\n",
    "# Cargar y procesar polígonos de fracciones de CONICET\n",
    "admin310 = gpd.read_file(admin310_f)\n",
    "admin310['IDFRAC'] = admin310.PROV_ + admin310.DEPTO_ + admin310.FRACC_ + '00'\n",
    "admin310 = admin310[['IDFRAC', 'geometry']]\n",
    "\n",
    "# Cargar y procesar polígonos de departamentos de CONICET\n",
    "admin210 = gpd.read_file(admin210_f)\n",
    "admin210['DPTO'] = (admin210['PROV_'] + admin210['DEPTO_']).astype(int)\n",
    "admin210 = admin210[['DPTO', 'geometry']]\n",
    "\n",
    "# Ajustar CRS para que todos los GeoDataFrames tengan el mismo CRS que admin1\n",
    "admin210 = admin210.to_crs(admin1.crs)\n",
    "admin310 = admin310.to_crs(admin1.crs)\n",
    "\n",
    "# Calcular el área en km^2 para cada GeoDataFrame\n",
    "admin1 = compute_area_km2(admin1)\n",
    "admin210 = compute_area_km2(admin210)\n",
    "admin310 = compute_area_km2(admin310)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROV           int64\n",
      "geometry    geometry\n",
      "area_km2     float64\n",
      "dtype: object\n",
      "DPTO           int64\n",
      "geometry    geometry\n",
      "area_km2     float64\n",
      "dtype: object\n",
      "IDFRAC        object\n",
      "geometry    geometry\n",
      "area_km2     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OBJECTID', 'Entidad', 'Objeto', 'FNA', 'GNA', 'NAM', 'SAG', 'FDC',\n",
       "       'IN1', 'SHAPE_STAr', 'SHAPE_STLe', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PROV_', 'DEPTO_', 'geometry'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PROV_', 'DEPTO_', 'FRACC_', 'geometry'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funciones import process_and_save\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando subset 'P' a nivel geografico 'PROV'...\n",
      "Procesamiento de subset 'P' a nivel geografico 'PROV' completado.\n",
      "Procesando subset 'P' a nivel geografico 'DPTO'...\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_203935/187950249.py\", line 25, in <module>\n",
      "    process_and_save(subset, grouper, geo_df, filename_prefix)\n",
      "  File \"/home/matias/repos/indice-pobreza-UBA/notebooks/funciones.py\", line 547, in process_and_save\n",
      "  File \"/home/matias/repos/indice-pobreza-UBA/notebooks/funciones.py\", line 532, in save_geojson\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/geopandas/geodataframe.py\", line 1263, in to_file\n",
      "    _to_file(self, filename, driver, schema, index, **kwargs)\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/geopandas/io/file.py\", line 572, in _to_file\n",
      "    _to_file_fiona(df, filename, driver, schema, crs, mode, **kwargs)\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/geopandas/io/file.py\", line 601, in _to_file_fiona\n",
      "    colxn.writerecords(df.iterfeatures())\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/fiona/collection.py\", line 558, in writerecords\n",
      "    self.session.writerecs(records, self)\n",
      "  File \"fiona/ogrext.pyx\", line 1409, in fiona.ogrext.WritingSession.writerecs\n",
      "  File \"fiona/ogrext.pyx\", line 426, in fiona.ogrext.OGRFeatureBuilder.build\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/fiona/model.py\", line 343, in properties\n",
      "    @property\n",
      "    \n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1428, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1319, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1172, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1087, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 969, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/home/matias/anaconda3/envs/base2/lib/python3.11/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# Define los GeoDataFrames para cada nivel geográfico\n",
    "geo_dfs = {\n",
    "    'PROV': admin1,\n",
    "    'DPTO': admin210,\n",
    "    'IDFRAC': admin310\n",
    "}\n",
    "\n",
    "# Define los subconjuntos de datos y sus prefijos correspondientes para los nombres de los archivos\n",
    "data_subsets = {\n",
    "    'P': cross_section_personas,\n",
    "    'M24': cross_section_personas[cross_section_personas.P03 >= 24],\n",
    "    'M14': cross_section_personas[cross_section_personas.P03 <= 14],\n",
    "    'M6': cross_section_personas[cross_section_personas.P03 <= 6],\n",
    "    'H': cross_section_hogares  # Asumiendo que data también incluye información de hogares\n",
    "}\n",
    "\n",
    "ow = False  # Sobrescribir archivos existentes\n",
    "# Procesar y guardar los datos para cada subconjunto y nivel geográfico\n",
    "for filename_prefix, subset in data_subsets.items():\n",
    "    for geo_level, geo_df in geo_dfs.items():\n",
    "        print(f\"Procesando subset '{filename_prefix}' a nivel geografico '{geo_level}'...\")\n",
    "        \n",
    "        if not ow and os.path.exists(f'poverty_{filename_prefix}_{geo_level}_sample{FRAC}.geojson'): continue\n",
    "        \n",
    "        process_and_save(subset, geo_level, geo_df, filename_prefix)\n",
    "        print(f\"Procesamiento de subset '{filename_prefix}' a nivel geografico '{geo_level}' completado.\")\n",
    "    print(f\"Procesamiento completo para subset '{filename_prefix}'.\")\n",
    "print(\"Todos los procesamientos han sido completados.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_and_save(subset, geo_level, geo_df, filename_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename_prefix, geo_level, FRAC in :\n",
    "    print(f\"Procesando subset '{filename_prefix}' a nivel geografico '{geo_level}'...\")\n",
    "    f'pobreza_{filename_prefix}_{geo_level}_{FRAC}.geojson'\n",
    "    display()\n",
    "    \n",
    "    process_and_save(subset, geo_level, geo_df, filename_prefix)\n",
    "    print(f\"Procesamiento de subset '{filename_prefix}' a nivel geografico '{geo_level}' completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
