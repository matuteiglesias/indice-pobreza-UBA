{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_columns = 60\n",
    "pd.options.display.max_rows = 500\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adulto equivalente. Cuanto cuesta la manutencion de las personas segun sexo y edad.\n",
    "ad_eq = pd.read_csv('./../data/info/adulto_eq.csv')\n",
    "\n",
    "#Importar canasta basica regional deflac\n",
    "CB_ipc = pd.read_csv('./../data/info/CB_Reg_defl.csv')\n",
    "\n",
    "ppp_defl = pd.read_csv('./../data/info/ppp_defl.csv')\n",
    "\n",
    "# Load radio ref. Merge regiones.\n",
    "# Anything that is AGLOMERADO 33 should be region Gran Buenos Aires\n",
    "\n",
    "# radio_ref = pd.read_csv('./../data/info/radio_ref.csv').merge(pd.read_csv('./../data/info/prov_regs.csv'), how = 'left')\n",
    "\n",
    "radio_ref = pd.read_csv('./../data/info/radio_ref.csv')#.merge(aglo_labels)\n",
    "dpto_region = pd.read_csv('./../data/info/DPTO_PROV_Region.csv')\n",
    "## Fix temporario, migracion a nombres de region oficiales\n",
    "dpto_region['Region'] = dpto_region['Region'].map({'Gran Buenos Aires':'gran_buenos_aires', \n",
    "                                                   'Pampeana':'pampeana', 'Noroeste':'noroeste', \n",
    "                                                   'Noreste':'noreste','Patag√≥nica': 'patagonia', 'Cuyo': 'cuyo'})\n",
    "\n",
    "radio_ref = radio_ref.merge(dpto_region)\n",
    "\n",
    "# DPTO_Region = radio_ref[['DPTO', 'Region']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpto_region = pd.read_csv('./../data/info/DPTO_PROV_Region.csv')\n",
    "DPTO_Region = radio_ref[['DPTO', 'Region']].drop_duplicates()\n",
    "\n",
    "if not os.path.exists('./../data/Pobreza/'):\n",
    "    os.makedirs('./../data/Pobreza/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Resultados series de tiempo (se computa para todos y cada trimestre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2010-02-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2010-05-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2010-08-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2010-11-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2011-02-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2011-05-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2011-08-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2011-11-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2012-02-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2012-05-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2012-08-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2012-11-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2013-02-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2013-05-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2013-08-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2013-11-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2014-02-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2014-05-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2014-08-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2014-11-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2015-02-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2015-05-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2016-05-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2016-08-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2016-11-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2017-02-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2017-05-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2017-08-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2017-11-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2018-02-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2018-05-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2018-08-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2018-11-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2019-02-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2019-05-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2019-08-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2019-11-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2020-02-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2020-05-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2020-08-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2020-11-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2021-02-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2021-05-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2021-08-15_ARG.csv',\n",
       " '/media/miglesia/Elements/suite/yr_samples/RFReg_0.01_2021-11-15_ARG.csv']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from pathlib import Path    \n",
    "\n",
    "# path ='./data/RFReg_' # use your path\n",
    "# path ='./../data/yr_samples/RFReg_' # use your path\n",
    "# path ='./../../encuestador-de-hogares/data/yr_samples/RFReg_' # use your path\n",
    "path ='./../../indice-pobreza-ExactasUBA/data/yr_samples/RFReg_' # use your path\n",
    "path ='./../data/yr_samples/RFReg_'\n",
    "path ='/media/miglesia/Elements/suite/yr_samples/RFReg_'\n",
    "\n",
    "\n",
    "allFiles = []\n",
    "for year in [str(s) for s in range(2010, 2022)]: ## Importante poner el anio de comienzo de la serie\n",
    "    # Estos archivos se computan en la notebook tipo 02c - Predict using trained models- Empleo Trimestral.ipynb\n",
    "    allFiles += glob.glob(path +str(frac)+'_'+ year +'*.csv')\n",
    "sorted(allFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # path +str(frac)+'_'+ year +'*.csv'\n",
    "# '/media/miglesia/Elements/suite/yr_samples/RFReg_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ingresos_a_pobreza(df_ingresos, filename, columnas_pesos = ['P47T']):\n",
    "\n",
    "    df_ingresos[columnas_pesos] = np.power(10, df_ingresos[columnas_pesos]) - 1\n",
    "    \n",
    "    # Editar columnas:\n",
    "    ## Nivel Educativo\n",
    "    df_ingresos['P10'] = 2 - df_ingresos['P10']  ## Re codificacion de pregunta 'termino el nivel'\n",
    "    df_ingresos['P09'] = df_ingresos.P09.replace(5, 4) # Polimodal tomado como secundario \n",
    "    df_ingresos['P0910'] = df_ingresos.P09.astype(str) + df_ingresos.P10.astype(str)\n",
    "    \n",
    "    ## Grupos Etarios\n",
    "    df_ingresos['Grupo_Etario_3'] = pd.cut(df_ingresos.P03, np.arange(-1, 80, 3)).astype(str)#.round(-1)\n",
    "    df_ingresos['Grupo_Etario_INDEC'] = pd.cut(df_ingresos.P03, np.array([0, 13, 29, 64, 110])).astype(str)#.round(-1)\n",
    "    df_ingresos['Grupo_Etario_q10'] = pd.cut(df_ingresos.P03, np.array([-0.001, 5.0,  11.0, 17.0, 23.0, 29.0, 36.0, 44.0, 53.0, 65.0, 110.0])).astype(str)#.round(-1)\n",
    "    # df = pd.read_csv('file.csv', dtype={'Col' : 'category'}) # Despues podemos necesitar...\n",
    "\n",
    "    df = df_ingresos.reset_index()\n",
    "\n",
    "    ## CANASTA: Datos mergeado con adulto equivalente, region y serie de tiempo canasta\n",
    "    df_cb = df_ingresos.merge(ad_eq).merge(DPTO_Region).merge(CB_ipc)#.merge(ppp_defl[['Q', 'ppp_5usd_ARS_deflac']])\n",
    "\n",
    "    ## VARIABLES A NIVEL HOGARES\n",
    "#     df_cb_hogares = df_cb.groupby(['HOGAR_REF_ID', 'Q'])[['P47T','CBA', 'CBT', 'CB_EQUIV', 'ppp_5usd_ARS_deflac']].sum()\n",
    "    df_cb_hogares = df_cb.groupby(['HOGAR_REF_ID', 'Q'])[['P47T','CBA', 'CBT', 'CB_EQUIV']].sum()\n",
    "    df_cb_hogares['Pobreza'] = df_cb_hogares['P47T'] < df_cb_hogares['CBT']\n",
    "    df_cb_hogares['Indigencia'] = df_cb_hogares['P47T'] < df_cb_hogares['CBA']\n",
    "#     df_cb_hogares['Pobreza_5usd'] = df_cb_hogares['P47T'] < df_cb_hogares['ppp_5usd_ARS_deflac']\n",
    "#     pobreza_hogares = df_cb_hogares[['P47T','CBA','CBT', 'CB_EQUIV','Pobreza', 'Indigencia', 'Pobreza_5usd']].reset_index()\n",
    "    pobreza_hogares = df_cb_hogares[['P47T','CBA','CBT', 'CB_EQUIV','Pobreza', 'Indigencia']].reset_index()\n",
    "    pobreza_hogares['gap_pobreza'] = pobreza_hogares.P47T - pobreza_hogares.CBT\n",
    "    pobreza_hogares['gap_indigencia'] = pobreza_hogares.P47T - pobreza_hogares.CBA\n",
    "    pobreza_hogares = pobreza_hogares.rename(columns = {'P47T': 'P47T_hogar'})\n",
    "\n",
    "    ## UNION DE DATOS DE HOGARES A REGISTROS INDIVIDUALES\n",
    "    data = df_ingresos.merge(pobreza_hogares, on = ['HOGAR_REF_ID', 'Q'])#, how = 'left')\n",
    "    del df; del pobreza_hogares # Ahorrar memoria\n",
    "    data = data.rename(columns = {'P47T': 'P47T_persona'}) # Renombrar la variable P47T para aclarar que es a nivel persona.\n",
    "\n",
    "    ## UNIR INFO GEOGRAFICA\n",
    "    data = data.merge(radio_ref[['RADIO_REF_ID', 'IDFRAC', 'PROV', 'NOMPROV', 'AGLOMERADO', 'Region']].drop_duplicates())\n",
    "\n",
    "    print(\"Poblacion: \"+str(len(data)/frac))\n",
    "#     display(data[['Pobreza', 'Indigencia', 'Pobreza_5usd']].mean())\n",
    "    data.to_csv(filename, index = False) ## Aca si ya existen no deberian sobreescribirse (o si)\n",
    "    \n",
    "    print(filename+' saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-15\n",
      "Poblacion: 44923900.0\n",
      "./../data/Pobreza/pobreza_0.01_q2021-08-15.csv saved\n",
      "2021-11-15\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-7d0f3ae96da5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     if not os.path.exists('./../data/Pobreza/pobreza_'+'_'.join([str(frac), 'q'+q])+'.csv'):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     df = pd.read_csv(quarter_Xy_file, \n\u001b[0m\u001b[1;32m      8\u001b[0m                            usecols = ['PERSONA_REF_ID', 'HOGAR_REF_ID','RADIO_REF_ID', 'CONDACT', 'CAT_INAC', 'CAT_OCUP',\n\u001b[1;32m      9\u001b[0m                                       \u001b[0;34m'INGRESO'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'INGRESO_NLB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'INGRESO_JUB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'INGRESO_SBS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PP07K'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "for quarter_Xy_file in sorted(allFiles)[-2:]:\n",
    "       \n",
    "    q = quarter_Xy_file[-18:-8]\n",
    "    print(q)\n",
    "#     if not os.path.exists('./../data/Pobreza/pobreza_'+'_'.join([str(frac), 'q'+q])+'.csv'):\n",
    "\n",
    "    df = pd.read_csv(quarter_Xy_file, \n",
    "                           usecols = ['PERSONA_REF_ID', 'HOGAR_REF_ID','RADIO_REF_ID', 'CONDACT', 'CAT_INAC', 'CAT_OCUP',\n",
    "                                      'INGRESO', 'INGRESO_NLB', 'INGRESO_JUB', 'INGRESO_SBS', 'PP07K',\n",
    "                                      'IX_TOT', 'H16', 'H15','P47T', 'P03','P02', 'P09','P10', 'DPTO', 'URP'])\n",
    "    df['ANO4'] = int(quarter_Xy_file[-18:-14])\n",
    "    df['Q'] = q\n",
    "\n",
    "    ingresos_a_pobreza(df_ingresos = df, filename = '/media/miglesia/Elements/suite/indice-pobreza-ExactasUBA/data/Pobreza/pobreza_'+'_'.join([str(frac), 'q'+q])+'.csv', columnas_pesos = ['P47T'])\n",
    "\n",
    "#     columnas_pesos = ['P47T']\n",
    "#     df[columnas_pesos] = np.power(10, df[columnas_pesos]) - 1\n",
    "    \n",
    "#     # Editar columnas\n",
    "#     df['P10'] = 2 - df['P10']\n",
    "#     df['P09'] = df.P09.replace(5, 4) #Polimodal tomado como secundario \n",
    "\n",
    "# #     df = df.astype(int)\n",
    "#     df['P0910'] = df.P09.astype(str) + df.P10.astype(str)\n",
    "#     df['Grupo_Etario_3'] = pd.cut(df.P03, np.arange(-1, 80, 3)).astype(str)#.round(-1)\n",
    "#     df['Grupo_Etario_INDEC'] = pd.cut(df.P03, np.array([0, 13, 29, 64, 110])).astype(str)#.round(-1)\n",
    "#     df['Grupo_Etario_q10'] = pd.cut(df.P03, np.array([-0.001, 5.0,  11.0, 17.0, 23.0, 29.0, 36.0, 44.0, 53.0, 65.0, 110.0])).astype(str)#.round(-1)\n",
    "# # df = pd.read_csv('file.csv', dtype={'Col' : 'category'}) # Despues podemos necesitar...\n",
    "\n",
    "#     df = df.reset_index()\n",
    "\n",
    "#     df_cb = df.merge(ad_eq).merge(DPTO_Region).merge(CB_ipc)#.merge(ppp_defl[['Q', 'ppp_5usd_ARS_deflac']])\n",
    "\n",
    "# #     df_cb_hogares = df_cb.groupby(['HOGAR_REF_ID', 'Q'])[['P47T','CBA', 'CBT', 'CB_EQUIV', 'ppp_5usd_ARS_deflac']].sum()\n",
    "#     df_cb_hogares = df_cb.groupby(['HOGAR_REF_ID', 'Q'])[['P47T','CBA', 'CBT', 'CB_EQUIV']].sum()\n",
    "#     df_cb_hogares['Pobreza'] = df_cb_hogares['P47T'] < df_cb_hogares['CBT']\n",
    "#     df_cb_hogares['Indigencia'] = df_cb_hogares['P47T'] < df_cb_hogares['CBA']\n",
    "# #     df_cb_hogares['Pobreza_5usd'] = df_cb_hogares['P47T'] < df_cb_hogares['ppp_5usd_ARS_deflac']\n",
    "# #     pobreza_hogares = df_cb_hogares[['P47T','CBA','CBT', 'CB_EQUIV','Pobreza', 'Indigencia', 'Pobreza_5usd']].reset_index()\n",
    "#     pobreza_hogares = df_cb_hogares[['P47T','CBA','CBT', 'CB_EQUIV','Pobreza', 'Indigencia']].reset_index()\n",
    "#     pobreza_hogares['gap_pobreza'] = pobreza_hogares.P47T - pobreza_hogares.CBT\n",
    "#     pobreza_hogares['gap_indigencia'] = pobreza_hogares.P47T - pobreza_hogares.CBA\n",
    "#     pobreza_hogares = pobreza_hogares.rename(columns = {'P47T': 'P47T_hogar'})\n",
    "\n",
    "#     # df = df.sample(25000)\n",
    "#     data = df.merge(pobreza_hogares, on = ['HOGAR_REF_ID', 'Q'])#, how = 'left')\n",
    "#     del df; del pobreza_hogares # Ahorrar memoria\n",
    "\n",
    "#     data = data.rename(columns = {'P47T': 'P47T_persona'})\n",
    "\n",
    "#     # data = data\n",
    "#     data = data.merge(radio_ref[['RADIO_REF_ID', 'IDFRAC', 'PROV', 'NOMPROV', 'AGLOMERADO', 'Region']].drop_duplicates())\n",
    "\n",
    "#     print(\"Poblacion: \"+str(len(data)/frac))\n",
    "# #     display(data[['Pobreza', 'Indigencia', 'Pobreza_5usd']].mean())\n",
    "#     filename = './../data/Pobreza/pobreza_'+'_'.join([str(frac), 'q'+q])+'.csv'\n",
    "#     data.to_csv(filename, index = False) ## Aca si ya existen no deberian sobreescribirse (o si)\n",
    "    \n",
    "#     print(filename+' saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c5d84736ba45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(quarter_Xy_file)\n",
    "# df[['PP07G1','PP07G_59','PP07I','PP07J','PP07K']].value_counts().cumsum()\n",
    "\n",
    "# PP07G1  PP07G_59  PP07I  PP07J  PP07K\n",
    "# 0       0         0      0      0        228552  No aplica porque no trabaja\n",
    "# 1       0         0      1      1        342662  Vacaciones pagas, trabaja de dia. Recibo con sello\n",
    "# 2       5         2      1      4        389235  No tiene Vacaciones pagas, Ningun beneficio, No aporta, trabaja de dia, no le entregan nada (recibo) cuando cobra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.PP07K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribucion del ingreso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# fig, ax = plt.subplots(1, figsize = (5, 3))\n",
    "# plt.hist(np.log10(df.loc[df.P47T > 100].P47T).values, 150, normed = 'pdf')#.groupby()\n",
    "# plt.yscale('log')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### # fig, ax = plt.subplots(1, figsize = (10, 5))\n",
    "# fig, ax = plt.subplots(1, figsize = (5, 3))\n",
    "# df_ = df.groupby('HOGAR_REF_ID').sum()#.loc[df.P47T > 100]\n",
    "# agg = df_.groupby(pd.cut(np.log10(df_.P47T), np.arange(2, 6, .05)))['P47T'].agg(['count','sum'])\n",
    "# (agg/agg.sum()).plot(ax = ax)\n",
    "# # ax.set_yscale('log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
